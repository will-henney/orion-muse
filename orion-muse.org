#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:{} arch:headline
#+OPTIONS: author:t c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+OPTIONS: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t
#+OPTIONS: tags:t tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+TITLE: orion-muse
#+AUTHOR: William Henney
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+TODO: TODO NEXT STARTED | DONE CANCELED
* Dealing with symbolic links to external disk
+ [2019-05-11 Sat] Unfortunately, because of the way that Dropbox works, there are problems with having links to folders that come and go
+ So for the moment, I am removing the symbolic link of ~Linemaps/~ to ~/Volumes/SSD-1TB/OrionMuse/LineMaps/~
+ We can reinstate it later if necessary, but that will cause Dropbox churn
+ Better would be to add an explicit path to the scripts


** Command to reinstate link
#+begin_src sh
ln -s Linemaps /Volumes/SSD-1TB/OrionMuse/LineMaps
#+end_src

* Project Planning
:PROPERTIES:
:EXPORT_FILE_NAME: project-planning
:END:
+ Everything in this section should be a well-defined task
+ Milestones (mainly Skype calls) are level-3 headings under [[id:706697F5-E600-4446-A4A4-C467A96CBD2C][Short term goals]] with deadlines
  + Tasks should be assigned as level-4 headings under those
+ Less imminent tasks can be dumped under [[id:CF91729B-5B8B-4A7A-B7BB-3F268F9C38EA][Medium term goals]] until they have a place to go

** New priorities - 2016 December

*** Support for orion-widths project
+ We want to improve the line extraction a bit
+ Aim is to be able to plot mean velocities and line widths as a function of wavelength
+ But we need to divide lines up into categories so that we are comparing like with like
+ Note that the transfer of files to linux server nil will not be done via git, since it is too much of a mess to work out what needs to be kept from the files there
*** Random thoughts on permitted lines
:LOGBOOK:
CLOCK: [2017-01-05 Thu 13:05]--[2017-01-09 Mon 19:46] => 102:41
:END:
+ Good discussion in Sharpee et al 2004
  + Turns out that the C II 7231, 7236 lines are already expected to be 50% fluorescence
    + At least according to Grandi (1976)
    + This is multiplet V3
  + Description of morphology of the fluorescent contribution is hidden away in [[id:347AC3EE-D131-4BEF-9A94-71DC9FFFD199][{10/10} Perform line extraction, fuzzing, binning, multimapping all on linux server]]
  + The best C II line is V6 4267, which we don't have
  + The pure recomb lines that we /do/ have are
    + 4620.11 V17.08 - clean bit of spectrum but very weak
    + 4802.740 - messy blend with N II and possibly [Co II]
    + 5342.40 V17.06 - clean but weak
    + 6151.43 V16.04 - stronger than the others, more or less clean, except for O I 6156 on the red side
    + 6461.95 V17.04 - strongest so far and clean
    + 7519.49 - not in Sharpee, sky contam but subtractable
  + So best bet seems to be 6461.95

** Short term goals
:PROPERTIES:
:ID:       706697F5-E600-4446-A4A4-C467A96CBD2C
:END:
*** DONE [7/7] Skype call Nashville+2 
CLOSED: [2015-11-04 Wed 15:42] DEADLINE: <2015-11-04 Wed>
**** DONE Make little cubes to cover borders between the wavsecs
CLOSED: [2015-10-30 Fri 10:24]
+ The window used in the line extraction is 24 Ang wide and sometimes this straddles two different wavsec sections
+ One way to deal with this would be to make separate little cubes covering +/- 12 Angstrom either side of the dividing lines
**** DONE [4/4] Estimate noise in MUSE maps
CLOSED: [2015-10-30 Fri 22:37]
+ [X] Use the error cube from the original FITS file
  + Need to do this on server (or maybe on hypatia)
  + [2015-10-29 Thu 11:28] I now have the cubes on hypatia (or on their way from nil)
  + I have put them in the =BigFiles/= folder, *which is excluded from Dropbox*
  + They are 6.8GB each = 47.6 GB all together
    + There is not enough disk space on my laptop for them
+ [X] Make fuzzed versions of the line maps
  + [X] First I [[id:9B385AF1-5AA5-4EA2-B1A3-8802C0959808][refactored]] extract-em-line.py to use windows of the cube
  + [X] Then I do a [[id:12C8CC0B-4F79-4726-B0E2-6DA1F9DFABA3][version]] that fuzzes each window first
  + I am doing 10 fuzzes of each line, which takes about 45 sec per line on my iMac
  + [X] 5192 is a special case, since it straddles two wavsecs - use the F%$7M window instead, but I need to extract that from the big variance cube
  + Lines I have fuzzed [2015-10-30 Fri 08:19]:
    + Reddening: H I 6563, 4861, 9229
    + Te: [S III] 6312, 9069, [N II] 5755, 6583, [Ar III] 5192, 7751, [O I] 5577, 6300
    + Ne: [Cl III] 5518, 5538, [S II] 6731, 6716, [Fe III] 4702, 4658
    + Constant: [O III] 5007, 4959, [Ar III] 7136, [N II] 6548, [O I] 6364
    + Other: [Cl IV] 8046, [C I] 8727
+ [X] Propagate the variance through all the data reduction steps
  + [X] First [[id:3D36AC7E-5321-420E-B0A4-29EC2068083D][multibinning]]
    + There might be an issue here with the fuzzing producing a bias towards higher brightness in the binned maps
    + I think this is because the binning masks out negative pixels, which is not appropriate for the weak lines (added [[id:4FBBD1CF-34BD-4B32-AF39-AB459DB44A18][task]] to fix this)
  + [X] Then calculation of [[id:55C78FE2-2D64-4EE3-9222-FA65A68FC55A][ratios]]
  + [X] Then extinction correction
  + [X] Then [[id:4DD175B0-88A8-4F96-B7B7-1DB2B241A3F6][calculation of Te, Ne]]
+ [X] Look at \Delta T, \Delta N and so on as function of brightness and binning
  + Where the \Delta's are the std among the different fuzzies
  + This is done in the section [[id:8793FA29-D493-4859-A5E7-BD522D218497][Delta Te, Ne from the fuzzing]] where we produce fits files of (\Delta T / T) and log(N'/N)
  + Then the histograms are plotted in the section [[id:7DB9EEBF-F83B-4D93-8C0D-8665AC9881AD][Fuzzy Deltas distribution histograms]] where I have used the same plotting range as in [[id:B85FB5E5-A541-4862-AEA4-796B64172022][Te - Ne distribution histograms]] so that they can be directly compared
    + Separate task: [[id:08241C4F-6455-4B2F-8042-4E5FA58599BC][Improve presentation of histograms and put in draft paper]]
+ Repeat for the "constant" ratios, to check that the fuzzies correctly predict the march towards the correct value as the binning is increased
  + This has been moved to its [[id:C0999AF9-C941-4063-952D-F3B34CDE80AD][own task]]
+ /Original note/ Then we can fuzz the line maps by adding Gaussian noise.
  + Actually it would be best to fuzz the data cubes directly. And then to follow exactly the same steps with the fuzzed data. We can then calculate the pixel by pixel differences between T from fuzzed and original cubes. The dispersion in this is then our best estimate for the noise contribution to t-squared.
  + We can also then use this to generate maps with a guaranteed signal to noise by using multi scale binning. Important here in the case of ratios to use the same mask hierarchy for all lines that contribute to the final quantity.
    + This also now has its own [[id:F6FE685C-CBCB-4B44-884B-873C0C39E8A0][task]]

**** DONE Improve presentation of histograms and put in draft paper
CLOSED: [2015-10-31 Sat 11:36]
:PROPERTIES:
:ID:       08241C4F-6455-4B2F-8042-4E5FA58599BC
:END:
+ Use color to distinguish the real data from the fuzzing estimates of noise
**** DONE [#A] Investigate upward bias in fuzzing + binning
CLOSED: [2015-11-01 Sun 11:23]
:PROPERTIES:
:ID:       4FBBD1CF-34BD-4B32-AF39-AB459DB44A18
:END:
+ Weak lines after binning are brighter in fuzzed versions
+ Presumably due to masking out negative pixels, which eliminates the negative part of the noise
+ [2015-10-31 Sat 16:25] I have modified [[file:multibin-map.py]] from the section [[id:3D36AC7E-5321-420E-B0A4-29EC2068083D][Multi-resolution MUSE line maps]] so that it no longer masks out negative pixels in the line maps
  + I have rerun the rebinning for the regular and fuzzed maps
  + Then rerun all the following steps
  + Things are *much improved*
    + The [Cl III] density now behaves much more reasonably in the faint parts.  It no longer tends to a constant value
    + We have also eliminated the high apparent [N II] temperatures in the Dark Bay
    + Other weak lines are also now much better, such as [C I] 8727 and [Cl IV]
**** DONE [#A] Analyse apparent and real t^2 as function of brightness
CLOSED: [2015-11-04 Wed 13:14]
:PROPERTIES:
:ID:       FC1CAAAF-8A94-4836-A8BE-BA2BC0B955CF
:END:
+ Modify the histogram plotting programs to calculate mean and variance for each brightness bin
  + And maybe plot mean +/- sigma on the graphs (although that might get too fussy)
+ Decompose the total t^2 into the (brightness-weighted) average over the variances within each brightness bin *plus* the variance in the mean values /between/ the brightness bins
  + Check that this works out OK for the total apparent t^2
+ Then we can subtract off the noise variance (obtained via fuzzing) from each brightness bin and recalculate the total t^2 to get the noise-corrected value for each degree of spatial binning
+ Plots of partial t-squared in section [[id:6B630292-2F8F-4192-89C1-AF07F5462505][Compare the observed and fuzzed variances in Te,Ne]]
  + It turns out that we need to use robust statistics because the variance is too sensitive to wings of the distribution
+ The continuation task for this topic is [[id:6D2E8B3E-1712-4EAF-8F6E-332C834EF9B0][Complete work on noise-corrected t^2 as function of scale/binning]]
**** DONE [#B] Generate line maps for the new lines I added to the table
CLOSED: [2015-11-04 Wed 09:24]
+ Most importantly [Ar IV]
  + From looking at the [[id:907D4EED-69C9-4B01-9ECB-E8A2C9757E80][Manu PPAK results for {Ar IV}]], the distribution is similar to [Cl IV], but it is slightly more extended
+ I also have a lot more [Fe III] lines in the blue
+ And the stellar absorption lines too
+ [X] This has to be done on =hypatia= or on =nil= since I have removed the big data cubes from my laptop
+ The [Ar IV] 4740 line looks great - very similar distribution to [Cl IV]
  + Shows the proplyd bowshocks very well
  + We also see [Ar IV] 4711 contamination in the He I 4713 map
    + The proplyd bowshocks show up in that too
+ The three semi-forbidden Ca I] lines look very strange
  + The red one 9095 looks like fluorescence, but 9052 looks like it comes from the i-front and 7890 like it comes from intermediate ionization gas
    + Could 7890 be contaminated with something else? Looks a bit like [Fe III]
+ The red C II 7231 7236 permitted lines are very strong
  + Also show up the proplyd bowshocks and very strong in the Big ARc as expected
+ [X] Now I need to do rebinning for them
**** DONE [#B] Pad images to multiple of 256 before binning
CLOSED: [2015-11-04 Wed 09:22]
+ This is so that all the binned maps are the same size,
  + which would look nicer
  + and would avoid having to continually align to WCS in ds9
+ This is now implemented in [[file:multibin-map.py]] from section [[id:3D36AC7E-5321-420E-B0A4-29EC2068083D][Multi-resolution MUSE line maps]]
*** DONE [3/3] Skype call Nashville+3
CLOSED: [2015-11-10 Tue 12:23] DEADLINE: <2015-11-10 Tue>
**** DONE [#A] Write script to generate figures of MUSE maps
CLOSED: [2015-11-06 Fri 13:43]
+ Use WCSAxes or APLpy?
  + Example of WCSAxes from [[id:37AA7727-E86E-424E-BCC2-764E8EC8EBA6][sinfoni notes]]
  + Looks really easy to use
+ This is done [[id:DF6370DF-79C4-4B48-B862-27B74302F9A0][down here]]
**** DONE [#A] [10/10] Perform line extraction, fuzzing, binning, multimapping all on linux server
CLOSED: [2015-11-09 Mon 19:46]
:PROPERTIES:
:ID:       347AC3EE-D131-4BEF-9A94-71DC9FFFD199
:END:
:LOGBOOK:
- Note taken on [2015-11-09 Mon 19:46] \\
  This took forever!
:END:
This will be a good test that the work flow can be made self-contained
1. [X] [[id:E29DD76D-0B11-4F52-8B50-8967046D2F0C][Ship over]] the .py, .sh, and .tab files
   - First had to link helio_utils.py from Alba project since needed in the extraction step src_sh{ln -s ../OrionWest/helio_utils.py .}
   - And had to add =-L= option to rsync so file is copied, not just dangling link
2. [X] [[id:9B385AF1-5AA5-4EA2-B1A3-8802C0959808][Extract]] the lines
   - Command is
     #+BEGIN_SRC sh :eval no
     python extract-em-line.py
     #+END_SRC
   - First I had to build and install [[https://github.com/scottransom/pyslalib][pyslalib]]
   - Seems to run slower than on iMac, presumably because it has spinning drives instead of SSDs
     - Finally, it took 13m4.796s
   - Had to correct another issue with straddling boundaries for DIB line
3. [X] Fuzz the lines and continua
   - This takes even longer
     - [2015-11-06 Fri 07:53] Finally finished - took 350m30.584s
   - Command is
     #+BEGIN_SRC sh :eval no
     python extract-em-line-fuzz.py
     #+END_SRC
4. [X] [[id:D49AD965-AFDC-4D58-9341-8202DD8508D3][Bin]] the lines and continua
   - Command is 
     #+BEGIN_SRC sh :eval no
       time sh all-lines-multibin.sh
       time sh all-continuum-multibin.sh
     #+END_SRC
   - There was a problem with missing f547m image file.  Needed to do the following
     #+BEGIN_SRC sh :eval no
       source activate py27
       export PYSYN_CDBS=/fs/nil/other0/will/CDBS
       time python filter-flatten.py wfc3 f547m
     #+END_SRC
   - Repeat for the fuzzed ones using =all-fuzz-multibin.sh= which takes an argument of the fuzzing number.  So we can run them all in parallel easily
   - [X] We missed the 92?? Angstrom lines because they hadn't finished from the previous step, so we need to do those again
   - [X] Also the continuum ones, which I had messed up
     - [2015-11-06 Fri 08:31] Now running on nil, but they are going really slowly
     - Most processes are stuck in "disk sleep" state
     - Had to nurse them by hand in small batches
     - It turns out that the trick is not to run more than 4 jobs at once that are trying to access the disk
5. [X] [[id:4B6B5B8C-94C8-456D-90CB-2CF7B0D73099][Calculate EW]] for all lines (binned and fuzzed)
   - [X] Normal =python muse-ew-all.py=
   - [X] Binned and Fuzzed
     - =sh batch-ew.sh= or =sh batch-ew.sh -fuzz000=, etc
     - I'm doing this 4 fuzzies at a time on the server so we don't have any disk sleep issues
6. [X] [[id:DED61F19-3303-4D94-BB1C-12B4BC789D65][Calculate the noise and signal-to-noise]] for each map
   - [X] First for =linesum= maps - this took several hours
   - [X] Next for =ew= maps, but not all of them
     - See [[id:5E28C927-CB18-45CB-87E0-C52109A04F79][Make a list of all the absorption lines]]
7. [X] [[id:92671F18-9117-4B7E-8315-8C74DC4FF786][Generate multibin-combined maps]] of
   - All lines at
     - SN=5
     - SN=10
     - SN=30
   - Selected EWs (absorption lines mainly)
8. [X] Generate [[id:07D1CD25-8319-4634-904D-A3A4CBC10E8D][ratio maps]]
   + This needs to be formalised a lot better
   + [X] Save the ratios we want to table files
   + [X] Use Make or similar for dependencies
     + Plumped for =distutils.dep_util.newer()= from the standard library, which works great
9. Do multibin combination for the ratios at constant s/n
   - [X] Pilot study for selected ratios.  Highlights are:
     - C II 7236 / H\alpha 6563 - shows wonderful swirls, presumably where thet fluorescent excitation of the C II line is highest, which should trace the inner edge of dense ionized gas in the nebula.  This has peaks (from inside to outside) at the LV bowshocks; at the *Ney-Allen Nebula*; at the filament behind LV6; /possibly/ the 177-341 bowshock; in a *270 degree shell* that starts in front of 177-341 and curves round to W past 159-350 shocks, then runs NW parallel to the SW lane (and yes, that is an extinction feature, the superposition may be conicidental), then bends to the E to run along just inside the high-ionization inner arm of the E-W bar (of course the appearance of a 270 deg shell may be illusory); then the E side of the *Big Arc*, which is the largest scale feature (to the W it becoes less prominent, which coincides in PA with where the inner 270 deg shell gets brighter - maybe it is blocking it); then finally, around \theta2A.  There is also a dip at the Bright Bar i-front, which must be due the C++/C+ transition
     - Various extinction ratios
   - [X] All ratios
10. [X] Generate fuzzed Te and Ne maps
    - [X] For the sii-nii case
      - Used command like
#+BEGIN_EXAMPLE
nohup time python muse-make-te-ne-maps-rebin.py -fuzz009 > job009.out
#+END_EXAMPLE
    - [X] For the cliii-siii case
    - Also, extend to [Fe III] density?
      - Not now
   
**** DONE [#A] Generate maps with constant signal-noise
CLOSED: [2015-11-06 Fri 22:26]
:PROPERTIES:
:ID:       F6FE685C-CBCB-4B44-884B-873C0C39E8A0
:END:
+ Multiple binning scales
+ For each pixel take least binning with s/n above required value
+ Calculate s/n from fuzzed versions
  + It turns out that N=10 fuzzed versions is a definite advantage with this, whereas N=1 was enough for the t^{2} statistics
  + We need enough fuzzed images that we get a /good/ estimate of the s/n in each pixel.  Only 3 is not good enough because a small but non-negligible fraction of the pixels have s/n overestimated (just by chance) and these can produce bright or dark spots in the results 
+ [2015-11-05 Thu 14:07] This is working great now, but I need to do it at scale, which will generate 100s of GB of files
  + For instance, I currently have 9.6GB of N_III-6634 files
  + And then my laptop takes ages to sync it all with Dropbox
  + One solution would be to do all the fuzz-binning in the =BigFiles/= folder
    + But keep the raw fuzz and the regular binning ones in =LineMaps/=
  + It only takes 20 s to generate all the fuzz???-bin??? files for a single line and they represent 90% of the disk space
    + They can be deleted again once the multibin files have been created
***** All the steps for a single line
As an example we use the unidentified absorption line 6634
#+BEGIN_SRC sh
  linelist=LineMaps/linesum-N_III-6634-fuzz???.fits 
  time (for line in $linelist; do     echo "Processing $line";     time python multibin-map.py $line; done)
  linelist=LineMaps/continuum-N_III-6634-fuzz???.fits 
  time (for line in $linelist; do     echo "Processing $line";     time python multibin-map.py $line; done)
  linelist=LineMaps/linesum-N_III-6634-fuzz???-bin???.fits 
  for line in linelist; do python muse-ew.py $line; done
  for line in $linelist; do python muse-ew.py $line; done
  linelist=LineMaps/linesum-N_III-6634-bin???.fits 
  for line in $linelist; do python muse-ew.py $line; done
  linelist=LineMaps/linesum-N_III-6634-bin???.fits 
  for line in $linelist; do python muse-ew.py $line; done
#+END_SRC
***** Redoing the fuzzed Te, Ne maps
#+BEGIN_SRC sh :eval no
  time python muse-make-te-ne-maps-rebin.py
  time python muse-make-te-ne-maps-iii-rebin.py
  for i in $(seq 0 9); do
      time python muse-make-te-ne-maps-rebin.py -fuzz00$i
      time python muse-make-te-ne-maps-iii-rebin.py -fuzz00$i
  done
#+END_SRC
*** [3/15] Skype call Nashville+4
DEADLINE: <2015-11-18 Wed>
**** DONE [#A] Package up fits files for Bob 
CLOSED: [2015-11-10 Tue 12:24]
+ Bob wants the constant s/n maps
#+BEGIN_SRC sh :results verbatim
date
files=LineMaps/muse-derived-[TN]e*-multibin-SN0???.fits
zip files-for-Bob-2015-11-10.zip  $files
#+END_SRC

#+RESULTS:
#+begin_example
Tue Nov 10 12:26:07 CST 2015
updating: LineMaps/muse-derived-Ne-iii-multibin-SN0003.fits (deflated 98%)
updating: LineMaps/muse-derived-Ne-iii-multibin-SN0010.fits (deflated 99%)
updating: LineMaps/muse-derived-Ne-iii-multibin-SN0030.fits (deflated 100%)
updating: LineMaps/muse-derived-Ne-iii-multibin-SN0100.fits (deflated 100%)
updating: LineMaps/muse-derived-Ne-multibin-SN0003.fits (deflated 36%)
updating: LineMaps/muse-derived-Ne-multibin-SN0010.fits (deflated 86%)
updating: LineMaps/muse-derived-Ne-multibin-SN0030.fits (deflated 98%)
updating: LineMaps/muse-derived-Ne-multibin-SN0100.fits (deflated 99%)
updating: LineMaps/muse-derived-Ne-multibin-SN0300.fits (deflated 100%)
updating: LineMaps/muse-derived-Te-iii-multibin-SN0003.fits (deflated 78%)
updating: LineMaps/muse-derived-Te-iii-multibin-SN0010.fits (deflated 88%)
updating: LineMaps/muse-derived-Te-iii-multibin-SN0030.fits (deflated 93%)
updating: LineMaps/muse-derived-Te-iii-multibin-SN0100.fits (deflated 98%)
updating: LineMaps/muse-derived-Te-iii-multibin-SN0300.fits (deflated 99%)
updating: LineMaps/muse-derived-Te-multibin-SN0003.fits (deflated 31%)
updating: LineMaps/muse-derived-Te-multibin-SN0030.fits (deflated 92%)
updating: LineMaps/muse-derived-Te-multibin-SN0100.fits (deflated 99%)
updating: LineMaps/muse-derived-Te-multibin-SN0300.fits (deflated 99%)
#+end_example

**** NEXT [#A] Write to the MUSE people
+ Be polite
+ Compliment them on the new paper
+ Draw their attention to the Sac paper
+ The effect of noise on the structure function is well known - you just have to subtract its variance from the (\Delta v)^2 values


**** DONE [#A] [2/2] Complete work on noise-corrected t^2 as function of scale/binning
CLOSED: [2015-11-12 Thu 21:23]
:PROPERTIES:
:ID:       6D2E8B3E-1712-4EAF-8F6E-332C834EF9B0
:END:
+ Continuation of previous task [[id:FC1CAAAF-8A94-4836-A8BE-BA2BC0B955CF][Analyse apparent and real t^2 as function of brightness]]
+ [X] Do average over all brightnesses
+ [X] And add in the trend of T with brightness
+ First we [[id:E7AFCF19-3976-4FD9-A91F-464A2EDD9C86][Calculate the total noise-corrected t2 versus binning scale]]
+ Then we make the [[id:BB997AAB-0452-497F-84A0-69713FB7228C][Plot of t2 versus scale]]
+ This seems to work great, but I have made another task to [[id:0A73C539-4A97-4C97-9F39-DA83032B340F][try alternative way of calculating the noise effects on t2]]
+ And another continuation of this task is to [[id:1B2D2809-A54A-4372-913C-F8DE9E5F5E65][make maps of the small-scale t2]]
**** STARTED [#B] [1/3] Try alternative way of calculating the noise effects on t2
:PROPERTIES:
:ID:       0A73C539-4A97-4C97-9F39-DA83032B340F
:END:
There are a couple of niggling things worying me about how I did [[id:6D2E8B3E-1712-4EAF-8F6E-332C834EF9B0][the work on noise-corrected t^2 as function of scale/binning]]
+ [X] First, I never really subtracted the noise separately in each brightness bin, but rather calculated the weighted average of both the variations and the noise and /then/ subtracted
  + But that should not make any difference at all, so I should stop worrying about that
+ [ ] Also, I never calculated the total t-squared directly from the maps, to check that it comes out the same
+ [ ] And lastly, it would make more sense to calculate the noise directly as the mean of the std maps (like muse-derived-Te-STD-bin008.fits), rather than as the variance of the (fuzz - observed) maps.  That way, we have a value per-pixel.  
**** TODO Extend the analysis to the density fluctuations
+ Instead of t^2 use variance of log(n/\langle{}n\rangle)
+ 
**** CANCELED Make maps of the small-scale t2 /NEVER GOING TO WORK/
CLOSED: [2016-02-21 Sun 11:45]
:PROPERTIES:
:ID:       1B2D2809-A54A-4372-913C-F8DE9E5F5E65
:END:
:LOGBOOK:
- Note taken on [2016-02-21 Sun 11:47] \\
  No point doing this since I don't believe in the reality of the small scale fluctuations any more, which is probably why it never worked in the first place!
:END:
+ From the [[id:6D2E8B3E-1712-4EAF-8F6E-332C834EF9B0][t2 vs scale plots]] we get a clean separation between
  1. Large scales (> 30 arcsec) that produce half the t^{2}
  2. Small scales (< 3 arcsec) that produce the other half
+ That means that it makes sense to make intermediate-resolution maps /of/ the small-scale variations.
  + Let's call this the *inner t^{2}*
  + Binning of 16 or 32 would probably work best
  + We can subtract off the square of the STD to account for the noise
  + I have checked and bin=16 will work fine for [N II] over most of the map
    + We are looking for a signal of order 4e-3
    + Noise t2 ranges from 3e-6 in Orion S to 2e-3 in Dark bay (average is 5e-5)
  + For [S III], bin=16 will only work for brighter parts
    + Signal is now only 1e-3
    + Noise t2 is 1e-5 in bright part, up to 5e-4 (or more) in Dark Bay
    + So it actually might be alright - if not bin=32 would have to do
**** TODO Take power spectrum of fluctuations
To confirm that we do indeed have a separate large-scale and small-scale mode of fluctuations
**** NEXT Extend the fluctuations down to the Field scale
+ We could maybe argue that the small scale fluctuations carry on down to the Field length
+ Although this only really applies to the case of thermal instabilities - can this really apply here?
  + It is well known that neutral gas is thermally unstable in the range around 1000 K, but how can this be the case for ionized gas?
  + We need that dP/dn is negative, or at least be small - so that compression can produce large T jumps
+ From the [N I] paper I had that this is (1e15/ n) cm, which is probably just for neutral gas - better to use the equation: 
  + \[ l_{f} = \sqrt(\kappa T / |\rho L|)]
  + \kappa is coefficient of conductivity;
  + L is net cooling rate per mass, where \rho L is in units erg/s/cm3
  + See Iwasaki and Inutsuka (2012)
    + We can use \kappa = 1e4 erg/s/cm/K, so \kappa T = 1e8 erg/s/cm
    + \rho L = n^{2} \Lambda is of order (1e4)**2 3e-24 = 3e-16 erg/s/cm3
    + So l_{f} = 5.77e11 cm for n = 1e4 and is proportional to 1/n
+ How does conductivity compare with advection in energy equation
  + Conductive flux is -\kappa dT/dx
  + Advective flux is v (5/2 P + 1/2 \rho v^2)
    + For roughly sonic velocities, v \simeq a, so that is about 3 a P, or 6 a n k T if we put P = 2 n k T for fully ionized pure H 
  + So Cond/Advec \simeq \kappa dT/dx / 6 a n k T
    + We can put (1/T) (dT/dx) = t/H, where t is the fractional temperature fluctuation (t = dT/T) and H is the scale of the fluctuation
    + F_{cond} = \kappa t T / H
    + => Cond/Advec = (\kappa t / 6 a n k H)
    + So Cond > Advec for H < \kappa t / 6 a n k
    + In fact, we should also take into account that v fluctuations will decline at smaller scales too - for instance v \sim l^{1/3} for Kolmogorov
      + OK, so if the injection scale is L, then advective flux at scale H becomes F_{ad} = 6 a (H/L)^{1/3} n k T 
      + Hence F_{cond} / F_{ad} = \kappa t L^{1/3} / 6 a H^{4/3} n k
      + This is unity when H = (\kappa t L^{1/3} / 6 a n k)^{3/4}
    + I will use the value derived below of \kappa = 1e4 erg/s/cm/K, which is almost universally valid for photoionized regions
      + For sonic advection velocities at all scales, this gives H < src_calc{clean(1e4 0.1 / 6 1e6 1e4 1.3806503e-16, 3)} {{{results(=1.21e8=)}}}, which is very small
      + For Kolmogorov-distributed advection velocities from sonic turbulence injected at a scale of L = 1e16 cm, the result is H = src_calc{(1e4 0.1 1e16**(1/3) / 6 1e6 1e4 1.3806503e-16)**(3/4)} {{{results(=1.15165870203e10=)}}}, which is still small, but is 100 times larger than the electron mean free path 
  + Lorentzian conductivity (electrons interacting with static ions) is
    + \[ \sigma = 2^{5/2 }m_{e}^{1/2}  (k T)^{3/2 }/ Z e^{2} (\pi m_{e})^{3/2} \ln \Lambda \]
    + *Nope* this is the /electrical conductivity/
    + Units should be erg/s/cm/K, but they aren't so forget this
    + I take a Coulomb logarithm of 20, which is vaguely what I remember
    + -> H < src_calc{2e12 0.1 / 6 1e6 1e4 1.3806503e-16} {{{results(=2.41432123206e16=)}}}
    + That is about (1000 / n_{4}) AU, which is really large - 2 arcsec
    + [X] But we need to calculate the effects of saturation on the conduction
      + OK, this just means that for scales smaller than λ_{e} we don't have diffusion any more, we just have free-streaming electrons, so the conductive flux is just \simeq v_{e} P \propto n_{e} T_{e}^{1/2}, independent of dT/dx
      + Note that in this limit, we always have Cond > Advec by a factor of (v_{e}/v_{ion}) \simeq 43, because the conduction is advection too and the electrons are moving faster
    + [ ] And magnetic fields - these should suppress conduction \perp to field
  + Use thermal conductivity formulae from Toalá & Arthur (2011)
    + They use D instead of \kappa
    + Citing Steffen (2008) they put
      + D = 7.04 × 10^{−11} λ_{e} n_{e} T^{1/2}
    + Where  λ_{e} is the electron mean free path
      + λ_{e} = 2.625 × 10^{5} T_{e}^{2}/(n_{e} ln Λ)
      + and ln Λ = 9.452 + (3/2) ln T_{e} − (1/2) ln n_{e} for T_{e} \le 4.2 \times 10^{5} K
      + So for 1e4 K and 1e4 pcc, ln \Lambda = src_calc{9.452 + 1.5 log(1e4) - 0.5 log(1e4)} {{{results(=18.662340372=)}}}
      + Better still, here is a table:
        |                  |   T |   n |    B |    \beta |    R |  ln \Lambda |      \lambda_{e} |       \ell |      \lambda_{D} |    r_{L} |      Kn |      \kappa |
        |------------------+-----+-----+------+------+------+-------+---------+---------+---------+-------+---------+--------|
        | ISM WIM          | 1e4 | 0.1 | 1e-6 |  6.9 | 3e20 | 24.42 | 1.07e13 |  2.15e0 |  2.18e3 | 2.2e6 |  3.6e-8 |  7.5e3 |
        | H II region      | 1e4 | 100 | 1e-5 | 69.4 | 3e18 | 20.96 | 1.25e10 | 2.15e-1 |  6.90e1 | 2.2e5 |  4.2e-9 |  8.8e3 |
        | H II compact     | 1e4 | 1e4 | 1e-4 | 69.4 | 3e17 | 18.66 |  1.41e8 | 4.64e-2 |  6.90e0 | 2.2e4 | 4.7e-10 |  9.9e3 |
        | Proplyd          | 1e4 | 1e6 | 1e-3 | 69.4 | 3e15 | 16.36 |  1.60e6 |    1e-2 | 6.90e-1 | 2.2e3 | 5.3e-10 |  1.1e4 |
        | Stel.Wind @ Prop | 3e7 |  50 | 2e-3 |  2.6 | 3e16 | 33.32 | 1.42e17 | 2.71e-1 |  5.35e3 | 6.1e4 |   4.7e0 | 2.7e12 |
        | Stel.Wind @ Neb  | 1e6 |   1 | 2e-5 | 17.3 | 3e18 | 30.18 | 8.70e15 |       1 |  6.90e3 | 1.1e6 |  2.9e-3 |  6.1e8 |
        | Solar Wind       | 1e5 |   1 | 1e-5 |  6.9 | 1e13 | 26.72 | 9.82e13 |       1 |  2.18e3 | 7.0e5 |   9.8e0 |  2.2e6 |
        | Fast Solar Wind  | 1e5 |  10 | 3e-5 |  7.7 | 1e13 | 25.57 | 1.03e13 | 4.64e-1 |  6.90e2 | 2.3e5 |   1.0e0 |  2.3e6 |
        | Slow Solar Wind  | 1e5 |   3 | 3e-5 |  2.3 | 1e13 | 26.17 | 3.34e13 | 6.93e-1 |  1.26e3 | 2.3e5 |   3.3e0 |  2.2e6 |
        | Magnetosphere    | 1e7 |  10 | 1e-4 | 69.4 |  1e9 | 32.48 | 8.08e16 | 4.64e-1 |  6.90e3 | 7.0e5 |   8.1e7 | 1.8e11 |
        #+TBLFM: $5=2 $3 $k $2 8 $pi / $4**2;f1::$7=9.452 + 1.5 log($2) - 0.5 log($3) ; f2::$8=2.625e5 $2**2 /($3 $7) ;s3::$9=$3**(-1/3); s3::$10=sqrt($k $2 / 4 $pi $3 $e**2) ; s3::$11=sqrt($me $k $2) $c / $e $4;s2::$12=$8/$6;s2::$13=7.04e-11 $8 $3 sqrt($2);s2::@2$6=100 $pc;s1::@5$6=200 $au;s1::@6$6=2000 $au;s1::@8$6..@10$6=1 $au;s1::@11$6=1e4 $km;s1

      + Here we have added mean particle separation \ell = n^{-1/3} and the Debye length \lambda_{D} = (k T / 4 \pi n e^{2})^{1/2}
      + Some of the numbers came from [[https://en.wikipedia.org/wiki/Debye_length][wikipedia Debye Length page]]
        + Remembering 1 /m3 = 1e-6 /cm3 and 1 T = 1e4 G
      + Fast/Slow solar winds come from Hansteen (2009)
        + Note that T ~ 1e5 K in table is electron temperature
        + Proton temperatures are different
          + 2 times lower in slow wind
          + 2 times higher in fast wind, and also anisotropic: T_{p,\perp} > T_{p,\parallel}
      + For shocked stellar wind, I took values for positions of LV bowshocks
        + B = 1 kG at the stellar surface: R \simeq 7e11 cm
        + Winds with open field lines have (split) monopole fields inside Alfven surface (where rotation is like solid body), and then Parker spiral after that (also from Hansteen 2009)
          + So B_{r} ~ 1/r^{2} and in equator B_{\phi} \simeq (r \Omega / v_{r}) B_{r}
          + So along pole, B will fall as r^{-2} (mostly radial field), while in equator, B falls as r^{-1} and is mainly azimuthal (but smaller by factor of R_{*} \Omega / v_{r})
          + So for th1C, we have v_{r} = 1500 km/s and R_{\star} \Omega =
            + 15-day period = 1.3e6 s
            + Circunference: 2 pi R = 4.4e12 cm
            + => R_{*} \Omega = Circ / P = 3.4e6 cm/s = 34 km/s equatorial rotational velocity
            + => factor is 0.02 or so
          + Conclusion, for th1C:
            + B_{r} = 1000 (R/R_{\star})^{-2}
            + B_{\phi} = 20 (R/R_{\star})^{-1}
            + Table:
              | R (au) | R (pc) |      B_{r} |     B_{\phi} |
              |--------+--------+---------+--------|
              |   2100 |   0.01 |  5.0e-7 | 4.5e-4 |
              |  2.1e4 |   0.10 |  5.0e-9 | 4.5e-5 |
              |  2.1e5 |   1.02 | 5.0e-11 | 4.5e-6 |
              #+TBLFM: $2=$1 $au/$pc ;f2::$3=1000 (7e11 / $1 $au)**2;s2::$4=20 (7e11 / $1 $au);s2
          + So this means that in the equatorial plane, we have a mainly azimuthal field with \beta \sim 1.  It will be a perpendicular (transverse) shock, so fast magnetosonic probably.  B and n will both increase in the shock by a factor of 4.  I include that in the above table
          + In the poles, we have a purely radial field, but *much* weaker, so that \beta \sim 1e5
            + However, the equatorial case is more typical, since B_{\phi} \gg B_{r} for all latitudes except /very/ close to 90 degrees
            + On the other hand, \beta will increase with latitude as cosec^{2} l
        + Also relevant [[http://www.scholarpedia.org/article/Collisionless_shock_wave][scholarpedia article on collisionless shocks]]
      + Finally the Larmor radius:
        + Cyclotron frequency: \omega_{c} = q B / m c
        + Larmor radius = v_{\perp} / \omega_{c} = v_{\perp} m c / q B
        + We will calculate it for thermal electrons (q=e) with 1-D velocity component 1/2 m v^{2} = 1/2 k T => v = (k T / m)^{1/2}
        + So r = (m k T)^{1/2} c / e B


**** TODO [#A] Repeat the fuzzing for the WFC3 data
+ We need to use the ERR array from the original data
+ Look into the astropy affiliated CCD analysis packages to see if they might be of any use

**** NEXT Make an atlas of all the constant s/n MUSE maps 
+ This will be a lot of pages
**** TODO [#B] Correlation of T, n peaks with shocked structures, etc
+ To Complement what Bob is doing
+ T(N II) is high where [O II] red line is strong
+ The arc that Bob found at 176-248 is indeed a shock
****** Density structure at ionization fronts 
+ [S II] density tends to peak more to neutral side
  + And is very narrow - evidence for the narrow Ne peak at D-critical i-front found
    + Although not everywhere has a narrow peak
    + In the Bar best places are
      1. Between HH204 and HH528
      2. In the forked i-front S of the Red Fan
+ [Cl III] densities tend to be higher, and peak in He+ zone
  + For example, in the Bar N([Cl III]) = 4000 - 5000 while N([S II]) = 3000 - 3700 
+ [ ] Do a model of a cylindrical photoevap flow to check if the density variations can explain the [S II] - [Cl III] density discrepancy
  + I am skeptical because although critical density will bias [S II] towards  the low density parts along the line of sight, the S++/S+ ionization gradient will bias it towards the high density parts since they are closer to the i-front

***** High T versus density fluctuations
+ We can use the PPAK [S II] 4076/6731 vs 6716/6731 to try and disentangle this
+ Also the plane-of-sky fluctuations in density can put a restriction on it
***** Shadows of embedded filaments?
****** Evidence for filaments
+ Some are jets - seen in proper motion, radial velocity
  + Do they have neutral cores?
  + Even if they don't,  the bright ones are high enough emission measure to reduce ionizing flux on "shadow" side, eben if they don't eliminate it
+ Some are neutral filaments
  + seen in O I permitted lines (fluorescent excitation in the near PDR)
  + some show clear ionization stratification on illuminated side
****** Correlation with T structures
+ High T([N II]) often seen on shadow side
+ Correlated with bright [O II] 7330
***** The nature of the 176-248 arc
+ I had wondered whether it was an object that I had investigated in the LL object project, but it appears not
  + There is a nearby stationary arc (and proplyd) centered at 170-249, which is what I was thinking of - but this is about 10 arcsec to the E
+ From looking at the RGB=(O I, [O II], [Ar III]) image, the 176-248 arc does not look like a neutral filament - it is more orange, so strong in [O II] 
**** TODO [#B] What is going on with the 6634 absorption line?
+ It is not seen in any of the Trapezium stars except for th1E
+ In the nebula it has a variable absorption EW of 0.1 to 0.4 Angstrom, with the maxima occurring in Orion S (behind the SW Compact Bar), behind the E-W Bright Bar (in N Lane A), and behind the Bright Bar 
+ It does not seem to ba a DIB
  + There is a DIB at 6278 and I have made images of its EW - gives roughly constant value of 0.4 Angstrom, suggesting it is foreground to nebula
  + Although there is also a telluric band around the same wavelength, so we need to be careful - looking at the integrated spectrum, I suspect that what ew are seeing is nearly all telluric
  + [ ] We will also look at the 5782 DIB, even though that is very weak
**** TODO [#C] Look at noise behavior with binning for "constant" ratios
:PROPERTIES:
:ID:       C0999AF9-C941-4063-952D-F3B34CDE80AD
:END:
+ Such as 6363/6300, 6583/6548, 5007/4959, etc
+ This will be a clear test that the fuzzing procedure is correctly estimating the noise contribution to line-ratio variations
+ It does require that I have the general reddening correction working
**** NEXT [#C] Do extinction correction for all lines
:LOGBOOK:
CLOCK: [2016-03-29 Tue 17:00]--[2016-03-31 Thu 20:04] => 51:04
:END:
+ This means first settling on a reddening curve
+ Simplest approach is to use Hb/Ha and then apply Blagrave to everything
  + pyneb.extinction.red_corr.RedCorr(law='CCM89 Bal07') could help
  + I think they mean =Bla= instead of =Bal=
+ Of course, there are issues with that since E(Hb-Ha) plus R_V=5 reddening law seems to underpredict the extinction, at least in the dark bay
**** NEXT [#C] [2/3] Make some color images of the line maps
+ [2015-11-05 Thu] Redo this when we have all the multibin-combined maps
+ [X] This is done in the section [[id:EB04009B-1EF8-468D-8B04-C823074CF185][Grab color images from ds9]]
+ [X] The channels are as follows:
  + [[file:rgb-C1-O1-N1.jpg]] (bin002)
    + red :: C_I-8727
    + green :: O_I-8446
    + blue :: N_I-5199
    + Shows fluorescent emission from neutral gas just behind the ionization front in blue-green and collisional neutral carbon emission from deep in the PDR in red
    + Note offset of [C I] emission behind the i-front at the Bright Bar
    + Also bright filament pointing down SSW from Orion S
  + [[file:rgb-Fe2.jpg]] (bin004)
    + red :: Fe_II-8617
    + green :: Fe_II-7453
    + blue :: Fe_II-5262
  + [[file:rgb-Fe3.jpg]] (bin004)
    + red :: Fe_III-4658
    + green :: Fe_III-4702
    + blue :: Fe_III-5270
    + In principle 4702/4658 is a density indicator but it is very noisy
      + This looks much better in the [[id:9FF99B23-1472-425D-B8DB-99370939AD43][Manu PPAK data]]
      + But the results are consistent - range of 0.2 to 0.35
    + We see diffuse emission from the nebula (pink tint)
      + Annoyingly, this is an intermediate ionization, unlike any other ion stage.  It is higher ionization than [N II], [O II], but lower ionization than [S III], [Ar III], [Cl III]
    + Emission from jets and knots - discussion was getting out of hand so broken out into a new task: [[id:994ED1D9-55BD-4577-8C0A-72B05614C763][Discuss {Fe III} knots]]

  + [[file:rgb-He1-O3-Cl4.jpg]] (bin008)
    + red :: Cl_IV-8046
    + green :: O_III-5007
    + blue :: He_I-6678
  + [[file:rgb-N2-permitted.jpg]] (bin064)
    + red :: N_II-5952
    + green :: N_II-5942
    + blue :: N_II-5932
  + [[file:rgb-O1-S2-O2.jpg]] (bin004)
    + red :: O_I-6364
    + green :: S_II-6731
    + blue :: O_II-7330
  + [[file:rgb-Si2-permitted.jpg]] (bin004)
    + red :: Si_II-5041
    + green :: Si_II-5056
    + blue :: Si_II-6347
  + [[file:rgb-chlorine-234.jpg]] (bin004)
    + red :: Cl_II-8579
    + green :: Cl_III-5538
    + blue :: Cl_IV-8046
  + [[file:rgb-continuum.jpg]] (no binning)
    + red :: continuum-H_I-8438
    + green :: continuum-Cl_IV-8046
    + blue :: continuum-O_II-4650
  + [[file:rgb-Cl4-C2-Ar4.jpg]] (bin008)
    + red :: Cl_IV-8046
    + green :: C_II-7236
    + blue :: Ar_IV-4740

+ [ ] Add descriptions to figure captions


** Medium term goals
:PROPERTIES:
:ID:       CF91729B-5B8B-4A7A-B7BB-3F268F9C38EA
:END:
Holding area for tasks that will get moved to [[id:706697F5-E600-4446-A4A4-C467A96CBD2C][Short term goals]]
*** STARTED [#B] Analyze the continuum better
:LOGBOOK:
- Note taken on [2015-11-11 Wed 21:19] \\
  Started this and got a bit carried away.  Further work should aldo include trying to measure the Paschen jump
:END:
+ Add together continuum windows from different lines in the same wavelength band
+ Maybe take it in 1000 \AA zones
+ Make maps of continuum color
+ Subtract off the atomic continuuum to reveal the scattered light
  + Using the nearest H line and an assumed T
  + Just longward of the Paschen jump would be best for the red end
  + And as blue as possible for the blue end
+ Compare the blue scattered light with the red scattered light
  + Can we distinguish between foreground scattering and background scattering

***** Empirical analysis of color continuum maps  
+ Visual bands: BGR = 4000->5000, 5000->6000, 6000->7000 \AA
  + [[file:rgb-cont-4000-5000-6000-sat-enhanced.jpg]]
  + Average wavelengths: 4800-5500-6500
  + A bit like B-V-R
  + I have enhanced the saturation to better show the changes in color
+ Near IR bands: BGR = 7000->8000, 8200->9000, 9000+ \AA
  + [[file:rgb-cont-7000-8000-9000-sat-enhanced.jpg]]
  + Average wavelengths: 7500-8600-9100
  + A bit like Sloan i'- ACS z - Sloan z'
  + For the 8000 channel I excluded \lambda < 8204 \AA so that blue-green comparison is giving you the Paschen jump
+ I also took ratios.  These 
  + RGB = (6000->7000)/(7000->8000), (5000->6000)/(6000->7000), (4000->5000)/(5000->6000)
    + [[file:rgb-cont-slopes-67-56-45.jpg]]
  + RGB = (8200->9000)/(9000+), (7000->8000)/(8200->9000), (6000->7000)/(7000->8000)
    + [[file:rgb-cont-slopes-89-78-67.jpg]]
  + Note that they overlap by one band
+ There are clear variations in the colors
  + The main emitting layer is slightly pink in the Visual image, indicating recombination continuum
  + The Region around th2A and (to a much lesser extent the Trap stars) is a beautiful blue color indicating dust scattering
  + Could the mauve color around the Big Arc be due to scattering - enhanced by forward-throwing scattering phase function?
    + Or could it be due to a different T?  I don't think so
    + Or even due to two-photon emission?
    + It also shows up as relatively bluer in the Infrared image (the difference is a lot subtler though), which can't be due to two-photon, but also argues against it being optically thin dust scattering
  + The scattered light behind the bar shows up as green in the Infrared color image
    + This is because the green band is red of the Paschen jump, where the recombination continuum is at a minimum, so scattered light makes a relatively larger contribution
    + It can be seen in the Visual image too - but it is partially swamped by the scattered halo around th2A
    + We don't see the scattered halos around the stars in the infrared very prominently - this is probably because it is optically thin (or almost) and \tau falls with wavelength
    + But the diffuse reflection should be a lot grayer, since it will only depend on the albedo and the phase function
+ [ ] Should we deredden the continuum images?
  + This certainly makes sense for the atomic continuum, since it comes from the same volume as the emission lines
  + But for scattered starlight it is not really appropriate - this is enhanced in the dark bay and the sw cloud anyway.  De-reddening would only enhance it further, but I suppose that is OK
+ [ ] We should plot the full continuum spectra integrated in selected regions of interest:
  1. The main emitting layer parallel to the Bar
  2. The scattered bit behind the Bar
  3. The flat bit of Orion S
  4. The SW compact bar
  5. HH 202
  6. The Dark Bay
  7. The Bright Arc
  8. The SW cloud
  9. The E-W Bar
  10. Etcetera
**** Add up some continum maps
#+BEGIN_SRC python :tangle muse-continuum-combine.py
  import glob
  import numpy as np
  from astropy.io import fits

  wavrange = ['4?', '5?', '6?', '7?', '8[2-9]', '9?']
  binnings = [1, 2, 4, 8, 16, 32, 64, 128, 256]

  for binning in binnings:
      for wavpat in wavrange:
          wav000 = wavpat[0]
          pattern = 'LineMaps/continuum-*-{}??-bin{:03d}.fits'.format(wavpat, binning)
          cfiles = glob.glob(pattern)
          average = None
          for fn in cfiles:
              hdu = fits.open(fn)['SCALED']
              if average is None:
                  average = np.zeros_like(hdu.data)
              average += hdu.data
          average /= len(cfiles)
          out_fn = 'LineMaps/continuum-average-{}000-bin{:03d}.fits'.format(wav000, binning)
          print('Saving', out_fn)
          fits.PrimaryHDU(header=hdu.header, data=average).writeto(out_fn, clobber=True)

        
#+END_SRC

#+BEGIN_SRC sh :eval no
python muse-continuum-combine.py
#+END_SRC

**** Take some ratios
#+BEGIN_SRC python :tangle muse-continuum-ratios-diffs.py
  import numpy as np
  from astropy.io import fits

  def cfile(wav, binning):
      return 'LineMaps/continuum-average-{}-bin{:03d}.fits'.format(wav, binning)

  def rfile(wav1, wav2, binning):
      return 'LineMaps/continuum-ratio-{}-{}-bin{:03d}.fits'.format(wav1, wav2, binning)

  def dfile(wav1, wav2, binning):
      return 'LineMaps/continuum-diff-{}-{}-bin{:03d}.fits'.format(wav1, wav2, binning)


  pairs = [
      ['4000', '6000'],
      ['4000', '5000'],
      ['5000', '6000'],
      ['6000', '7000'],
      ['7000', '8000'],
      ['8000', '9000'],
      ]
  binnings = [1, 2, 4, 8, 16, 32, 64, 128, 256]
  for binning in binnings:
      for wavA, wavB in pairs:
          hduA = fits.open(cfile(wavA, binning))['SCALED']
          hduB = fits.open(cfile(wavB, binning))['SCALED']

          fn = rfile(wavA, wavB, binning)
          print('Writing', fn)
          fits.PrimaryHDU(header=hduA.header,
                          data=hduA.data/hduB.data).writeto(fn, clobber=True)

          fn = dfile(wavA, wavB, binning)
          print('Writing', fn)
          fits.PrimaryHDU(header=hduA.header,
                          data=hduA.data-hduB.data).writeto(fn, clobber=True)
        
#+END_SRC

#+BEGIN_SRC sh :eval no
python muse-continuum-ratios-diffs.py
#+END_SRC

*** STARTED [#C] Discuss [Fe III] knots
:PROPERTIES:
:ID:       994ED1D9-55BD-4577-8C0A-72B05614C763
:END:
+ In the [Fe III] maps we see enhanced emission from jets and shocks (due to increased gas phase Fe abundance following dust destruction in shocks)
+ These should be compared with the WFC3 F469N image, which has an important contribution from the 4702 line
+ From Orion S we see two linear chains of knots
  + PA114 flow
    - Probably associated with the strange [S II] bright tongue coming from 143-353 and then continues WSW through 159-402 (west side of this knot just caught in WFC3 field) and 165-406
      - On the other side to ENE (PA294) there are knots at 118-345 and 116-345, seen in WFC3 image and in MUSE line map.
        - Before getting to these there is a fainter knot at 126-346 
        - There are W-facing [N II]-bright bowshocks wrapping around each of these.
        - [X] Need to check if this is a cataloged HH flow
          - They might possibly be related to HH507 (main bow at 109-347) but I think not.  HH507 has lower ionization and is at PA315 according to BOM00 (see their Fig 22).
          - In OD15 the proper motion of 118-345 and other related knots is discussed in Sec 5.12.2., entitled /Shocks near but Probably Unrelated to HH 507/ so it looks like Bob agrees with me!
          - OD15 Table 6 gives Vt = 46, 53, 40, 48 and PA278, 279, 298, 269 for knots at 118-346, 116-346, 116-344, which all fall within the [Fe III] knots in the F649N image
            - Interestingly, there are other motion features, slightly below at 116-348 and 118-348, which have similar POS velocities, but *no [Fe III] emission* at all
          - OD15 gives the mean PA as 284, as opposed to 294, but given the uncertainties in the proper motions I think this is consistent
          - OD15 mentions the possibility of connection to the blueshifted SiO from Coup 554
            - But Coup 554 is at 135.6-355.3, whereas the [Fe III] knot chain points to 143-353 as the source (DR 1186, ZRK 15, 142.9-353.1)
          - OD15 also mentions the possibility of connection to HH269
            - That seems unlikely since the PAs are different
          - OD15 also talks about the knot 126-346, but in section 5.6, which is about HH 1127
            - However 126-346 is clearly not part of HH 1127
            - Tab 6 gives Vt = 40 at PA270
            - It is also shown as 125.5-346.5 in Fig 41, where it looks clearly to be part of same flow as 118-345
      - MUSE has a possible further knot at 091-340
        - OD15 has motions measured for 090-339 and 090-340 of Vt = 21, 52, 39 and PA284, 274, 304 - /this is consistent with being the same flow/ 
      - This flow is unlikely to be driving HH 203 unless it has bent to the south
    - This flow is likely unrelated to the PA120 filament starting around 152-358 that may also pass through 149-355 (high T filament) and might have its source in 146-351 (near-IR source).  This PA120 flow is the perfect candidate for driving HH203
  + PA090 to PA093 flow
    - probably associated with HH529
    - knot at 152-353 corresponds to a flat shock just to E of the corkscrew jet
      - OD15 has Vt=89 PA087, which cis in the right direction
    - further E there is a very compact knot at 160-353, but that is probably the proplyd 159-350, knot related to the flow
    - on the W side there is a knot at 143-352
      - OD15 has a very slow-moving knot there: 143-351 with Vt = 8 at PA284
  + The *contested knot* at 137-352
    + It is knot(!) clear whether this is part of the PA114 or PA090 flow.
      + The alignment seems equally good with either of them
        + *not true* see below: certainly PA090
    + It is the brightest [Fe III] knot of all
    + It has a strange morphology in the F469N image (it is poorly resolved in the MUSE maps)
      + It looks like a west-pointing comma-shaped bowshock with a line slashed across the S wing of the bow
      + But it can also be seen in the other filters, such as F673N, where it looks more like it is the superposition of two bowshocks, an upper one heading almost due W (PA270) and a lower one, heading more at PA260
      + It appears in OD15 as 137-352 with Vt = 49 at PA271
      + The shock just above it 137.3-350.2 is discussed in sec 5.12.6 and is classified as the first knot in HH1151 - other knots are 125.5-346.5 and 094-336
        + Note that 137.3-350.2 itself does not show [Fe III] emission, but 125.5-346.5 certainly does - it is the same as 126-346 discussed above!
    + *Revisionist version*
      + Some of the above classification is probably wrong
      + Better assignment of knots to flows is here
        + [[file:~/Work/RubinWFC3/Tsquared/feiii-knots-MUSE.reg]]
      + Also, I did the same for the [Fe II] knots here
        + [[file:~/Work/RubinWFC3/Tsquared/feii-knots-MUSE.reg]]
      + I have several apparent groupings of the knots along straight monopolar or bipolar lines
      + But I am still not entirely convinced
        + Partly due to looking at the proper motions
          + [[file:~/Work/RubinWFC3/Tsquared/proper-motion-orion-s-vslow.gif]]
          + The proper motions make it look like the HH529 corkscrew is coming from 145.7-350.8 (HC209 radio source)
          + Also that the westward knots at 138-351 and 137-352  might be coming from the same source - it looks like their proper motion is close to due W (PA270) or even slightly southward (PA260). So they are certainly not related to the  
      + Orange flow at PA110 seems to correspond to HH 1149 from OD15
        + This shows an offset between the [Fe III] and the [Fe II] knots, where [Fe II] is consistentlydisplaced a bit fiurhter from the Trapezium

        + 
*** TODO [#C] Improved robust measure of scale 
+ We need a robust measure so we are not too sensitive to fat tails!
+ Currently we use the interquartile range (IQR)
+ Another simple possibility would be the median absolute deviation (MAD)
  + These are equivalent (IQR = 2 MAD) for symmetric distributions, but are different if there is non-zero skew
+ The problem with both of these is low "efficiency" for Gaussian distributions
  + We see this in the fact that the robust partial t^2 looks noisier than the regular t^2 for high binning
+ Supposedly, Rouusseuw and Croux (1993) have better measures
  + But they are more complicated
*** TODO [#B] Make profile cuts perpendicular to the Bright Bar
+ Every other paper does this, so why not
+ To make things more interesting, we could "correct" for the Ne, Te variations
+ One problem with this is that there are no "clean" parts of the bar
  + There are multiple strands everywhere
    + Best seen in the O I 8446 fluorescence line
    + But also in the mosaic WFPC2 image of [[file:~/Work/BobPC/2002/masterf547-f656-radec.fits]]
*** TODO [#C] Deal better with sky subtraction 
+ [2015-11-01 Sun 11:11] This task demoted in importance because it turns out that it was [[id:C0999AF9-C941-4063-952D-F3B34CDE80AD][masking out noisy negative values]] that was causing most of the problems wit faint lines
  + But this is still important for the [O I] lines, particularly 5577
+ Plot weak line brightness against similar ionization strong line brightness
+ Look for an obvious floor to the weak line brightness to give estimate of the sky brightness
+ Subtract from line maps before taking ratios
+ See also [[id:C28F4B1F-E911-4C87-8AEB-E199C645CC4D][How can we deal with the systematic pattern "noise"]]
  + If we could fix that at the same time it would be great
+ Note that this issue seriously effects the [Cl III] 5518/5538 ratio
  + The extinction in the Dark Bay can be clearly seen in the ratio, which makes no sense
    + This is because there is a constant added to both line strengths
  + It is the reason why the [Cl III] density appears to tend to a constant value of about 1300 as the surface brightness tends to zero
*** TODO [#B] How can we deal with the systematic pattern "noise"
:PROPERTIES:
:ID:       C28F4B1F-E911-4C87-8AEB-E199C645CC4D
:END:
+ The most obvious pattern is the square grid where the different fields overlap
  + In principal, the overlap strips should just be a reduction in noise, but in reality the values themselves change
  + Often seen as dark strips on the 
+ None of this is captured by the fuzzing, so we will be underestimating the total noise contribution to fluctuations if this is important
+ Possible solution:
  + Take FFT of image
  + Look for peak at (6, 5) in k-space and interpolate it away
  + Take iFFT to get back to the image
*** TODO [#C] Improve continuum subtraction in extracting lines
+ Some lines such as O II 4650 complex need more attention
+ Need more flexible sizing of line and continuum windows
*** TODO [#B] Calculate maps line-of-sight depth of emission zones for different ions
+ Once we know the Ne, Te (and assuming known elemental abundances)
+ And once we have extinction-corrected surface brightness maps
*** TODO [#C] Fit Gaussians to blended lines in MUSE data
+ Only way to get the [Ar IV] density
+ Would also help with the O II lines
*** Write up WFC3 calibration material
+ This will be in an appendix
+ We already have the figures sorted
+ Copy material from the original draft of the paper
*** TODO Reorganise Latex documents
+ Split out the future papers stuff into another document
+ Split out the source code stuff into another document
*** TODO Include color velocity maps somewhere
+ E.g. this figure
  + [[file:~/Work/BobKPNO/2004/multi-panel-isovel-oiii-nii.pdf]]
*** TODO Write up Dust extinction complications stuff
+ Show all the different reddening indicators
  + Balmer decrement
  + Paschen decrements
  + Balmer-Paschen decrement
    + This is the longest wavelength range (if we used 4861 to 9229)
    + With 6563/9229 we have
      + 1.41 factor in ratio
      + 
  + [Ar III] and [O III] ratio
    + Small wavelength range, but high S/N and rock solid intrinsic ratio
    + [Ar III] 7751/7136 is 9% change in wavelength
      + 15% change in ratio between SW cloud and HH 202 region
    + [O III] 5007/4959 is a 1% change in wavelength
      + 1% change in ratio between SW cloud and HH 202 region
**** STARTED Theoretical treatment of reddening, extinction, scattering  
:LOGBOOK:
- Note taken on [2015-11-09 Mon 13:04] \\
  Wrote this when I should have been working on other things!  And I am sure I have done it before - look for an evernote note somewhere, or maybe handwritten in my notebooks
:END:
+ Simple absorbing screen
  + Observed flux F'(\lambda) = F(\lambda) exp(-\tau(\lambda)) 
  + \tau(\lambda) = \beta(\lambda) \tau(V)
    + where V is the V-band (5500 \AA say) and \beta(\lambda) is the extinction curve, normalised to 1 at 5500 \AA
  + A(\lambda) = -2.5 log_{10 }(F'(\lambda) / F(\lambda)) = 1.0857 \beta(\lambda) \tau(V)
  + E(\lambda_{1}-\lambda_{2}) = A(\lambda_{1}) - A(\lambda_{2}) = 1.0857 \tau(V) [\beta(\lambda_{1}) - \beta(\lambda_{2})] 
+ Double absorbing screen - sandwich model
  + Foreground screen with depth \tau_{1} then a front emitting layer with fraction \xi of total flux, then midground screen with depth \tau_{2}, then back emitting layer with (1-\xi) fraction of flux   
  + Observed flux F'(\lambda) = F(\lambda) exp(-\tau_{1}(\lambda)) [ \xi  + (1-\xi) exp(-\tau_{2}(\lambda)) ]
  + Or, putting \tau = \tau_{1} + \tau_{2} we can write it as
    + F'(\lambda) = F(\lambda) exp(-\tau(\lambda)) { 1 + \xi [exp(\tau_{2}(\lambda)) - 1] }
    + So A(\lambda) = 1.0857 \beta(\lambda) \tau(V) - 2.5 log_{10 }(1 + \xi [exp(\tau_{2}(\lambda)) - 1] )
    + A(\lambda) = 1.0857 { \beta(\lambda) \tau(V) - ln(1 + \xi [exp(\tau_{2}(\lambda)) - 1]) }
  + For small \tau_{2}, A(\lambda) = 1.0857  \beta(\lambda) {\tau(V) - \xi \tau_{2}(V)}, so the wavelength dependence is still \prop \beta(\lambda) and reddening still looks the same
  + But for large \tau_{2} \gg \tau_{1}, the apparent extinction saturates since only the front emitting layer is detected
    + E.g., if \tau_{1} = 0 so \tau = \tau_{2} then A(\lambda) saturates at -2.5 log_{10 }\xi as \tau \to \infty
    + Since this is independent of wavelength, then the reddening tends to zero in this case
  + This can explain why E(Hb-Ha) drops for high values of E(Ha-Pa9) - 
+ Alternative - dust fully mixed with gas
  + Will give similar result
  + Use formal solution to radiative transfer with constant source function
    + Although really S \propto N since emission goes as N^2 and absorption goes as N
+ And the scattering, of course - which makes things even more complicated
*** TODO Write up the CEL-ORL T indicator stuff for O++
+ Even though this is not for the current paper, I don't want to forget about it and it would be good to get Manuel's input
*** TODO [#B] Velocity patterns at local i-fronts
**** Discontinuities in peak velocity
+ For low ionization lines, I think these are mainly caused by internal extinction in the nebula (opaque obstacle)
**** Write up the simple theory from my evernote note
+ [[https://www.evernote.com/shard/s36/nl/1035026487/bc8a1634-3a50-4d87-b1c3-28e307dcc371/][Photo of blackboard]]
*** Write about plane-of-sky t^2 theory
+ Suppression of fluctuations on scales smaller than LOS depth
* TODO Important things to follow up
** 

** TODO [#A] Remove the sky components
This is very important for the weak lines
** [Fe III] 5270
+ This shows lots of wonderful structure in the jet source regions
  + HH529 and counterjet?
+ Also strong in NW extension of HH202
+ Shows jet that can be maybe linked with HH203/204
+ Our WFC3 469N filter shows a small field of this around Orion S
+ MUSE spectrum starts at 4595, so we should also have [Fe III] 4702, 4658, which are of similar brightness to 5270, plus a host of weaker ones - see the Manuel notes.
  + Yes, they are seen - 4658 is the best
** O I 5577
+ Dominated by sky
  + Need to subtract it in square sections
  + Calculate histogram of values for each tile, and take the histogram peak as the sky value
+ Has some interesting point sources - presumably proplyd disks, but also HH201
+ Also diffuse emission from Orion S and Bar
+ Ratio 5577/6300 should be T-sensitive
** [N I] 5199
+ Spatial distribution confirms fluorescent origin
+ Very bright in proplyds
+ But why is it absent in HH 203 and weak in 204 - also absent in 202
  + But strong in 201
** [Fe II] lines
+ These are varied
+ 5262 looks like fluorescence in PDR
+ 7453 looks like collisionally excited at IF
+ 8617 (strongest) looks intermediate between the two (8616.9498 a4F-a4P 9/2-5/2)
  + Also 8892 must also be [Fe II], although I had initially classified it as Ne I
  + Intensity map looks very similar to 8617
  + Velocity is more consistent with [Fe II] 8891.9283 7/2-3/2 than with Ne I 8892.22
  + They are in same a4F-a4P multiplet, which also provides IDs for 2 of my XXX lines!
    + 9033.49 5/2-1/2, which may be density indicator with 8891.93 and 8616.95
    + 9267.55 3/2-1/2 likewise (they both have J_k = 1/2)
  + The remaining multiplet members are in blends
    + 9051.95 7/2-5/2 is blended with Ca I] 9052.16
      + It shares an upper level with 8617 so should have intensity that is 4.9/19 = 0.258 times smaller (after de-reddening: 5% wavelength change)
    + 9226.63 5/2-3/2 is blended with H I Pa 9 9229.01
      + *Needs to be removed for width analysis*
      + Shares upper level with 8892, so we can use that
      + Intrinsic intensity ratio 9227/8892 = 6.90E-03/1.10E-02 = 0.627
      + Wavelength change is ~ 4% but maybe should be dereddened

** Si II lines
+ Extremely varied
+ Combination of recomb and fluorescence
+ Or perhaps fluorescence with different opacities
  + So some fluoresce in the ionized gas, and some in the neutral
+ There are linear features seen in 6371 and nowhere else

** O II complex at 4650
+ 4649 and 4651 are severely blended
  + Disentangling these is vital for getting an O II density diagnostic
+ We have to sum over a large area to get enough s/n to fit for all the O II components
+ We could maybe use the mean wavelength of the 4649+51 blend as a proxy for the 4649/51 ratio, but we would have to correct for the kinematics, using perhaps [O III] or, better yet, an unblended line of the same multiplet
  + But the only one is  4676 and that is too weak
  + We can't really use 4639+42 because that is blended with N II 4643 and N III 4641
+ [2015-11-03 Tue 19:53] O II 4676 in the same V1 multiplet is well isolated and produces the best O II map so far
** O I 8446 multiplet
+ This is way brighter than the bluer O I lines
+ Excellent for tracing kinematics of neutral gas
** [C I] 8727.13
+ This has a different morphology than anything else!
+ Redshifted filament pointing down SSW from Orion S
  + This must be collisionally excited in the neutral gas
+ There is also a diffuse component that seems to come from the PDR
  + Seen beyond the Bright Bar for instance
+ It looks like we are oversubtracting the emission from a fluorescent line
  + We are already avoiding the red side, so we need to improve the continuum fitting algorithm before we can resolve this

*** TODO Quick fix to the [C I] line
+ We can add back in a fraction of the [N I] 8703 line to compensate for the [N I] 8719 line that got in the continuum band
#+BEGIN_SRC python
import os
from astropy.io import fits
DD = os.path.expanduser('~/tmp/musedata')
FACTOR = 1.0

fn_c = os.path.join(DD, 'linesum-C_I-8727-bin016.fits')
fn_n = os.path.join(DD, 'linesum-N_I-8703-bin016.fits')

hdu_c = fits.open(fn_c)['SCALED']
hdu_n = fits.open(fn_n)['SCALED']

hdu_c.data += FACTOR*hdu_n.data

hdu_c.writeto(fn_c.replace('linesum', 'linesum-corr'), clobber=True)


#+END_SRC

#+RESULTS:
: None

** [Cl IV] 8045.62
+ The highest ionization line
+ Traces very interior gas, and also inner edge of ORL clump
+ Very strong from LV1 bowshock
** [Ar III] 7135.78
+ This is excellent for velocity mapping
+ The velocity resolution is better at longer wavelengths
+ You can see blue-shifted and red-shifted flows easily
** Paschen lines 
Doing the ratio with Ha would be good for reddening curve
*** Comparing Hb/Ha with Paschen/Balmer
:PROPERTIES:
:ID:       236AC762-7034-42E9-83BC-754A68346A23
:END:
The reddenings are very similar, except for two things:
1. Some very opaque filaments show up as reddening in 9229/6563, but minima in reddening in 4861/6563 (and high extinction in Ha-radio)
   - I'm thinking this could be due to blocking all the light behind in 6563 and 4861, so being dominated by the foreground extinction
   - Whereas not totally opaque at 9229 (but extinction curve is not /that/ steep, is it?)
2. Thin strip on neutral side of bar has increased Hb/Ha reddening but barely visible in 9229/6563 - and has /negative/ Ha-radio estinction in parts
   - This must be scattering!
   - Multiple scattering so that it is red rather than blue
   - No real H+ emission, so not see in radio, leading to negative Ha-radio extinction
** Ca II permitted lines in HST3 170-337
+ This is a proplyd with redshifted jet
+ It has components that look like they are blue wings of some Paschen lines
  + But they can't be because only some Pa lines have them
  + Instead they must be something else
  + 8495, 8538, 8658
  + Turns out that they are Ca II lines, and these are well-known in T Tauri stars
    + EW(Ca II) correlates with mass accretion rate
    + Moto'oka and Itoh (2015)
    + Looking at the full-res cube, this is restricted to the star - not extended
    + Also seen in many other young stars/proplyds
      + E.g., LV2, LV5, LL Ori and many more
      + Even mentioned in the Weilbacher paper
+ Also red component to [S III] 9069
+ In blue end of spectrum He I lines at 4921 and 5016 show a red component
+ Also 5167, 5183, 5197, 5231 unidentified lines
  + plus other weaker ones
  + These may well be photospheric
+ Strong [N II] 5755 but it is not redshifted
+ C II (?) 5890 line shows up maybe
  + But wav doesn't quite match
  + Could be unidentified lines at 5887 and 5894
+ More lines at 6135, 6147, 6240, 6245 - very weak
+ More lines at 6430, 6453, 6514
** Weaker lines that might be interesting
+ Ne I 8892.22 - similar to O I
+ Ca I] 9052.16 but 9095.09 is missing so maybe something else
+ [O I] 5577.31 need to remove sky line but then there are some interesting little spots like HH 201
+ 5906 very weak line - I had classified it as Si I 5906.22, 5906.15, 5906.418, 5906.92 but this seems very unlikely since it is not seen in any of the low-ionization parts, only near the Trapezium, most strongly in the SW compact bar
** Using the absorption lines
:PROPERTIES:
:ID:       29ACCF8C-F49A-4FEB-8374-DC19BB20048E
:END:
+ The trouble here is that many of the best He II lines are bluer than the spectral range
+ He II 4686 works well
  + Deepest in th2A
  + One problem is that it is phase-dependent in th1C
+ He II 5411 has some potential, but is contaminated by [Fe III]
  + This is now fixed here: [[id:6E7A33A7-0822-42C0-9F1D-7A5E8A4DD732][Correcting the He I 5411 absorption line for {Fe III} emission]]
+ O II 4650 is seen in absorbtion right on th2A, but in the nebula it is swamped by the ORL emission lines
+ C IV 5801.35, 5811.97 are clearly seen in th1C spectrum and much weaker in th2A, absent in other trapezium stars
  + Unfortunately, they are very weak in the nebula
  + Requires integration over 15x15 arcsec box to have much s/n
+ N III 6633.9 is very interesting
  + [2019-05-11 Sat 22:18] *Look for molecular ID*
    + /Conclusions:/ Nothing useful
    + Use JPL database
      + https://spec.jpl.nasa.gov/ftp/pub/catalog/catform.html
      + That is useless - does not cover optical wavelengths
    + HITRAN is better
      + https://hitran.org/lbl/
    + Requires frequency or wavenumber
      |   \lambda, \AA | \lambda(Vac) |   \nu, GHz | wavenumber, cm^-1 |
      |--------+--------+----------+-------------------|
      | 6633.5 | 6635.4 | 4.5181e5 |          1.5071e4 |
      | 6634.5 | 6636.4 | 4.5174e5 |          1.5068e4 |
      |--------+--------+----------+-------------------|
      |   6000 | 6001.8 | 4.9950e5 |          1.6662e4 |
      |   7000 | 7002.0 | 4.2815e5 |          1.4282e4 |
      #+TBLFM: $2=(1.0 + 1e-6*(287.6155 + 1.62887/($1/1e4)**2 + 0.01360/($1/1e4)**4)) $1 ; f1::$3=$c / $2 $Ang $GHz; s5::$4=1 / $2 $Ang ; s5
    + Air \to vac factor = 1.00029
    + There are H_2 O lines at 15067.8706 cm^-1 and 15071.70
    + But there are other H_2 O lines that are 100 times stronger at other wavelengths
      + For instance 14400 cm^-1 = 6944 \AA
      + And 15450 = 6473 \AA
    + There is an H_2 transition at 15021.905 Hz = 6657 \AA = 6655 \AA in air
      + So that is a long way from the right wavelength
      + There are weaker ones that are closer, but nothing looks promising
    + Strength S is in units of cm^-1 / (mol cm^-2)
      + cm^-1 = n \sigma
      + (mol cm^-2) =  n z
      + So these units are strange
  + [2015-11-03 Tue 19:35] *New info*
    + Now I have made a map of this line, and it is amazing
    + It can't be scattered continuum - I think it is foreground absorption
    + Which means it probably isn't N III
    + [X] Now I am going to calculate the EW
  + Has absorption depth of 0.08 in Orion S region
  + But not seen in any OB stars 
  + Seen in th1E, which is G2V spectral type
    + (which Olivares et al 2013) say is not bound to Trapezium
    + And is also eclipsing binary (Morales-Calderón et al 2012)
    + But absorption depth there is only 0.05
  + Also seen in th2B
    + This is the brightest star that shows the feature
    + T=29000., g=4.1, L=4.11
    + B0.5V, which is ostensibly the same as th1A and th1D
  + Also seen in star 180-245
  + Conclusion must be that we are seeing scattered light from an embedded yellow supergiant that is leaking out.
    + *No longer believe this*
  + Some T Tauri stars show a Cr I line at 6630 but that has a very low EW ~0.01 A (Apenzeller et al 1986, Table III)
  + There are also lines around 6480 and 6490 in the nebular scattered light
    + Some stars show a strongish line around 6495
    + th1A and th1D show the 6480 line but only at about the 3% level (this can be seen in Fig 2 of Simon-Diaz)
    + Even th1C shows a tiny hint of it

** DONE Looking at the strange broad NIR emission bump
CLOSED: [2015-08-13 Thu 11:15]
+ *NO - This is just a second order Balmer line - see their paper!*
+ Take the difference or ratio between 8570 A and 8552 A
+ Results are very disappointing
  + We see a vague form of the nebula in the ratio image
  + It looks similar to the continuum image, but not exactly the same
  + It doesn't look much like scattered continuum
  + And there is this instrumental tartan pattern superimposed on it
  + And it is also very noisy
  + Certainly not worth bothering with
  + Ratio image is even worse
#+BEGIN_SRC python :results output
  from astropy.io import fits
  import numpy as np

  cubehdu, = fits.open('muse-hr-data-wavsec6.fits')
  continuum = np.nanmean(cubehdu.data[441:446], axis=0)
  bump = np.nanmean(cubehdu.data[455:471], axis=0)
  fits.PrimaryHDU(header=cubehdu.header, data=bump-continuum).writeto('bump8600-diff.fits', clobber=True)
  fits.PrimaryHDU(header=cubehdu.header, data=bump/continuum).writeto('bump8600-ratio.fits', clobber=True)
#+END_SRC

#+RESULTS:

** Longer wavelength lines
7492
| 7001.92 | O I      | 3 |                          |
| 7002.23 | O I      | 3 | blend                    |
| 7065.28 | He I     | 2 |                          |
| 7135.78 | [Ar III] | 1 | super strong             |
| 7155.14 | [Fe II]  | 4 |                          |
| 7231.34 | C II     | 3 |                          |
| 7236.42 | C II     | 3 |                          |
| 7254.15 | O I      | 3 | Also 7254.45, 7254.53    |
| 7281.35 | He I     | 3 |                          |
|  7290.3 | ?        | 4 | possibly [Fe II]         |
| 7318.39 | [O II]   | 1 | Also 7319.99             |
| 7329.66 | [O II]   | 1 | Also 7330.73             |
| 7377.83 | [Ni II]  | 4 |                          |
| 7411.61 | [Ni II]  | 5 |                          |
| 7442.30 | N I      | 5 |                          |
| 7452.54 | [Fe II]  | 4 |                          |
| 7468.31 | N I      | 4 |                          |
|---------+----------+---+--------------------------|
| 7751.10 | [Ar III] | 1 |                          |
| 7816.13 | He I     | 4 |                          |
| 7890.07 | Ca I]    | 4 |                          |
|    7900 | Sky      | 4 | Lots of sky lines        |
|    8000 | Sky      | 4 | in this spectral         |
| 8045.62 | [Cl IV]  | 4 | HIGH IONIZATION!         |
|    8100 | Sky      | 4 | range                    |
|---------+----------+---+--------------------------|
|    8189 | Fe I?    | 4 | ID uncertain             |
| 8200.36 | N I?     | 5 | very weak                |
| 8210.72 | N I      | 5 |                          |
| 8216.34 | N I      | 4 |                          |
| 8223.14 | N I      | 4 | Strongest component      |
|    8243 | ?        | 4 | O I? or Fe II?           |
|   8240+ | H I      | 4 | Lots of Paschen lines    |
| 8437.96 | H I      | 3 | Pa 18                    |
| 8446.36 | O I      | 2 | And 8444.25, 8444.76--   |
| 8467.25 | H I      | 2 | Pa 17                    |
| 8502.48 | H I      | 2 | Pa 16                    |
| 8545.38 | H I      | 2 | Pa 15                    |
| 8578.69 | [Cl II]  | 3 |                          |
| 8598.39 | H I      | 2 | Pa 14                    |
|    8600 | Bump?    | 4 | second order             |
| 8616.95 | [Fe II]  | 3 |                          |
| 8665.02 | H I      | 2 | Pa 13                    |
| 8680.28 | N I      | 4 | Strongest component      |
| 8683.40 | N I      | 4 |                          |
| 8686.15 | N I      | 4 |                          |
| 8703.25 | N I      | 4 |                          |
| 8711.70 | N I      | 4 |                          |
| 8718.83 | N I      | 5 | very weak                |
| 8727.13 | [C I]    | 4 | Different!               |
| 8733.43 | He I     | 5 | very weak                |
| 8750.47 | H I      | 2 |                          |
|---------+----------+---+--------------------------|
| 8862.79 | H I      | 2 |                          |
| 8892.22 | Ne I     | 4 |                          |
| 8996.99 | He I     | 5 |                          |
| 9014.91 | H I      | 2 | Pa 10                    |
|    9032 | ?        | 5 | low ionization shocks    |
| 9052.16 | Ca I]    | 5 |                          |
| 9068.90 | [S III]  | 1 |                          |
| 9095.09 | Ca I]    | 5 |                          |
| 9123.60 | [Cl II]  | 4 |                          |
| 9204.17 | Co I     | 5 | but looks low ionization |
| 9210.28 | He I     | 4 |                          |
| 9229.01 | H I      | 2 | Pa 9                     |
|    9267 | ??       | 5 | only in shock knots      |



* Extracting individual emission lines from MUSE cube

** [2016-12-24 Sat] Revisiting the line extraction
This is based on the [[file:~/Dropbox/orion-widths/line-all-wav-grid.pdf][postage-stamp plot]] I have made in the [[id:1F9D411C-9C16-4F18-AB96-103DC86F80D9][linewidths project]]
+ [X] We have added a few new lines (marked with "*") in the table
+ [X] Refined some of the choices about blue and red continuum
+ [ ] Extract the 1D spectrum in different regions for different lines
  + Try and choose regions where EW is maximised for each class of
    line separately
  + Previously it was just the slice [900:1400] in X and [400:900] in Y for all lines, which is not ideal


*** Choosing the extraction regions for different classes of line
:PROPERTIES:
:TABLE_EXPORT_FILE: line-classes.tab
:TABLE_EXPORT_FORMAT: orgtbl-to-tsv
:END:

#+name: line-classes
| Class         | Code | Line ID    | Bin |    EW | Linesum |
|---------------+------+------------+-----+-------+---------|
| Ultra         | U    | Ar_IV-4740 |  16 |   0.6 |    2000 |
| Permitted     | P    | C_II-7236  |  16 |   3.5 |    5000 |
| Di-electronic | D    | C_II-7236  |  16 |   3.5 |    5000 |
| High          | H    | O_III-5007 |  16 |   850 |     3e6 |
| Moderate      | M    | O_II-7318  |  16 |    70 |   1.5e5 |
| Low           | L    | O_I-8446   |  16 |    25 |     3e4 |
| Abs PDR       | AP   | N_III-6634 |  64 | -0.16 |    -600 |
| Abs O9        | A9   | He_II-4686 |  32 | -0.23 |   -1500 |
| Abs 07        | A7   | C_IV-5812  | 128 | -0.07 |    -150 |
| Abs DIB       | A0   | DIB-5781   | 128 | -0.15 |    -300 |

+ [2017-10-24 Tue] Added di-electronic class
  + Just copied the one for permitted lines


**** Create masks for each line class
+ Take =AND= of thresholds in EW and Line Flux
+ The do a bit of dilate/expand to eliminate noise islands

#+BEGIN_SRC python
  import os
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from skimage.morphology import binary_dilation, binary_erosion, square, disk


  table = Table.read('line-classes.tab', format='ascii.tab')
  D = 'LineMaps'
  for row in table:
      mask_name = 'mask-line-class-{}.fits'.format(row['Code'])
      map_suffix = '{}-bin{:03d}.fits'.format(row['Line ID'], row['Bin'])

      # Factor s is +1 for emission line, -1 for absorption line
      s = row['Linesum']/abs(row['Linesum'])

      bname =  os.path.join(D, 'linesum-' + map_suffix)
      bhdu = fits.open(bname)['SCALED']
      bmask = s*bhdu.data >= s*row['Linesum']

      ename = os.path.join(D, 'ew-' + map_suffix)
      ehdu = fits.open(ename)['SCALED']
      emask = s*ehdu.data >= s*row['EW']

      mask = emask & bmask

      # Reduce to natural size
      n = row['Bin']
      mask = mask[::n, ::n]
      # Eliminate 1-pixel islands
      mask = binary_erosion(mask)
      # Then spread out a bit
      mask =  binary_dilation(mask, disk(3.5))
      # Expand back to original size
      mask = np.kron(mask, square(n))

      fits.PrimaryHDU(
          header=bhdu.header,
          data=mask.astype(np.uint8)
      ).writeto(
          os.path.join(D, mask_name),
          clobber=True,
      )

#+END_SRC

#+RESULTS:
: None

**** Ultra high ionization
+ Ar IV is the obvious choice here
**** Permitted metal ++ lines
+ May be recombination or fluorescence
+ C II 7236 is the strongest
**** High ionization
+ Use [O III] 16x16 binning
  + ew-O_III-5007-bin016 > 850
  + AND linesum-O_III-5007-bin016 > 3e6
**** Moderate ionization

**** Low ionization


**** These are all the ones we looked at last time 
#+BEGIN_SRC sh
  D=/Users/will/Dropbox/OrionMuse/LineMaps
  xpaset -p muse fits $D/ew-O_III-5007-bin004.fits
  xpaset -p muse fits $D/ew-N_II-5755-bin004.fits 
  xpaset -p muse fits $D/ew-Ar_IV-4740-bin004.fits
  xpaset -p muse fits $D/ew-Ar_IV-4740-bin016.fits
  xpaset -p muse fits $D/ew-Ar_IV-4740-bin064.fits
  xpaset -p muse fits $D/ew-O_I-8446-bin004.fits
  xpaset -p muse fits $D/ew-H_I-9229-bin004.fits 
  xpaset -p muse fits $D/ew-He_I-5876-bin004.fits 
  xpaset -p muse fits $D/ew-C_II-5890-bin016.fits 
  xpaset -p muse fits $D/ew-C_II-7236-bin004.fits 
  xpaset -p muse fits $D/ew-S_III-9069.fits 
  xpaset -p muse fits $D/ew-Ar_IV-4740-bin032.fits
  xpaset -p muse fits $D/ew-O_II-7318-bin001.fits 
  xpaset -p muse fits $D/ew-O_III-5592-bin016.fits 
  xpaset -p muse fits $D/ew-O_III-5592-bin064.fits 
  xpaset -p muse fits $D/ew-N_I-5199-bin016.fits 
  xpaset -p muse fits $D/ew-O_III-4959.fits 
  xpaset -p muse fits $D/ew-Ar_IV-4740-bin016.fits
#+END_SRC

*** Correcting the He I 5411 absorption line for [Fe III] emission
:PROPERTIES:
:ID:       6E7A33A7-0822-42C0-9F1D-7A5E8A4DD732
:END:
:LOGBOOK:
CLOCK: [2017-01-03 Tue 10:50]--[2017-01-03 Tue 10:50] =>  0:00
:END:
#+BEGIN_SRC python
from astropy.io import fits
hdu, = fits.open('LineMaps/linesum-Fe_III-5412.fits')
hdu2, = fits.open('LineMaps/linesum-Fe_III-5270.fits')
hdu.data -= 0.1*hdu2.data
hdu.writeto('LineMaps/linesum-He_II-5411.fits', clobber=True)
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC sh
cp LineMaps/continuum-Fe_III-5412.fits LineMaps/continuum-He_II-5411.fits
python multibin-map.py LineMaps/linesum-He_II-5411.fits
python multibin-map.py LineMaps/continuum-He_II-5411.fits
#+END_SRC

#+RESULTS:
| Saving | LineMaps/continuum-He_II-5411-bin001.fits |
| Saving | LineMaps/continuum-He_II-5411-bin002.fits |
| Saving | LineMaps/continuum-He_II-5411-bin004.fits |
| Saving | LineMaps/continuum-He_II-5411-bin008.fits |
| Saving | LineMaps/continuum-He_II-5411-bin016.fits |
| Saving | LineMaps/continuum-He_II-5411-bin032.fits |
| Saving | LineMaps/continuum-He_II-5411-bin064.fits |
| Saving | LineMaps/continuum-He_II-5411-bin128.fits |
| Saving | LineMaps/continuum-He_II-5411-bin256.fits |

#+BEGIN_SRC sh
  for file in LineMaps/linesum-He_II-5411-bin???.fits; do
      python muse-ew.py $file
  done
#+END_SRC

#+RESULTS:


** Sky lines
:LOGBOOK:
CLOCK: [2017-01-04 Wed 22:48]--[2017-01-05 Thu 00:11] =>  1:23
CLOCK: [2017-01-03 Tue 10:50]--[2017-01-03 Tue 12:05] =>  1:15
:END:
+ The OH and O_{2} sky lines are important for two main reasons:
  1. POSITIVE: They allow us to do accurate wavelength calibration and determine instrumental width as function of wavelength
  2. NEGATIVE: They blend with some of the lines, so need to be subtracted or otherwise taken account of
+ There are also night-sky contributions to some of the nebular lines, particularly [O I], [N I], but also maybe [N II] and others
+ We will pursue the problem via a combination of two approaches :
  1) Using the line lists from Osterbrock et al (1996)
     + This has all the OH and O_{2} lines at a resolution that is good enough to calculate mean wavelengths and sigmas for multiplets that we do not resolve
     + The tables give the wavelengths, but not the relative intensities, although those are apparent in the figures
     + We will have to assume that the relative-intensities-within-a-blend in the MUSE observations are the same as in Osterbrock 
  2) By making spectra of regions at periphery of the Orion field
     + These will be mainly sky, except for the strongest lines, which will have a contribution from the extended nebula and the diffuse galactic emission

*** Extract table of source and sky spectra from binned data cubes
#+BEGIN_SRC python :results file :return outfile 
  import os
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy.table import Table
  from astropy import units as u
  import numpy as np

  outfile = 'full-spectrum-by-area.tab'
  N = 16
  D = 'BigFiles'
  fmt = 'muse-hr-data-wavsec{0:d}-rebin{1:d}x{1:d}.fits'

  # Areas on the map where we want to extract the spectrum
  areas = {
      # Python axis order for FITS cube is
      # (Z, Y, X) = (wavelength, Dec, RA)
      'all': [slice(None, None), slice(None, None), slice(None, None)],
      # Take sky samples from 10x10 squares in top left and bottom right 
      'sky-ne': [slice(None, None), slice(-10, -1), slice(0, 9)],
      'sky-sw': [slice(None, None), slice(0, 9), slice(-10, -1)],
      'orion-s': [slice(None, None), slice(40, 50), slice(60, 70)],
      'hh-202': [slice(None, None), slice(60, 64), slice(80, 83)],
      'lv1': [slice(None, None), slice(50, 53), slice(54, 56)],
      'lv6': [slice(None, None), slice(47, 51), slice(59, 65)],
      'big-arc': [slice(None, None), slice(28, 35), slice(49, 59)],
      'bar-ifront': [slice(None, None), slice(27, 30), slice(29, 33)],
      'hh-203': [slice(None, None), slice(20, 32), slice(30, 31)],
  }

  formats = {'wavelength': '%.2f'}
  results = {'wavelength': []}
  for k in areas:
      results[k] = []
      formats[k] = '%.6e'


  for iwavsec in range(8):
      fn = fmt.format(iwavsec, N)
      hdu = fits.open(os.path.join(D, fn))[0]

      w = WCS(hdu.header)
      nv, ny, nx = hdu.data.shape

      _, _, wavs = w.all_pix2world([0]*nv, [0]*nv, np.arange(nv), 0)
      results['wavelength'].extend(wavs*u.m/u.AA)

      for area, area_slice in areas.items():
          spectrum = np.nanmean(hdu.data[area_slice], axis=(1, 2))
          results[area].extend(spectrum)

  Table(results).write(outfile, format='ascii.tab', formats=formats)
#+END_SRC

#+RESULTS:
[[file:full-spectrum-by-area.tab]]


*** Plot the sky and source spectra
:LOGBOOK:
CLOCK: [2017-01-05 Thu 11:18]--[2017-01-05 Thu 13:25] =>  2:07
:END:
#+BEGIN_SRC python :results file :return plotfile
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.ticker import (MultipleLocator, LogLocator, 
				 MaxNLocator, FormatStrFormatter)
  import seaborn as sns

  wavmin, wavmax = 4580, 9380
  NSECTIONS = 6
  SCALE = 1e6
  dwav = (wavmax - wavmin)/NSECTIONS
  plotfile = 'full-sky-spectrum.pdf'
  VHEL = -16.217273731

  sns.set(style='whitegrid', font_scale=1.0, color_codes=True)
  fig, axes = plt.subplots(NSECTIONS, 1,
                           figsize=(16, 20), sharey=True)
  # Leave more height between plots (hspace), but otherwise reduce the margins
  plt.subplots_adjust(bottom=0.06, top=0.99, left=0.06, right=0.99, hspace=0.35)

  startwavs = np.linspace(wavmin, wavmax, NSECTIONS, endpoint=False)

  tab = Table.read('full-spectrum-by-area.tab', format='ascii.tab')

  chosen_spectra = {
      'big-arc': {'label': 'Big Arc', 'color': 'b'},
      'orion-s': {'label': 'Orion S', 'color': 'r'},
      'hh-203': {'label': 'HH 203', 'color': 'm'},
      'lv6': {'label': 'Trapezium', 'color': 'y'},
      'bar-ifront': {'label': 'Bright Bar', 'color': 'c'},
  }

  # What we have to multiply the NE sky spectrum by before subtracting
  # it from the source spectrum
  sky_factor_default = 0.75
  sky_factors = {}

  oh_tab = Table.read(
      'SkyLines-Osterbrock96/oh.dat',
      format='ascii.cds',
      readme='SkyLines-Osterbrock96/ReadMe'
  )
  o2_tab = Table.read(
      'SkyLines-Osterbrock96/o2.dat',
      format='ascii.cds',
      readme='SkyLines-Osterbrock96/ReadMe'
  )
  # Sky lines are at 0 km/s topocentric, so need correcting for the
  # heliocentric frame
  oh_tab['lambda'] *= (1.0 + VHEL/2.99792458e5)
  o2_tab['lambda'] *= (1.0 + VHEL/2.99792458e5)

  neb_tab = Table.read('basic-line-list.tab', format='ascii.tab')
  neb_label_kwds = {
      1: {'fontsize': 7, 'bbox': {'facecolor': 'w', 'alpha': 0.8}},
      -1: {'fontsize': 5, 'color': 'w', 'bbox': {'facecolor': 'k', 'alpha': 0.4}},
  }


  for startwav, ax in zip(startwavs, axes.flat):
      ax.fill_between(tab['wavelength'], 4*tab['sky-ne']/SCALE,
                      alpha=0.2, color='k', label='4 x Sky')
      for spectrum, plot_kws in chosen_spectra.items():
          sky_fac = sky_factors.get(spectrum, sky_factor_default)
          ax.plot(tab['wavelength'],
                  (tab[spectrum] - sky_fac*tab['sky-ne'])/SCALE,
                  lw=1, alpha=0.7, **plot_kws)
      wavmin, wavmax = startwav - 0.01*dwav, startwav + 1.01*dwav

      # Rug plots of OH and O_2 sky lines
      for wav in oh_tab['lambda']:
          if wavmin <= wav <= wavmax:
              ax.axvline(wav, ymin=0.0, ymax=0.06, color='m', lw=0.5, alpha=0.6)
      for wav in o2_tab['lambda']:
          if wavmin <= wav <= wavmax:
              ax.axvline(wav, ymin=0.0, ymax=0.04, color='k', lw=0.5, alpha=0.6)

      # Inverted rug plot of nebular lines
      for neb in neb_tab:
          if wavmin <= neb['wav0'] <= wavmax:
              neblabel = '{} {:.0f}'.format(neb['Ion'], neb['wav0'])
              ax.axvline(neb['wav0'], ymin=0.1, ymax=1.0, color='r', lw=0.5, alpha=0.6)
              ax.text(neb['wav0'], 2.6, neblabel,
                      ha='center', va='center', rotation='vertical',
                      **neb_label_kwds[np.sign(neb['strength'])])
      ax.set(
          xlim=[wavmin, wavmax],
          ylim=[0.0, 2.9],
      )
      ax.xaxis.set_major_locator(MaxNLocator(52, integer=True, prune='both'))
      ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))
      ax.yaxis.set_major_locator(MaxNLocator(3, integer=True, prune='both'))
      ax.yaxis.set_major_formatter(FormatStrFormatter('%d'))

  axes[-1].set(
      xlabel='Wavelength, Angstrom',
      ylabel='Mean brightness',
  )
  axes[2].legend(ncol=2, loc='upper right')
  fig.savefig(plotfile)

#+END_SRC

#+RESULTS:
[[file:full-sky-spectrum.pdf]]

*** Make a curated list of sky lines to use
:LOGBOOK:
CLOCK: [2017-01-05 Thu 00:11]--
:END:
+ These will be lines we have identified on the sky spectrum which satisfy the following criteria:
  1. Not also nebular lines 
  2. Have wavelengths and appoximate intensities from Osterbrock 1996
     + (so either OH or O_{2})
  3. Well-isolated enough to extract moment maps of with the usual techniques
     + But this need not be hard and fast, since we could try and fit Gaussians to a bunch of lines at once maybe
+ We want a good coverage in wavelength
+ Then we will use them in the orion-widths project to try and determine the instrumental profile as a function of wavelength
+ And we will investigate how well we can determine the \sigma of multiplet splitting
+ We will start at the red end, since that seems easier
**** 9300 \to 9500 \AA
+ This range has a lot of strong sky lines
+ /But/ there is also strong absorption of the continuum here, which makes the spectrum hard to interpret
+ So we will ditch it for now
**** 8750 \to 9000 \AA
+ This range has a lot of strong OH lines
+ Some of them are well separated from any nebular lines
|   |
|   |



*** Cross correlating with Osterbrock's lists

+ [X] Obtained tables from Vizier
+ [X] Saved them to ascii files
  + O_{2} lines :: [[file:SkyLines-Osterbrock96/o2.dat]]
  + OH lines :: [[file:SkyLines-Osterbrock96/oh.dat]]
+ [X] Check the files can be read
  + Open with 
    : astropy.Table.read(..., format='ascii.cds', readme=...)

#+BEGIN_SRC python :results output
  from astropy.table import Table

  tab = Table.read(
      'SkyLines-Osterbrock96/o2.dat',
      format='ascii.cds',
      readme='SkyLines-Osterbrock96/ReadMe'
  )

  print(tab)
#+END_SRC

#+RESULTS:
#+begin_example
 lambda Trans 
 0.1 nm       
------- ------
     -- rQ(21)
8609.98  R(21)
8610.57 rQ(19)
     --  R(19)
     -- rQ(17)
     --  R(17)
8615.56 rQ(15)
8617.15  R(15)
     -- rQ(13)
8619.95  R(13)
    ...    ...
8680.17 pQ(15)
8681.59  P(15)
 8685.9 pQ(17)
 8687.3  P(17)
8691.81 pQ(19)
8693.22  P(19)
     -- pQ(21)
     --  P(21)
8704.22 pQ(23)
8705.61  P(23)
Length = 45 rows
#+end_example

+ We will now test the OH table by printing out all lines in range 9300 \to 9350 \AA
+ Note that each line is a doublet, with intensity ratio roughly 1
+ In the figures in Osterbrock paper, only the mean wavelength is used since splitting is only about 1 km/s, and therefore unresolved even with HIRES

#+BEGIN_SRC python :return result
  import numpy as np
  from astropy.table import Table

  tab = Table.read(
      'SkyLines-Osterbrock96/oh.dat',
      format='ascii.cds',
      readme='SkyLines-Osterbrock96/ReadMe'
  )
  tab.remove_column('---')
  mask = np.abs(tab['lambda'] - 9325) <= 25
  result = [
      tab.colnames,
      None
  ] + [row.data for row in tab[mask]]

#+END_SRC

#+RESULTS:
|   lambda | nu' | nu" | Trans    |
|----------+-----+-----+----------|
| 9305.982 |   8 |   4 | R1f(4.5) |
| 9306.009 |   8 |   4 | R1e(4.5) |
| 9307.345 |   8 |   4 | R1f(3.5) |
| 9307.398 |   8 |   4 | R1e(3.5) |
| 9308.998 |   8 |   4 | R2e(3.5) |
|  9309.11 |   8 |   4 | R2f(3.5) |
| 9310.701 |   8 |   4 | R2e(4.5) |
| 9310.822 |   8 |   4 | R2f(4.5) |
| 9312.861 |   8 |   4 | R2e(2.5) |
| 9312.944 |   8 |   4 | R2f(2.5) |
| 9313.316 |   8 |   4 | R1f(2.5) |
| 9313.375 |   8 |   4 | R1e(2.5) |
| 9317.663 |   8 |   4 | R1e(6.5) |
| 9317.753 |   8 |   4 | R1f(6.5) |
| 9317.878 |   8 |   4 | R2e(5.5) |
| 9317.988 |   8 |   4 | R2f(5.5) |
| 9322.431 |   8 |   4 | R2e(1.5) |
| 9322.467 |   8 |   4 | R2f(1.5) |
| 9323.706 |   8 |   4 | R1f(1.5) |
| 9323.752 |   8 |   4 | R1e(1.5) |
| 9330.493 |   8 |   4 | R2e(6.5) |
| 9330.574 |   8 |   4 | R2f(6.5) |
| 9330.999 |   8 |   4 | R1e(7.5) |
| 9331.178 |   8 |   4 | R1f(7.5) |
| 9337.842 |   8 |   4 | R2f(0.5) |
| 9337.866 |   8 |   4 | R2e(0.5) |

** Strong lines and others of primary interest: basic-line-list.tab
:PROPERTIES:
:TABLE_EXPORT_FILE: basic-line-list.tab
:TABLE_EXPORT_FORMAT: orgtbl-to-tsv
:ID:       30F9E738-EE31-4C62-B5CA-CE103485A481
:END:
+ After editing, remember to export the table to file with =C-c t e=
+ This table has now expanded to cover all lines that can be extracted easily (that is, without fitting gaussians)
#+name: basic-line-list
| Ion      | Class |     wav0 | strength | blue cont | red cont | comment                      |
|----------+-------+----------+----------+-----------+----------+------------------------------|
| N II     | P     |  4607.16 |        4 |         1 |        1 | blend [Fe III], O II 4609.44 |
| C II     | P     |  4620.11 |        6 |         1 |        1 | *** also 4620.26, pure recom |
| N II     | P     |  4630.54 |        4 |         1 |        0 |                              |
| O II     | P     |  4641.81 |        4 |         1 |        0 | blend N III + N II           |
| O II     | P     |  4650.00 |        4 |         1 |        0 | blend 4649.13,50.84          |
| [Fe III] | M     |  4658.10 |        3 |         0 |        1 | **                           |
| [Fe III] | M     |  4667.01 |        6 |         1 |        1 |                              |
| O II     | P     |  4676.24 |        5 |         1 |        1 | blend with 4673.73           |
| He II    | A9    |  4685.68 |       -4 |         1 |        1 | absorption line              |
| [Fe III] | M     |  4701.62 |        4 |         1 |        1 |                              |
| He I     | H     |  4713.14 |        3 |         1 |        1 | blend with [Ar IV] 4711.37   |
| [Fe III] | M     |  4733.93 |        4 |         1 |        0 |                              |
| [Ar IV]  | U     |  4740.17 |        4 |         0 |        1 |                              |
| [Fe III] | M     |  4754.83 |        4 |         1 |        1 |                              |
| [Fe III] | M     |   4769.6 |        4 |         0 |        1 |                              |
| [Fe III] | M     |  4777.88 |        4 |         0 |        1 | blend with [Fe II] 4774.74   |
| N II     | P     |  4788.13 |        7 |         1 |        1 | BAD ARTEFACT                 |
| C II     | P     | 4802.740 |        5 |         1 |        0 | *** blend but pure recom     |
| N II     | P     | 4803.287 |        4 |         1 |        1 | blend [Co II] 4802.36        |
| [Fe II]  | L     | 4814.534 |        4 |         1 |        1 | blend N II, S II             |
| H I      | H     |  4861.32 |        1 |         1 |        1 |                              |
| [Fe III] | M     | 4881.073 |        4 |         1 |        1 |                              |
| [Fe II]  | L     | 4889.704 |        5 |         0 |        1 |                              |
| [Fe II]  | L     | 4905.339 |        5 |         1 |        1 |                              |
| He I     | H     |  4921.93 |        3 |         1 |        1 |                              |
| [Fe III] | M     |  4930.50 |        4 |         0 |        1 | blend with [O III] 4931.32   |
| [O III]  | H     |  4958.91 |        1 |         1 |        1 |                              |
| O I      | L     |  4980.13 |        6 |         1 |        0 | ***                          |
| [Fe III] | M     |  4987.20 |        4 |         0 |        0 | *** blend 4985.90+N II 87.38 |
| N II     | P     |  4994.37 |        6 |         0 |        0 | *** hidden in [O III] wing   |
| [O III]  | H     |  5006.84 |        1 |         1 |        1 |                              |
| He I     | H     |  5015.68 |        3 |         0 |        1 | On red wing of 5007          |
| [Fe III] | M     |  5032.68 |        6 |         1 |        0 | ***                          |
| [Fe II]  | L     |  5035.49 |        6 |         1 |        1 | ***                          |
| Si II    | P     |  5041.03 |        4 |         1 |        0 |                              |
| He I     | H     |  5047.74 |        4 |         0 |        1 | No good cont!                |
| Si II    | P     |  5055.98 |        4 |         0 |        1 |                              |
| [Fe III] | M     |  5084.77 |        6 |         1 |        1 | ***                          |
| [Fe II]  | L     |  5111.63 |        6 |         1 |        1 | ***                          |
| C II     | P     |  5121.82 |        7 |         1 |        1 | ***                          |
| N II     | D     |  5132.95 |        7 |         1 |        1 | *** and 5133.28 DIELEC RECOM |
| O I      | L     |  5146.61 |        5 |         1 |        1 |                              |
| [Fe II]  | L     |  5158.81 |        5 |         1 |        1 |                              |
| [Ar III] | H     |  5191.82 |        4 |         1 |        0 |                              |
| [N I]    | L     |  5199.00 |        4 |         0 |        1 | Blend 5197.98,200.26         |
| S III    | P     |  5219.31 |        6 |         0 |        1 | *Also something 5210         |
| [Fe II]  | L     |  5261.61 |        4 |         1 |        0 |                              |
| [Fe III] | M     |  5270.40 |        3 |         0 |        1 | + [Fe II] 5273.38            |
| O I      | L     |  5298.89 |        5 |         1 |        1 |                              |
| [Fe II]  | L     | 5333.646 |        5 |         1 |        1 |                              |
| C II     | P     |  5342.40 |        6 |         0 |        1 | *** V17.06 pure recom        |
| [Fe II]  | L     | 5376.452 |        5 |         1 |        1 |                              |
| [Fe III] | M     |  5412.00 |        5 |         1 |        1 | + He II abs +[Fe II]?        |
| O II     | P     |  5433.49 |        6 |         1 |        1 |                              |
| S II     | P     |  5453.81 |        6 |         1 |        1 |                              |
| N II     | P     |  5495.67 |        6 |         1 |        1 | *** multiplet 29 + [Fe II]?  |
| O I      | L     |  5512.77 |        5 |         1 |        0 | ***                          |
| [Cl III] | H     |  5517.71 |        3 |         0 |        1 |                              |
| Mg I     | L     |  5528.40 |        7 |         0 |        0 | *** ID unsure (but not N II) |
| [Cl III] | H     |  5537.88 |        3 |         1 |        1 |                              |
| N II     | P     |  5551.95 |        6 |         1 |        0 | multiplet 63                 |
| O I      | L     |  5555.03 |        5 |         0 |        1 |                              |
| [O I]    | L     |  5577.34 |        4 |         1 |        1 | + S II 5578.870 ?            |
| O III    | A7    |  5592.37 |       -5 |         1 |        1 | Absorption line              |
| XXX      | P     | 5640.346 |        7 |         1 |        1 | *** very weak                |
| N II     | P     | 5666.629 |        5 |         1 |        1 | multiplet 3  (contam low?)   |
| N II     | P     |  5676.02 |        6 |         0 |        0 | *** multiplet 3  - no good c |
| N II     | P     | 5679.558 |        5 |         1 |        1 | multiplet 3                  |
| N II     | P     |  5686.21 |        6 |         0 |        1 | *** multiplet 3              |
| N II     | P     |  5711.06 |        6 |         1 |        1 | *** multiplet 3              |
| Si III   | U     |  5739.73 |        5 |         1 |        1 |                              |
| [N II]   | M     |  5755.08 |        4 |         1 |        1 |                              |
| DIB      | A0    |     5781 |       -4 |         1 |        0 | Diffuse interstellar band    |
| He II    | A7    | 5784.947 |       -5 |         0 |        1 | Abs blend O II 5783.788      |
| C IV     | A7    |  5801.35 |       -5 |         1 |        1 | Absorption line              |
| [Ni IV]  | H     |  5820.10 |        7 |         1 |        1 | *** Very high ionization     |
| Ni II    | P     |  5867.99 |        6 |         1 |        0 | ***                          |
| He I     | H     |  5875.62 |        1 |         1 |        1 |                              |
| C II     | P     |  5889.78 |        4 |         1 |        0 | Na I sky blend, V5           |
| N III    | A7    |   5896.1 |       -5 |         0 |        1 | Absorption line              |
| N III    | A7    |   5901.2 |       -5 |         0 |        1 | Absorption line              |
| XXX      | U     |  5906.00 |        5 |         0 |        1 | Unidentified                 |
| N III    | A7    |   5918.5 |       -5 |         1 |        1 | Absorption line              |
| N II     | P     |  5927.82 |        5 |         1 |        0 | ***                          |
| N II     | P     |  5931.78 |        4 |         0 |        1 | Blend with 5927.81           |
| N II     | P     |  5941.65 |        4 |         0 |        1 | Blend with 5940.24           |
| N II     | P     |  5952.39 |        4 |         1 |        0 | All multiplet 28             |
| Si II    | P     |  5957.56 |        4 |         0 |        1 | Blend with O I 5958.39       |
| Si II    | P     |  5978.93 |        4 |         1 |        1 | Multiplet 4                  |
| [Ni III] | M     |   6000.2 |        6 |         1 |        1 |                              |
| XXX      | L     |   6033.0 |        7 |         1 |        1 | Very weak (only HH 202)      |
| O I      | L     |  6046.23 |        4 |         1 |        1 |                              |
| He II    | H     |  6074.20 |        7 |         1 |        1 | *** Surely not He II !!!     |
| [Fe II]  | L     | 6133.433 |        4 |         1 |        1 | plus sky?                    |
| C II     | P     |  6151.43 |        5 |         1 |        0 | V16.04, pure recomb          |
| O I      | L     |  6155.98 |        6 |         0 |        1 | * blend with Ni II 6157.42   |
| N II     | P     |  6167.76 |        7 |         1 |        0 | ***                          |
| N II     | P     |  6173.31 |        7 |         0 |        1 | ***                          |
| C II     | P     |  6257.18 |        7 |         1 |        0 | *** V10.03 + O I ?           |
| C II     | P     |  6259.56 |        7 |         0 |        1 | *** V10.03, pure recomb      |
| DIB      | A0    |  6278.00 |       -2 |         1 |        0 | Telluric gamma band?         |
| [O I]    | L     |  6300.30 |        3 |         1 |        1 |                              |
| [S III]  | H     |  6312.06 |        3 |         1 |        1 |                              |
| N II     | P     |  6334.35 |        7 |         0 |        1 | ***                          |
| Si II    | P     |  6347.11 |        4 |         1 |        1 |                              |
| [O I]    | L     |  6363.78 |        3 |         1 |        0 |                              |
| Si II    | P     |  6371.36 |        4 |         0 |        1 |                              |
| N II     | P     |   6382.8 |        7 |         1 |        0 | *** blend with C II ?        |
| [Ni III] | M     |   6401.5 |        6 |         1 |        1 | Blend with Ne I 6402.25      |
| C II     | P     |  6461.95 |        6 |         1 |        1 | V17.04 Pure recomb           |
| XXX      | AP    |   6480.0 |       -5 |         1 |        0 | * Absorption                 |
| XXX      | AP    |   6490.0 |       -5 |         0 |        1 | * Absorption                 |
| O II     | P     |  6501.40 |        7 |         1 |        0 | *** and 6500.83, 6501.42     |
| XXX      |       |     6505 |        7 |         0 |        0 | *** could be N II            |
| O II     | P     |  6509.80 |        7 |         0 |        1 | *** and 6509.711, 6510.61    |
| [N II]   | L     |  6527.24 |        6 |         1 |        0 |                              |
| [Ni III] | M     |   6533.8 |        6 |         0 |        1 |                              |
| [N II]   | L     |  6548.05 |        2 |         1 |        1 |                              |
| H I      | H     |  6562.79 |        1 |         1 |        1 |                              |
| C II     | P     |  6578.05 |        5 |         1 |        0 | Blue 6583.45 dominates       |
| [N II]   | L     |  6583.45 |        2 |         1 |        1 |                              |
| N III    | AP    |   6633.9 |       -4 |         1 |        1 | Absorption line              |
| Si III   | A9    |  6662.90 |       -5 |         1 |        0 | Abs + em [Ni II] 6666.80     |
| [Ni II]  | L     |  6666.80 |        6 |         0 |        1 |                              |
| He I     | H     |  6678.15 |        2 |         1 |        1 |                              |
| [S II]   | M     |  6716.44 |        3 |         1 |        1 |                              |
| [S II]   | M     | 6730.816 |        3 |         1 |        1 |                              |
| [Fe II]  | L     | 6746.933 |        7 |         1 |        1 | +                            |
| C II     | D     |  6779.94 |        7 |         1 |        0 | *** +6780.60 DIELEC          |
| C II     | D     |  6787.22 |        7 |         1 |        1 | ***                          |
| He I     | H     |  6804.94 |        7 |         1 |        0 | ***                          |
| N II     | P     |  6809.99 |        7 |         0 |        0 | ***                          |
| C II     | P     |  6812.28 |        7 |         0 |        1 | *** or [Ni II] 6813.57 ?     |
| He I     | H     |  6827.97 |        6 |         1 |        1 | *** blend [Kr III] 6826.7 ?  |
| He I     | H     |  6855.99 |        6 |         1 |        1 | ***                          |
| He I     | H     |  6933.91 |        6 |         1 |        1 | ***                          |
| He I     | H     |  6989.47 |        6 |         1 |        1 |                              |
| O I      | L     |  7001.92 |        3 |         0 |        1 | Weak line at 6996 (He I?)    |
| He I     | H     |  7065.28 |        2 |         1 |        1 |                              |
| [Ar III] | H     |  7135.78 |        1 |         1 |        1 | super strong                 |
| [Fe II]  | L     |  7155.14 |        4 |         1 |        0 |                              |
| He I     | H     |  7160.13 |        4 |         0 |        1 |                              |
| [Fe II]  | L     |  7172.00 |        5 |         0 |        1 |                              |
| C II     | P     |  7231.34 |        3 |         1 |        0 | V3 - 50% fluorescence        |
| C II     | P     |  7236.42 |        3 |         0 |        1 | 7236.42 + 7237.17            |
| O I      | L     |  7254.15 |        3 |         1 |        1 | Blend with 7254.45,54.53     |
| He I     | H     |  7281.35 |        3 |         1 |        1 |                              |
| [Ca II]  | L     |  7291.47 |        7 |         1 |        0 | ***                          |
| He I     | H     | 7298.050 |        4 |         1 |        1 |                              |
| [O II]   | M     |  7318.39 |        1 |         1 |        1 | Also 7319.99                 |
| [O II]   | M     |  7329.66 |        1 |         0 |        1 | Also 7330.73                 |
| O II     | P     |   7340.7 |        5 |         0 |        1 | Or N II 7338.6               |
| O II     | P     | 7369.029 |        6 |         1 |        0 | blend C II 7370.0            |
| [Ni II]  | L     |  7377.83 |        4 |         1 |        1 |                              |
| [Fe II]  | L     |  7388.16 |        5 |         0 |        1 |                              |
| [Ni II]  | L     |  7411.61 |        5 |         1 |        1 |                              |
| N I      | L     |  7423.64 |        6 |         1 |        1 |                              |
| N I      | L     |  7442.30 |        5 |         1 |        1 |                              |
| [Fe II]  | L     |  7452.54 |        4 |         1 |        1 |                              |
| N I      | L     |  7468.31 |        4 |         1 |        1 |                              |
| He I     | H     |  7499.85 |        5 |         1 |        1 |                              |
| Fe II    | L     |  7515.83 |        6 |         1 |        0 | ***                          |
| C II     | P     |  7519.49 |        6 |         1 |        0 | Plus Sky at 7524             |
| [Cl IV]  | U     |  7530.80 |        5 |         0 |        1 | blend C II 7530.57           |
| [Fe II]  | L     |  7733.13 |        7 |         1 |        1 | ***                          |
| [Ar III] | H     |  7751.10 |        1 |         1 |        1 |                              |
| He I     | H     |  7757.62 |        6 |         0 |        1 | *** wing of [Ar III]         |
| O I      | L     |  7773.37 |        5 |         1 |        0 | *** Mean 71.94,74.17,75.39   |
| He I     | H     |  7811.69 |        7 |         1 |        1 | *** singlet                  |
| He I     | H     |  7816.13 |        4 |         1 |        0 | Sky OH (?) at 7820           |
| [P II]   | L     |  7875.99 |        6 |         1 |        0 | *** Also 4669.25, 4736.55    |
| He I     | H     |  7880.90 |        7 |         0 |        1 | *** singlet                  |
| Ca I]    | L     |  7890.07 |        4 |         1 |        1 |                              |
| He I     | H     |  7952.96 |        7 |         0 |        1 | *** triplet                  |
| He I     | H     |  7962.43 |        7 |         1 |        1 | *** triplet                  |
| He I     | H     |  7971.63 |        6 |         1 |        1 | *** singlet                  |
| O I      | L     |  7982.40 |        6 |         1 |        0 | ***                          |
| O I      | L     |  7987.33 |        6 |         0 |        1 | ***                          |
| [Fe II]  | L     |  7997.03 |        6 |         1 |        0 | ***                          |
| [Cr II]  | L     |  8000.08 |        5 |         0 |        1 | or [Fe II] 7999.47? Sky 7994 |
| He I     | H     |  8015.96 |        6 |         1 |        1 | *** triplet                  |
| Si I     | L     |  8034.91 |        6 |         1 |        1 | *** Or He I 8035.06          |
| [Cl IV]  | H     |  8045.62 |        4 |         1 |        0 | HIGH IONIZATION!             |
| He I     | H     |  8057.54 |        6 |         1 |        1 | *** triplet                  |
| He I     | H     |  8084.28 |        6 |         1 |        1 | *** triplet                  |
| He I     | H     |  8094.11 |        6 |         1 |        1 | *** singlet                  |
| He I     | H     |  8116.42 |        6 |         1 |        0 | *** triplet                  |
| Ca I]    | L     |  8125.31 |        6 |         0 |        1 | ***                          |
| He I     | H     |  8155.66 |        6 |         1 |        1 | ***                          |
| XXX      | L     |     8189 |        4 |         1 |        1 | Could be [Cr II] 8188.12?    |
| N I      | L     |  8216.34 |        4 |         1 |        0 | *Also 8210.72                |
| N I      | L     |  8223.14 |        4 |         0 |        1 | Same multiplet as 8216.34    |
| XXX      | L     |     8243 |        4 |         1 |        1 | Could be O I? or Fe II?      |
| He I     | H     |  8361.73 |        4 |         9 |        1 | *** Blend with H I           |
| He I     | H     |  8397.41 |        7 |         0 |        1 | *** triplet av wav           |
| He I     | H     |  8421.97 |        6 |         1 |        0 | *** triplet av wav           |
| He I     | H     |  8423.79 |        6 |         0 |        1 | *** triplet av wav           |
| [Cl III] | H     |  8433.94 |        5 |         1 |        0 | *** Blend with H I           |
| H I      | H     |  8437.96 |        3 |         1 |        0 | Pa 18                        |
| O I      | L     |  8446.36 |        2 |         0 |        1 | Also  8444.25, 8444.7        |
| H I      | H     |  8467.25 |        2 |         0 |        1 | Pa 17 Blend with ?? 8464     |
| [Cl III] | H     |  8480.90 |        5 |         1 |        0 | ***                          |
| He I     | H     |  8486.27 |        5 |         0 |        1 | ***                          |
| He I     | H     |  8488.73 |        6 |         0 |        0 | ***                          |
| [Cl III] | H     |   8499.7 |        4 |         0 |        0 | *** Blend with H I           |
| H I      | H     |  8502.48 |        2 |         1 |        1 | Pa 16                        |
| He I     | H     |  8518.04 |        6 |         1 |        0 | *** singlet                  |
| He I     | H     |  8529.04 |        5 |         1 |        0 | *** Multiplet av wav         |
| He I     | H     |  8532.27 |        6 |         0 |        1 | *** Multiplet av wav         |
| H I      | H     |  8545.38 |        2 |         1 |        1 | Pa 15                        |
| [Cl II]  | L     |  8578.69 |        3 |         1 |        0 | 3P-1D 2-2 Blend with 8582    |
| He I     | H     |  8582.61 |        4 |         0 |        1 | ** multiplet .611->.646      |
| H I      | H     |  8598.39 |        2 |         1 |        1 | Pa 14 plus 2nd order ghost   |
| [Fe II]  | L     |  8616.95 |        3 |         1 |        1 | a4F-a4P 9/2-5/2              |
| He I     | H     |  8632.97 |        7 |         1 |        1 | ***                          |
| He I     | H     |  8648.27 |        6 |         1 |        0 | *** and 49.89, 50.83         |
| H I      | H     |  8665.02 |        2 |         1 |        1 | Pa 13                        |
| N I      | L     |  8680.28 |        4 |         1 |        0 | Plus 83.4                    |
| N I      | L     |  8684.24 |        4 |         0 |        0 | ***                          |
| N I      | L     |  8686.15 |        4 |         0 |        1 | *                            |
| [Co II]  | L     |  8695.33 |        7 |         1 |        0 | ***                          |
| N I      | L     |  8703.25 |        4 |         1 |        0 |                              |
| N I      | L     |  8711.70 |        4 |         0 |        1 | Also 8718.83                 |
| N I      | L     |  8718.83 |        5 |         0 |        0 | ***                          |
| [C I]    | L     |  8727.13 |        4 |         1 |        0 | Different!                   |
| He I     | H     |  8733.43 |        4 |         0 |        1 | *                            |
| H I      | H     |  8750.47 |        2 |         1 |        1 | Pa 12                        |
| He I     | H     |  8776.71 |        6 |         0 |        1 | *** and .73, .93             |
| [Cr II]  | L     |  8818.87 |        6 |         0 |        0 | *** no good cont             |
| He I     | H     |  8830.51 |        6 |         0 |        0 | *** no good cont             |
| He I     | H     |  8845.36 |        6 |         1 |        0 | *** and .40                  |
| He I     | H     |  8848.04 |        6 |         0 |        0 | *** no good cont             |
| He I     | H     |  8854.20 |        6 |         0 |        1 | *** and .23                  |
| H I      | H     |  8862.79 |        2 |         1 |        1 | Pa 11                        |
| [Fe II]  | L     |  8891.93 |        4 |         0 |        1 | a4F-a4P 7/2-3/2              |
| He I     | H     |  8914.77 |        5 |         1 |        0 | ***                          |
| He I     | H     |  8930.97 |        6 |         1 |        1 | ***                          |
| He I     | H     |  8996.98 |        5 |         1 |        0 | *** Triplet - Sky to red     |
| H I      | H     |  9014.91 |        2 |         1 |        1 | Pa 10                        |
| [Fe II]  | L     |  9033.49 |        5 |         1 |        1 | a4F-a4P 5/2-1/2 + [Cr II]    |
| Ca I]    | L     |  9052.16 |        5 |         1 |        0 | + [Fe II] 9051.95 7/2-5/2    |
| [S III]  | H     |  9068.90 |        1 |         1 |        1 |                              |
| Ca I]    | L     |  9095.09 |        5 |         0 |        0 | No good continuum            |
| [Cl II]  | M     |  9123.60 |        5 |         1 |        1 | *** 3P-1D  1-2               |
| Ca I]    | L     |  9204.09 |        5 |         1 |        0 | *** 3P-1Po  0-1              |
| He I     | H     |  9210.28 |        4 |         0 |        1 |                              |
| [Cr II]  | L     |  9222.18 |        6 |         0 |        0 | *** NoGC - or Fe I]?         |
| H I      | H     |  9229.01 |        2 |         1 |        1 | Pa 9 +[Fe II]9226.63 5/2-3/2 |
| XXX      | L     |   9236.0 |        6 |         0 |        0 | No ID.  No good cont         |
| Ca I]    | L     |  9244.31 |        6 |         0 |        1 | *** 3P-1Po  1-1              |
| [Fe II]  | H     |  9267.55 |        5 |         1 |        1 | a4F-a4P 3/2-1/2              |


*** Not wanted on voyage
+ Lines that we have since got rid of
+ First two seemed to be off end of spectrum

| O II | P | 4595.95 | 7 | 0 | 1 | ** blend 4596.18 + [Ni III] |
| N II | P | 4601.48 | 7 | 1 | 1 | ** blend O II 4602.11       |
| XXX  | L |  6328.0 | 7 | 1 | 0 | * mostly sky                |

** Simple method with moments
+ This will work for any line that is sufficiently isolated

*** Program to extract a single line extract-em-line.py
:PROPERTIES:
:ID:       9B385AF1-5AA5-4EA2-B1A3-8802C0959808
:END:
:LOGBOOK:
CLOCK: [2016-03-24 Thu 14:36]--[2016-03-24 Thu 14:36] =>  0:00
:END:
+ First go
  + Choose wavelength range around line
    + [ ]This should come from a velocity range really
  + Extract cube that is just the line
+ Revisited [2015-10-29 Thu]
  + We want to add "fuzzed" versions of the maps in which we add gaussian noise made from the variance
  + First we refactor the original extract-em-line.py so that it separates the finding of the wavelength window from the line extraction proper
  + This is because we don't want to fuzz the entire wavsec cube
  + The idea is that we will be able to re-use parts in the fuzz version


#+BEGIN_SRC python :tangle extract_utils.py
  from __future__ import print_function
  import sys
  import os
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy import units as u
  from astropy import constants as const
  from misc_utils import sanitize_string

  linetab = Table.read('basic-line-list.tab', format='ascii.tab')
  wavsectab = Table.read('wavsec-startwavs.tab', format='ascii.tab')
  classtab = Table.read('line-classes.tab', format='ascii.tab')

  def waves2vels(waves, restwav):
      """Naive wavelength to radial velocity (in km/s) 

      Performs no manner of heliocentric correction
      """
      return const.c.to(u.km/u.s)*(waves - restwav)/restwav


  def get_masks(mask_dir='LineMaps'):
      """Return a dict of masks for each line class

      The mask is True for pixels where that class of line is prominent,
      as measured by both EW and total flux.  Optional argument
      `mask_dir` specifies directory from which to load masks

      """
      masks = {}
      for row in classtab:
          k = row['Code']
          mask_name = 'mask-line-class-{}.fits'.format(k)
          masks[k] = fits.open(os.path.join(mask_dir, mask_name))[0].data.astype(bool)
      return masks


  def find_wavsec(wav):
      """Which wavsec chunk is this wavelength in"""
      return wavsectab['Section'][wav > wavsectab['CRVAL3']].max() 


  def trim_to_window(wav, cube, wcube, dwav=12.0):
      """Trim a spectral `cube` with accompanying WCS `wcube` down to a
  window of width 2*`dwav` Angstrom around a central wavelength `wav`.
  Returns tuple of trimmed cube and trimmed WCS

      """
      wavs = (wav + dwav*np.array([-1, 1]))*u.Angstrom.to(u.m)
      _, _, [wavmin, wavmax] = wcube.wcs_pix2world([0, 0], [0, 0], [0, cube.shape[0]-1], 0)
      print('Requested wavelength window:', wavs)
      print('Available wavelength range:', wavmin, wavmax)
      _, _, pixels = wcube.wcs_world2pix([0, 0], [0, 0], wavs, 0)
      k1, k2 = int(pixels[0]), int(pixels[1])+2
      if k1 < 0:
          print('Adjusting blue edge from', k1, 'to', 0)
          k1 = 0
      window = slice(k1, k2), slice(None), slice(None)
      return cube[window], wcube.slice(window)


  def extract_line_maps(wav, cube, wcube,
			usecont=[1, 1], dwav=4.0, dwavcont=8.0,
			specmask=None,
  ):
      """Extract line moments and continuum"""


      nwav, ny, nx = cube.shape
    
      # outer range is wav +/- dwavcont
      wavs = (wav + dwavcont*np.array([-1, 1]))*u.Angstrom.to(u.m)
      _, _, (kout1, kout2) = wcube.all_world2pix([0, 0], [0, 0], wavs, 0)
      kout1, kout2 = int(kout1), int(kout2) + 2
      if kout1 < 0:
          print('Adjusting kout1 from', kout1, 'to 0')
          kout1 = 0

      # inner range is wav +/- dwav
      wavs = (wav + dwav*np.array([-1, 1]))*u.Angstrom.to(u.m)
      _, _, (kin1, kin2) = wcube.all_world2pix([0, 0], [0, 0], wavs, 0)
      kin1, kin2 = int(kin1), int(kin2) + 2
      print('kout1, kin1, kin2, kout2, nwav =', kout1, kin1, kin2, kout2, nwav)

      # find average continuum
      cont1 = np.nanmean(cube[kout1:kin1, :, :], axis=0)
      cont2 = np.nanmean(cube[kin2:kout2, :, :], axis=0)
      # Maybe don't use the continuum on one side (if contaminated)
      wt1, wt2 = usecont          
      avcont = (wt1*cont1 + wt2*cont2)/(wt1 + wt2)

      # Subtract to get pure line window
      linewin = cube[kin1:kin2, :, :] - avcont[None, :, :]
      # Now find moments
      nwin = kin2 - kin1
      _, _, winwavs = wcube.all_pix2world([0]*nwin, [0]*nwin, np.arange(kin1, kin2), 0)
      # Convert wavelengths to velocities
      winvels = waves2vels(winwavs*u.m.to(u.Angstrom), wav)
      mom0 = linewin.sum(axis=0)
      mom1 = np.sum(linewin*winvels[:, None, None], axis=0)
      vmean = mom1/mom0
      mom2 = np.sum(linewin*(winvels[:, None, None] - vmean)**2, axis=0)
      vsig = np.sqrt(mom2/mom0)
      maps = {'continuum': avcont, 'linesum': mom0,
              'mean': vmean.to(u.km/u.s).value, 'sigma': vsig.to(u.km/u.s).value}

      # Save an average spectrum as well
      if kout2 > cube.shape[0]:
          print('Out of bounds: truncating from', kout2, 'to', cube.shape[0])
          kout2 = cube.shape[0]
      nwinout = kout2 - kout1
      _, _, winwavsout = wcube.all_pix2world([0]*nwinout, [0]*nwinout, np.arange(kout1, kout2), 0)
      winvelsout = waves2vels(winwavsout*u.m.to(u.Angstrom), wav)

      # Use per-class mask to calculate 1D spectrum
      if specmask is None:
          specmask = np.ones_like(avcont).astype(bool)
      else:
          # The line class masks are defined on binned maps, which are
          # bigger, so need to trim back down to the original size
          specmask = specmask[:ny, :nx]

      spec = {
          'vhel': winvelsout.to(u.km/u.s),
          'wav': winwavsout*u.m.to(u.Angstrom),
          'flux': np.nansum(
              specmask[None, :, :]*cube[kout1:kout2, :, :],
              axis=(1, 2)) / specmask.sum(),
          'cont': np.nanmean(avcont[specmask])*np.ones(nwinout),
      }
      print(*[(k, len(v)) for k, v in spec.items()])
      return maps, spec
#+END_SRC

#+BEGIN_SRC python :tangle extract-em-line.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from astropy.wcs import WCS
  from misc_utils import sanitize_string
  from extract_utils import (find_wavsec, trim_to_window,
                             extract_line_maps, get_masks, linetab)

  def save_linemap_files(wav, species,
			 mapdir='LineMaps', usecont=[1, 1], specmask=None):
      full_width = 24.0  # Angstrom
      wavsec = find_wavsec(wav)
      wavsec_blue = find_wavsec(wav - full_width/2)
      wavsec_red = find_wavsec(wav + full_width/2)
      if (wavsec_blue != wavsec) or (wavsec_red != wavsec):
          print('Uh, oh - line straddles wavsecs', wavsec_blue, wavsec, wavsec_red)
          wavsecs = set([wavsec_blue, wavsec, wavsec_red])
          fn = 'muse-hr-data-wavsec-edge{}{}.fits'.format(*wavsecs)
      else:
          fn = 'muse-hr-data-wavsec{}.fits'.format(wavsec)
      try:
          hdulist = fits.open(fn)
      except:
          # Maybe we have the cube in the BigFiles folder
          hdulist = fits.open('BigFiles/' + fn)
      hdu = hdulist['DATA']
      print('Using', fn)
      wfull = WCS(hdu.header)
      cube, w = trim_to_window(wav, hdu.data, wfull, dwav=full_width/2)
      print('Cube shape:', cube.shape)
      maps, spec =  extract_line_maps(wav, cube, w, usecont, specmask=specmask)
      wavid = str(int(wav+0.5))
      # Save the maps to FITS file 
      for mapid, mapdata in maps.items():
          mhdu = fits.PrimaryHDU(header=w.celestial.to_header(), data=mapdata)
          mname = '{}/{}-{}-{}.fits'.format(mapdir, mapid, species, wavid)
          mhdu.writeto(mname, clobber=True)
      sname = '{}/spec1d-{}-{}.tab'.format(mapdir, species, wavid)
      # And save the spectrum to TSV file
      Table(spec).write(sname, format='ascii.tab')


  try:
      # Otionally specify a single line
      wav_wanted = int(sys.argv[1])
  except:
      wav_wanted = None


  masks = get_masks()
  for row in linetab:
      if wav_wanted is not None and wav_wanted != int(0.5 + row['wav0']):
          # jump all unwanted lines if command line argument was given
          continue                
      print(row['Ion'], row['wav0'])
      save_linemap_files(
          row['wav0'], sanitize_string(row['Ion']),
          usecont=[row['blue cont'], row['red cont']],
          specmask=masks[row['Class']],
      )

#+END_SRC

#+BEGIN_SRC sh :results silent
mkdir LineMaps
#+END_SRC

Test it out in a shell
#+BEGIN_SRC sh :eval no
  python extract-em-line.py
#+END_SRC

Check out the heliocentric correction
#+BEGIN_SRC python :results output
  from __future__ import print_function
  import sys
  from astropy.io import fits
  from helio_utils import helio_topo_from_header

  hdr = fits.open('muse-hr-window-wfc3-f656n.fits')[0].header
  print(helio_topo_from_header(hdr, observatory='VLT4'))
#+END_SRC

#+RESULTS:
: -16.217273731
*** fuzz_utils.py: add Gaussian noise to data according to per pixel variance
+ This was remarkably easy - it turns out that the numpy random distributions take array arguments for the mean and std parameters
#+BEGIN_SRC python :tangle fuzz_utils.py
  import numpy as np

  def fuzz(data, variance, nfuzz=1):
      '''Return `nfuzz` fuzzed versions of `data` in which each pixel is
  replaced by a value taken from a Gaussian distribution with mean equal
  to `data` and sigma equal to sqrt of `variance` (which must have same
  shape as `data`).  Returns an array of shape `(nfuzz,) + shape(data)` in
  which each (hyper) plane is a distinct fuzzed version of the original

      '''
      newshape = (nfuzz,) + data.shape
      return np.random.normal(data, np.sqrt(variance), newshape)
    

#+END_SRC
*** extract-em-line-fuzz.py: Fuzzy version of line extraction
:PROPERTIES:
:ID:       12C8CC0B-4F79-4726-B0E2-6DA1F9DFABA3
:END:
#+BEGIN_SRC python :tangle extract-em-line-fuzz.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from astropy.wcs import WCS
  from misc_utils import sanitize_string
  from extract_utils import (find_wavsec, trim_to_window,
                             extract_line_maps, get_masks, linetab)
  from fuzz_utils import fuzz


  def save_linemap_files(
          wav, species,
          mapdir='LineMaps', usecont=[1, 1], specmask=None):
      full_width = 24.0  # Angstrom
      wavsec = find_wavsec(wav)
      wavsec_blue = find_wavsec(wav - full_width/2)
      wavsec_red = find_wavsec(wav + full_width/2)
      if (wavsec_blue != wavsec) or (wavsec_red != wavsec):
          print('Uh, oh - line straddles wavsecs', wavsec_blue, wavsec, wavsec_red)
          wavsecs = set([wavsec_blue, wavsec, wavsec_red])
          fn = 'muse-hr-data-wavsec-edge{}{}.fits'.format(*wavsecs)
      else:
          fn = 'muse-hr-data-wavsec{}.fits'.format(wavsec)

      try:
          hdulist = fits.open(fn)
      except:
          # Maybe we have the cube in the BigFiles folder
          hdulist = fits.open('BigFiles/' + fn)
      hdu = hdulist['DATA']
      wfull = WCS(hdu.header)

      # Read in variance for fuzzing
      vfn = fn.replace('data', 'variance')
      try: 
          variance = fits.open(vfn)['STAT'].data
      except:
          variance = fits.open('BigFiles/' + vfn)['STAT'].data

      cube, w = trim_to_window(wav, hdu.data, wfull, dwav=full_width/2)
      varcube, _ = trim_to_window(wav, variance, wfull, dwav=full_width/2)

      fuzzies = fuzz(cube, varcube, nfuzz)

      for ifuzz, fuzzcube in enumerate(fuzzies):
          maps, spec =  extract_line_maps(wav, fuzzcube, w, usecont, specmask=specmask)
          wavid = str(int(wav+0.5))
          fuzzid = '{:03d}'.format(ifuzz)
          # Save the maps to FITS file 
          for mapid, mapdata in maps.items():
              mhdu = fits.PrimaryHDU(header=w.celestial.to_header(), data=mapdata)
              mname = '{}/{}-{}-{}-fuzz{}.fits'.format(mapdir, mapid,
                                                       species, wavid, fuzzid)
              try:
                  # Possible sky line correction 30 Oct 2017
                  cname = '{}/{}-{}-{}-correction.fits'.format(
                      mapdir, mapid, species, wavid)
                  chdu = fits.open(cname)[0]
                  mhdu.data -= chdu.data
                  print('Correcting map with', cname)
              except FileNotFoundError:
                  # No correction file found
                  pass
              mhdu.writeto(mname, clobber=True)
          sname = '{}/spec1d-{}-{}-fuzz{}.tab'.format(mapdir, species, wavid, fuzzid)
          # And save the spectrum to TSV file
          Table(spec).write(sname, format='ascii.tab')


  try:
      # Optionally specify a single line
      wav_wanted = int(sys.argv[1])
  except:
      wav_wanted = None

  try:
      # Optionally specify number of fuzzies
      nfuzz = int(sys.argv[2])
  except:
      nfuzz = 10

  masks = get_masks()
  for row in linetab:
      if wav_wanted is not None and wav_wanted != int(0.5 + row['wav0']):
          # jump all unwanted lines if command line argument was given
          continue                
      print(row['Ion'], row['wav0'])
      save_linemap_files(
          row['wav0'], sanitize_string(row['Ion']),
          usecont=[row['blue cont'], row['red cont']],
          specmask=masks[row['Class']],
      )
#+END_SRC


*** DONE Calculate equivalent widths
CLOSED: [2015-11-03 Tue 22:26]
:PROPERTIES:
:ID:       4B6B5B8C-94C8-456D-90CB-2CF7B0D73099
:END:
+ The continuum maps are already per Angstrom, so this should automatically give an answer in Angstroms

#+BEGIN_SRC python :tangle muse_ew_utils.py
  from astropy.io import fits
  
  def save_ew(fname, hdu_id=0):
      '''Calculate and save EW for line map in file named `fname`

  It is assumed that the continuum can be found by transforming the filename
  '''
      hdu = fits.open(fname)[hdu_id]
      cname = fname.replace('linesum', 'continuum')
      cdata = fits.open(cname)[hdu_id].data
      hdu.data /= cdata
      ename = fname.replace('linesum', 'ew')
      hdu.writeto(ename, clobber=True)
  
#+END_SRC


#+BEGIN_SRC python :tangle muse-ew-all.py
  from astropy.table import Table
  from misc_utils import sanitize_string
  from muse_ew_utils import save_ew
  linetab = Table.read('basic-line-list.tab', format='ascii.tab')
  for row in linetab:
      wav = row['wav0']
      wavid = str(int(wav+0.5))
      species = sanitize_string(row['Ion'])
      fname = 'LineMaps/linesum-{}-{}.fits'.format(species, wavid)
      save_ew(fname)
#+END_SRC

+ This works on all the raw line maps
#+BEGIN_SRC sh
python muse-ew-all.py
#+END_SRC

#+RESULTS:

+ And this does one at a time, but is more flexible for binned or fuzzed maps
#+BEGIN_SRC python :tangle muse-ew.py
  import sys
  from muse_ew_utils import save_ew
  fn = sys.argv[1]
  save_ew(fn, 'SCALED')
#+END_SRC


#+BEGIN_SRC sh :result silent
python muse-ew.py LineMaps/linesum-DIB-6278-bin064.fits
#+END_SRC

#+RESULTS:

Here is a script that takes an argument (blank or =-fuzz000=, etc) and does EW for all the binned lines of that type
#+BEGIN_SRC sh :eval no :tangle batch-ew.sh
  for file in LineMaps/linesum*-[0-9][0-9][0-9][0-9]$1-bin*.fits; do
      python muse-ew.py $file
  done
#+END_SRC

**** Make a list of all the absorption lines
:PROPERTIES:
:ID:       5E28C927-CB18-45CB-87E0-C52109A04F79
:END:
This is useful, since these are the ones where EW is most relevant
#+BEGIN_SRC python :results output :tangle list-abs-lines.py
  from __future__ import print_function
  from astropy.table import Table
  from misc_utils import sanitize_string
  linetab = Table.read('basic-line-list.tab', format='ascii.tab')
  for row in linetab:
      if row['strength'] < 0.0:
          wav = row['wav0']
          wavid = str(int(wav+0.5))
          species = sanitize_string(row['Ion'])
          print('ew-{}-{}'.format(species, wavid))

#+END_SRC

#+RESULTS:
#+begin_example
ew-He_II-4686
ew-O_III-5592
ew-DIB-5781
ew-He_II-5785
ew-C_IV-5801
ew-C_IV-5812
ew-N_III-5896
ew-N_III-5901
ew-N_III-5919
ew-DIB-6278
ew-N_III-6634
ew-Si_III-6663
#+end_example

#+BEGIN_SRC sh
python list-abs-lines.py > absorption-lines.tab
#+END_SRC

#+RESULTS:

** CANCELED Median filter for images
CLOSED: [2016-12-26 Mon 19:21]
:LOGBOOK:
- Note taken on [2016-12-26 Mon 17:21] \\
  Just throwing this out there
:END:
+ May be useful alternative to the binning for some purposes
+ Can use =skimage.filter.median=
+ [X] This is really difficult because skimage filters only working with =uint= data types, which is a pain
+ [X] Currently gives all NaNs! - forget it!
 
#+BEGIN_SRC python :eval no :tangle median-filter-image.py
  import sys
  import numpy as np
  import skimage
  import skimage.filters
  import skimage.morphology
  import skimage.exposure
  from astropy.io import fits

  try:
      fn = sys.argv[1]
  except IndexError:
      sys.exit('Usage: {} FITSFILE [RADIUS]'.format(sys.argv[0]))

  try:
      radius = float(sys.argv[2])
  except IndexError:
      radius = 3.5

  hdulist = fits.open(fn)
  hdu = hdulist[0]
  if hdu.data is None:
      # Fallback if first HDU has no image
      hdu = hdulist['SCALED']

  mask = np.isfinite(hdu.data)
  save_range = hdu.data[mask].min(), hdu.data[mask].max()
  selem = skimage.morphology.disk(radius)
  image = skimage.exposure.rescale_intensity(
      hdu.data,
      in_range=save_range,
      out_range=(0.0, 1.0))
  image = skimage.filters.median(
      skimage.img_as_uint(image),
      selem=selem, mask=mask)
  hdu.data = skimage.exposure.rescale_intensity(
      skimage.img_as_float(image),
      out_range=save_range)
  suffix = '-median{:03d}.fits'.format(int(radius))
  hdu.writeto(fn.replace('.fits', suffix), clobber=True)
#+END_SRC
** Plot the average spectrum for each line
#+BEGIN_SRC python :tangle plot-em-line-spec.py
  from astropy.table import Table
  from misc_utils import sanitize_string
  from matplotlib import pyplot as plt
  import seaborn as sns

  linetab = Table.read('basic-line-list.tab', format='ascii.tab')

  for row in linetab:
      wav = row['wav0']
      wavid = str(int(wav+0.5))
      species = sanitize_string(row['Ion'])
      sname = 'Linemaps/spec1d-{}-{}.tab'.format(species, wavid)
      spec = Table.read(sname, format='ascii.tab')
      for xkey, xlabel in [['vhel', 'Heliocentric velocity, km/s'],
                           ['wav', 'Observed air wavelength, Angstrom']]:
          fig, ax = plt.subplots(1, 1)
          ax.plot(spec[xkey], spec['flux'])
          ax.plot(spec[xkey], spec['cont'])
          if xkey == 'wav':
              ax.set_xlim(row['wav0']-8.0, row['wav0']+8.0)
          else:
              ax.set_xlim(-300.0, 300.0)
          ax.set_ylim(0.0, None)
          ax.set_xlabel(xlabel)
          ax.set_ylabel('Mean flux per pixel')
          ax.set_title('{} {:.2f}'.format(row['Ion'], row['wav0']))
          fig.set_size_inches(5, 5)
          fig.savefig(sname.replace('.tab', '-{}.pdf'.format(xkey)))
          del(fig)
          del(ax)

#+END_SRC

#+BEGIN_SRC sh :results silent
python plot-em-line-spec.py
#+END_SRC

Look at spectra on heliocentric velocity scale
#+BEGIN_SRC sh
open LineMaps/spec1d*-vhel.pdf
#+END_SRC

#+RESULTS:

Look at spectra on wavelength scale
#+BEGIN_SRC sh
open LineMaps/spec1d*-wav.pdf
#+END_SRC

#+RESULTS:

** TODO Complex method with Gaussian fits
+ This is necessary for blended lines

** DONE Do extinction correction for all lines
CLOSED: [2016-03-29 Tue 22:33]
:PROPERTIES:
:ID:       7778E7D1-3209-481E-B301-163D5AEB8BAB
:END:
+ Basic strategy is to use the Hb/Ha map to predict C(lambda) from the Blagrave extinction law
#+BEGIN_SRC python :eval no :tangle correct-for-extinction.py
  from __future__ import print_function
  import sys
  import numpy as np
  import pyneb
  from astropy.io import fits

  # Set up Blagrave 2007 extinction law
  REDCORR = pyneb.extinction.red_corr.RedCorr(
      law='CCM89 Bal07', R_V=5.5, cHbeta=1.0)

  def flambda(wav):
      """Find [(A_lam / A_Hb) - 1] as function of wavelength `wav`

      This is the same as given in Table 2 of Blagrave et al (2007)

      """
      return np.log10(REDCORR.getCorrHb(wav))


  def CHb_from_RHbHa(RHbHa, balmer0=2.874):
      """Find base-10 extinction at H beta from balmer decrement `RHbHa`

      Assumes that the intrinsic Balmer decrement is `balmer0`

      """
      return np.log10(balmer0*RHbHa) / flambda(6563)


  def CHb_from_R6563_9229(RBaPa, RBaPa0=112.0):
      """Find base-10 extinction at H beta from 6563/9229 decrement `RBaPa`

      Assumes that the intrinsic decrement is `RBaPa0`

      """
      return np.log10(RBaPa/RBaPa0) / (flambda(9229) - flambda(6563))


  if __name__ == '__main__':

      try:
          lineid = sys.argv[1]
          ion_string, wav_string = lineid.split('-')
      except IndexError:
          print('Usage: {} LINEID'.format(sys.argv[0]))
      try:
          suffix = sys.argv[2] + '.fits'
          iHDU = 'SCALED'
      except:
          suffix = '.fits'
          iHDU = 0

      hb_ha = fits.open('Linemaps/ratio-4861-6563' + suffix)[iHDU].data
      ha_h9229 = fits.open('Linemaps/ratio-6563-9229' + suffix)[iHDU].data 
      chb = CHb_from_RHbHa(hb_ha)
      chb2 = CHb_from_R6563_9229(ha_h9229)

      wav = int(wav_string)
      clam = (1.0 + flambda(wav))*chb
      clam2 = (1.0 + flambda(wav))*chb2

      for prefix in 'continuum', 'linesum':
          fn = 'Linemaps/{}-{}'.format(prefix, lineid) + suffix
          try:
              hdu = fits.open(fn)[iHDU]
          except IOError:
              print('Skipping', fn, iHDU)
              continue
          for c, newsuff in [[clam, '-excorr'],
                              [clam2, '-excorr2']]:
              fn_new = fn.replace(suffix, newsuff + suffix)
              fits.PrimaryHDU(
                  data=hdu.data*10**c,
                  header=hdu.header).writeto(fn_new, clobber=True)
              print(fn_new)
  
#+END_SRC


#+BEGIN_SRC sh :results verbatim
source activate py27
python correct-for-extinction.py S_III-9069 -bin016
#+END_SRC

#+RESULTS:
: Skipping Linemaps/continuum-S_III-9069-bin016.fits SCALED
: Linemaps/linesum-S_III-9069-excorr-bin016.fits
: Linemaps/linesum-S_III-9069-excorr2-bin016.fits



*** Write out extinction maps C(H\beta), etc
#+BEGIN_SRC python :eval no :tangle make-extinction-maps.py
  from __future__ import print_function
  import sys
  import numpy as np
  import pyneb
  from astropy.io import fits

  # Set up Blagrave 2007 extinction law
  REDCORR = pyneb.extinction.red_corr.RedCorr(
      law='CCM89 Bal07', R_V=5.5, cHbeta=1.0)

  WAV_PASCHEN_BETA = 12820 

  def flambda(wav):
      """Find [(A_lam / A_Hb) - 1] as function of wavelength `wav`

      This is the same as given in Table 2 of Blagrave et al (2007)

      """
      return np.log10(REDCORR.getCorrHb(wav))


  def CHb_from_RHbHa(RHbHa, balmer0=2.874):
      """Find base-10 extinction at H beta from balmer decrement `RHbHa`

      Assumes that the intrinsic Balmer decrement is `balmer0`

      """
      return np.log10(balmer0*RHbHa) / flambda(6563)


  def CHb_from_R6563_9229(RBaPa, RBaPa0=112.0):
      """Find base-10 extinction at H beta from 6563/9229 decrement `RBaPa`

      Assumes that the intrinsic decrement is `RBaPa0`

      """
      return np.log10(RBaPa/RBaPa0) / (flambda(9229) - flambda(6563))


  if __name__ == '__main__':

      try:
          suffix = sys.argv[1] + '.fits'
          iHDU = 'SCALED'
      except:
          suffix = '.fits'
          iHDU = 0

      hdu = fits.open('Linemaps/ratio-4861-6563' + suffix)[iHDU]
      hb_ha = hdu.data
      ha_h9229 = fits.open('Linemaps/ratio-6563-9229' + suffix)[iHDU].data 
      chb = CHb_from_RHbHa(hb_ha)
      chb2 = CHb_from_R6563_9229(ha_h9229)

      # Find C(Pa b) / C(H b)
      paschen_b_factor = (1.0 + flambda(WAV_PASCHEN_BETA))
      print('C(Pa b) / C(H b) =', paschen_b_factor)

      for name, data in [['C_H_beta', chb],
                         ['C_Pa_beta', paschen_b_factor*chb],
                         ['C_H_beta_9229', chb2],
                         ['C_Pa_beta_9229', paschen_b_factor*chb2]]:
          fn = 'Linemaps/' + name + suffix
          fits.PrimaryHDU(data=data, header=hdu.header).writeto(fn, clobber=True)
          print(fn)

      #+END_SRC

#+BEGIN_SRC bash :results verbatim
source activate py27
python make-extinction-maps.py -bin004
#+END_SRC

#+RESULTS:


** Calculate effective depths of each ion

#+BEGIN_SRC python :eval no :tangle muse-depth.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  import pyneb 

  # Convert muse line surface brightness to erg/s/cm2/sr
  MUSE_CONSTANT = 1e-20 * 0.85 / (0.2 / 206265)**2

  ESTEBAN_ABUNDANCES = {
      'H': 12.00,  'He': 10.99, 'C': 8.42, 'N': 7.73, 'O': 8.65,
      'Ne': 8.05, 'S': 7.22, 'Cl': 5.46, 'Ar': 6.62, 'Fe': 6.0
  }

  ESTEBAN_ABUNDANCES_T2_EQUALS_0 = {
      'H': 12.00,  'He': 10.991, 'C': 8.42, 'N': 7.65, 'O': 8.51,
      'Ne': 7.78, 'S': 7.06, 'Cl': 5.33, 'Ar': 6.5, 'Fe': 5.86
  }

  LINE_DICT = {
      'N_II-6583': {
          'element': 'N',
          'atom': pyneb.Atom(atom='N2'),
          'wave': '6584A',
          'Te': 'Te',
          'Ne': 'Ne',
      },
      'S_II-6731': {
          'element': 'S',
          'atom': pyneb.Atom(atom='S2'),
          'wave': '6731A',
          'Te': 'Te',
          'Ne': 'Ne',
      },
      'S_III-9069': {
          'element': 'S',
          'atom': pyneb.Atom(atom='S3'),
          'wave': '9069A',
          'Te': 'Te-iii',
          'Ne': 'Ne-iii',
      },
      'Cl_III-5538': {
          'element': 'Cl',
          'atom': pyneb.Atom(atom='Cl3'),
          'wave': '5538A',
          'Te': 'Te-iii',
          'Ne': 'Ne-iii',
      },
      'Cl_II-8579': {
          'element': 'Cl',
          'atom': pyneb.Atom(atom='Cl2'),
          'wave': '8579A',
          'Te': 'Te',
          'Ne': 'Ne',
      },
      'Cl_IV-8046': {
          'element': 'Cl',
          'atom': pyneb.Atom(atom='Cl4'),
          'wave': '8579A',
          'Te': 'Te-iii',
          'Ne': 'Ne-iii',
      },
      'O_III-5007': {
          'element': 'O',
          'atom': pyneb.Atom(atom='O3'),
          'wave': '5007A',
          'Te': 'Te-iii',
          'Ne': 'Ne-iii',
      },
      'O_II-7330': {
          'element': 'O',
          'atom': pyneb.Atom(atom='O2'),
          'wave': '7330A',
          'Te': 'Te',
          'Ne': 'Ne',
      },
      'O_I-6300': {
          'element': 'O',
          'atom': pyneb.Atom(atom='O1'),
          'wave': '6300A',
          'Te': 'Te',
          'Ne': 'Ne',
      },
      'H_I-6563':{
          'element': 'H',
          'atom': pyneb.RecAtom('H', 1),
          'label': '3_2',
          'Te': 'Te-iii',
          'Ne': 'Ne-iii',
      },

  }


  D_M42_PC = 440.0
  AU_cm = 1.49597870691e13
  iHDU = 'SCALED'
  abundances = ESTEBAN_ABUNDANCES_T2_EQUALS_0

  def find_emissivity_map(lineid, suffix):
      d = LINE_DICT[lineid]
      Te = fits.open('LineMaps/muse-derived-' + d['Te'] + suffix)[iHDU].data
      Ne = fits.open('LineMaps/muse-derived-' + d['Ne'] + suffix)[iHDU].data
      abundance = 10**(abundances[d['element']] - 12.0)
      if 'wave' in d:
          e = d['atom'].getEmissivity(Te, Ne, wave=d['wave'], product=False)
      else:
          e = d['atom'].getEmissivity(Te, Ne, label=d['label'], product=False).T
      return abundance*Ne*Ne*e


  if __name__ == '__main__':
      try:
          lineid = sys.argv[1]
          suffix = sys.argv[2] + '.fits'
      except IndexError:
          print('Usage: {} LINEID SUFFIX')
    
      hdu = fits.open('LineMaps/linesum-{}-excorr{}'.format(lineid, suffix))[iHDU]
      s = MUSE_CONSTANT*hdu.data
      em = find_emissivity_map(lineid, suffix)
      d_cm = 4.0*np.pi * s / em
      d_arcsec = d_cm / (D_M42_PC*AU_cm)

      fn = 'LineMaps/emissivity-' + lineid + suffix
      fits.PrimaryHDU(data=em,
                      header=hdu.header).writeto(fn, clobber=True)
      print(fn)

      fn = 'LineMaps/depth-' + lineid + suffix
      fits.PrimaryHDU(data=d_arcsec,
                      header=hdu.header).writeto(fn, clobber=True)
      print(fn)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
source activate py27
time python muse-depth.py S_III-9069 -bin016
#+END_SRC

#+RESULTS:
: LineMaps/emissivity-S_III-9069-bin016.fits
: LineMaps/depth-S_III-9069-bin016.fits


*** DONE Make the depth maps for all binnings
CLOSED: [2016-03-31 Thu 20:02]
#+BEGIN_SRC sh :tangle multi-depth-maps.sh
  source activate py27
  for bin in 001 002 004 008 016 032 064 128 256; do
      for emline in S_II-6731 N_II-6583 S_III-9069 Cl_III-5538 O_II-7330 H_I-6563 O_III-5007; do
          time python correct-for-extinction.py $emline -bin$bin
          time python muse-depth.py $emline -bin$bin
      done
  done

#+END_SRC

*** DONE Make multi-resolution depth maps at constant s/n
CLOSED: [2016-03-31 Thu 22:44]
:LOGBOOK:
CLOCK: [2016-03-31 Thu 20:04]--[2016-03-31 Thu 22:44] =>  2:40
:END:
+ I am going to mask on the s/n of the density, because it is too much work to try and calculate s/n of depth maps themselves
  + That would mean making fuzzed depth maps, which would take days
+ Based on [[id:CFEF861F-1888-435B-B2F0-B6C80AAD1448][multibin-combine-s-n.py - combine multiple binning levels for constant s/n]]
+ Luckily, we already have the masks - or do we?

#+BEGIN_SRC python :tangle multi-depth-combine-s-n.py
  from __future__ import print_function
  import sys
  import glob
  import numpy as np
  from astropy.io import fits
  try: 
      fileroot = sys.argv[1]
      target_signal_to_noise = int(sys.argv[2])
      maskroot = sys.argv[3]
      newsuff = sys.argv[4]
  except IndexError:
      sys.exit('Usage: {} FILEROOT S/N MASKROOT NEWSUFF')
  
  prefix = 'LineMaps/'
  snlabel = 'SN{:04d}'.format(target_signal_to_noise)
  outim = None
  nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]
  for n in reversed(nlist):
      # Read in data
      fn = prefix + '{}-bin{:03d}.fits'.format(fileroot, n)
      hdu = fits.open(fn)['SCALED']
      if outim is None:
          # One-time setup to do on first iteration
          hdr = hdu.header
          # set up image for output
          outim = np.empty_like(hdu.data)

      # Read in mask
      mfn = fn.replace(fileroot,
                       '{}-mask-{}'.format(maskroot, snlabel))
      try:
          mask = fits.open(mfn)['SCALED'].data.astype(np.bool)
      except IOError:
          sys.exit(mfn + ' not found. Try running multibin-mask-s-n.py first.')
      # mask = mask & (hdu.data > 0.0)

      # Paste into image and into saved s/n
      outim[mask] = hdu.data[mask]

  out_fn = '{}{}-multibin-{}.fits'.format(prefix, fileroot, newsuff)
  fits.PrimaryHDU(header=hdr, data=outim).writeto(out_fn, clobber=True)
  print(out_fn)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
python multi-depth-combine-s-n.py depth-H_I-6563 20 linesum-Cl_III-5538 Clmask
python multi-depth-combine-s-n.py depth-O_III-5007 20 linesum-Cl_III-5538 Clmask
python multi-depth-combine-s-n.py depth-S_III-9069 20 linesum-Cl_III-5538 Clmask
python multi-depth-combine-s-n.py depth-Cl_III-5538 20 linesum-Cl_III-5538 Clmask
#+END_SRC

#+RESULTS:
: LineMaps/depth-H_I-6563-multibin-Clmask.fits
: LineMaps/depth-O_III-5007-multibin-Clmask.fits
: LineMaps/depth-S_III-9069-multibin-Clmask.fits
: LineMaps/depth-Cl_III-5538-multibin-Clmask.fits

#+BEGIN_SRC sh :results verbatim
python multi-depth-combine-s-n.py depth-H_I-6563  10 muse-derived-Ne-iii Ne3mask 
python multi-depth-combine-s-n.py depth-S_II-6731 10 muse-derived-Ne-iii Ne3mask 
python multi-depth-combine-s-n.py depth-O_II-7330 10 muse-derived-Ne-iii Ne3mask 
python multi-depth-combine-s-n.py depth-N_II-6583 10 muse-derived-Ne-iii Ne3mask 
#+END_SRC

#+RESULTS:
: LineMaps/depth-H_I-6563-multibin-Ne3mask.fits
: LineMaps/depth-S_II-6731-multibin-Ne3mask.fits
: LineMaps/depth-O_II-7330-multibin-Ne3mask.fits
: LineMaps/depth-N_II-6583-multibin-Ne3mask.fits

*** Take ratios of the depth maps wrt H+ 
#+BEGIN_SRC sh :results verbatim
python muse_line_ratio.py S_II-6731 H_I-6563 depth multibin-Ne3mask
python muse_line_ratio.py O_II-7330 H_I-6563 depth multibin-Ne3mask
python muse_line_ratio.py N_II-6583 H_I-6563 depth multibin-Ne3mask
#+END_SRC

#+RESULTS:
: LineMaps/depth-S_II-6731-multibin-Ne3mask.fits LineMaps/depth-H_I-6563-multibin-Ne3mask.fits
: LineMaps/depth-O_II-7330-multibin-Ne3mask.fits LineMaps/depth-H_I-6563-multibin-Ne3mask.fits
: LineMaps/depth-N_II-6583-multibin-Ne3mask.fits LineMaps/depth-H_I-6563-multibin-Ne3mask.fits

#+BEGIN_SRC sh :results verbatim
python muse_line_ratio.py O_III-5007 H_I-6563 depth multibin-Clmask
python muse_line_ratio.py S_III-9069 H_I-6563 depth multibin-Clmask
python muse_line_ratio.py Cl_III-5538 H_I-6563 depth multibin-Clmask
#+END_SRC

#+RESULTS:
: LineMaps/ratio-depth-5007-6563-multibin-Clmask.fits already up to date.  Use force=True to recreate regardless.
: LineMaps/ratio-depth-9069-6563-multibin-Clmask.fits already up to date.  Use force=True to recreate regardless.
: LineMaps/ratio-depth-5538-6563-multibin-Clmask.fits already up to date.  Use force=True to recreate regardless.

+ So it works fine for S, with the S+ and S++ mirroring each other (with missing part from S+++)
+ But for O it fails miserably.  O++ is fine, but O+ is too large by a factor of 4
  + Could be that density is underestimated by a factor of 2

* MUSE spectra as a check on fidelity of filter-derived line ratios
** Calculate MUSE line ratios directly from emission line maps
+ [2015-11-08 Sun 15:11] Edited to do dependency checking and only recalculate ratios if the numerator or denominator map is newer
  + Use =force=True= to make it recalculate a fuerzas
  + [X] Needs testing
    + Works fine [2015-11-08 Sun 17:28] - now rolling it out for [[id:D49AD965-AFDC-4D58-9341-8202DD8508D3][multibin-map.py]] too
+ [2015-11-08 Sun] This will now be called by program in [[id:07D1CD25-8319-4634-904D-A3A4CBC10E8D][Rewrite of multibin and fuzzed ratios]]
+ Note that [[id:125BB238-D032-4FAD-B6DA-FBFB14DAD3AF][Ratio of multibin maps]] has scripts that run this program
#+BEGIN_SRC python :tangle muse_line_ratio.py
  from __future__ import print_function
  import sys
  from astropy.io import fits
  from distutils.dep_util import newer, newer_group

  def save_line_ratio_map(line1, line2,
                          prefix='linesum', suffix='',
                          mapdir='LineMaps', force=False):
      fn1 = '{}/{}-{}{}.fits'.format(mapdir, prefix, line1, suffix)
      fn2 = '{}/{}-{}{}.fits'.format(mapdir, prefix, line2, suffix)
      wav1 = line1.split('-')[-1]
      wav2 = line2.split('-')[-1]
      if prefix == 'linesum':
          fn_out = '{}/ratio-{}-{}{}.fits'.format(
              mapdir, wav1, wav2, suffix)
      else:
          fn_out = '{}/ratio-{}-{}-{}{}.fits'.format(
              mapdir, prefix, wav1, wav2, suffix)

      if newer_group([fn1, fn2], fn_out) or force:
          print(fn1, fn2)
          hdu1 = fits.open(fn1)[0]
          if hdu1.data is None:
              hdu1 = fits.open(fn1)[1]
          hdu2 = fits.open(fn2)[0]
          if hdu2.data is None:
              hdu2 = fits.open(fn2)[1]
          hdu1.data /= hdu2.data
          hdu1.writeto(fn_out, clobber=True)
      else:
          print(fn_out, 'already up to date.  Use force=True to recreate regardless.')

  if __name__ == '__main__':
      try:
          line1 = sys.argv[1]
          line2 = sys.argv[2]
      except IndexError:
          sys.exit('Usage: {} LINE1 LINE2 [PREFIX] [SUFFIX]'.format(sys.argv[0]))

      try:
          prefix = sys.argv[3]
      except IndexError:
          prefix = 'linesum'

      try:
          suffix = '-' + sys.argv[4]
      except IndexError:
          suffix = ''

      save_line_ratio_map(line1, line2, prefix, suffix)
      

#+END_SRC

S III ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py S_III-6312 S_III-9069
#+END_SRC

Cl III ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py Cl_III-5538 Cl_III-5518
#+END_SRC

N II ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py N_II-5755 N_II-6583
#+END_SRC

N II/Ha
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py N_II-6583 H_I-6563
#+END_SRC

S II/Ha
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py S_II-6731 H_I-6563
#+END_SRC

O III/Ha
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py O_III-5007 H_I-6563
#+END_SRC

S II ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py S_II-6716 S_II-6731
#+END_SRC

Balmer decrement
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py H_I-6563 H_I-4861
#+END_SRC

Balmer decrement upside down for good measure
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py H_I-4861 H_I-6563
#+END_SRC

Paschen-Balmer decrement
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py  H_I-9229 H_I-6563
#+END_SRC

And other way up
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py  H_I-6563 H_I-9229
#+END_SRC

Paschen-Paschen decrement
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py  H_I-8545 H_I-9229
python muse_line_ratio.py  H_I-8598 H_I-9229
python muse_line_ratio.py  H_I-8750 H_I-9229
python muse_line_ratio.py  H_I-8863 H_I-9229
python muse_line_ratio.py  H_I-9015 H_I-9229
#+END_SRC

N II sanity check
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py N_II-6548 N_II-6583
#+END_SRC

O III sanity check
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py O_III-4959 O_III-5007
#+END_SRC

O II red lines
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py O_II-7318 O_II-7330
#+END_SRC

He I ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py He_I-5876 He_I-6678
#+END_SRC

Ar III line ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py Ar_III-7136 Ar_III-7751
#+END_SRC

O I permitted lines ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py O_I-7254 O_I-8446
#+END_SRC

This doesn't work - I need to do the fuzzing s/n on the ratio maps
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py O_I-7254 O_I-8446 linesum bin016
#+END_SRC



*** Continuum ratios to see spatial variations in slope

This one doesn't work because of contamination by Balmer line wings
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py H_I-4861 H_I-6563 continuum
#+END_SRC

This one is the best - blue side of 5755
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py Fe_III-4658 N_II-5755 continuum
#+END_SRC

And this one covers red side of 5755
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py N_II-5755 S_II-6731 continuum
#+END_SRC

+ It looks like these ratios do correlate well with equivalent width
  + But that remains to be tested
+ Also should have secondary correlation with reddening
  + But that is not so apparent
    + At least not for the highest extinction, where we seem to have bluer spectra
    + But for the brightest parts, we do maybe have redder continuum where extinction is higher




** Calculate MUSE line ratio maps indirectly from synthetic filters
:PROPERTIES:
:ID:       385E5413-D978-4DE6-98C2-BC893905316B
:END:
+ We start from the =muse-hr-image-wfc3-f*.fits= maps
+ These were created using the nominal throughputs, so we need to back transform them using the same nominal throughputs
+ We do this using nebulio
+ [2015-10-20 Tue] Also, take ratio with the true line ratio
#+BEGIN_SRC sh 
mkdir NebulioMUSE
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :tangle muse-nebulio-line-ratios.py
  from __future__ import print_function
  from misc_utils import sanitize_string
  from astropy.io import fits
  import nebulio
  print(nebulio.__version__)

  # Mean and std of the color terms ktwiddle
  # This is copied from ratio-sensitivity-nebulio.py in the Tsquared folder
  COLOR_TERMS_MEAN_SIG = {
      FQ674N: (1.00, 0.10), 
      F673N:  (1.00, 0.10), 
      FQ672N"": (0.99, 0.10), 
      "F658N":  (1.04, 0.11), 
      "F656N":  (1.04, 0.11), 
      "FQ575N": (0.95, 0.03), 
      "F547M":  (1.03, 0.01), 
      "F502N":  (1.10, -0.04), 
      "F487N":  (1.06, -0.06), 
  #    "F487N":  (1.65, -0.06), 
      "FQ437N": (1.41, -0.13), 
      "FQ436N": (1.87, -0.08), 
  }
  def get_color_term(fname="FQ575N", kshift=0.0):
      """Return color term for filter `fname`, shifted `kshift` stdevs from mean"""
      mean, sigma = COLOR_TERMS_MEAN_SIG[fname]
      return mean + kshift*sigma

  filtersets = {
      "5755-6583": {"line1": "[N II] 5755", "line2": "[N II] 6583",
                           "I": "FQ575N", "II": "F658N", "III": "F547M"},
      "6716-6731": {"line1": "[S II] 6716", "line2": "[S II] 6731",
                           "I": "FQ672N", "II": "FQ674N", "III": "F547M"}, 
      "6716-6731-N": {"line1": "[S II] 6716", "line2": "[S II] 6731",
                           "I": "FQ672N", "II": "FQ674N", "III": "F673N"}, 
      "4861-6563": {"line1": "H I 4861", "line2": "H I 6563",
                           "I": "F487N", "II": "F656N", "III": "F547M"},
  }


  def get_fits_data(fn='FQ575N'):
      hdu = fits.open('muse-hr-image-wfc3-{}.fits'.format(fn.lower()))['DATA']
      return hdu.data

  def get_fits_header(fn='FQ575N'):
      hdu = fits.open('muse-hr-image-wfc3-{}.fits'.format(fn.lower()))['DATA']
      return hdu.header

  heliocentric_correction = -16.2
  default_velocity =  25.0 + heliocentric_correction
  default_width = 20.0

  for ratio_name, filterset in filtersets.items():
      FI, FII, FIII = [filterset[J] for J in ("I", "II", "III")]
      print(FI, FII, FIII)
      RI = get_fits_data(FI)
      RII = get_fits_data(FII)
      RIII = get_fits_data(FIII)
      print(RIII[::100, ::100])
      lineids = filterset['line1'], filterset['line2']
      bpnames = ['wfc3,uvis1,' + F for F in (FI, FII, FIII)]
      fset = nebulio.Filterset(bpnames, lineids,
                               velocity=default_velocity, fwhm_kms=default_width)
      kI = get_color_term(FI)/get_color_term(FIII)
      kII = get_color_term(FII)/get_color_term(FIII)
      print('Color terms:', kI ,kII)
      ratio = fset.find_line_ratio(rates=[RI, RII, RIII], colors=(kI, kII), naive=False)
      ratio_naive = fset.find_line_ratio(rates=[RI, RII, RIII], colors=(kI, kII), naive=True)
      # And if we just ignore the color terms
      ratio_flat = fset.find_line_ratio(rates=[RI, RII, RIII], colors=(1.0, 1.0), naive=False)

      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio)
      outhdu.writeto(
          'NebulioMUSE/synthetic-ratio-{}.fits'.format(ratio_name),
          clobber=True)

      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_naive)
      outhdu.writeto(
          'NebulioMUSE/synthetic-naive-ratio-{}.fits'.format(ratio_name),
          clobber=True)

      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_flat)
      outhdu.writeto(
          'NebulioMUSE/synthetic-flat-ratio-{}.fits'.format(ratio_name),
          clobber=True)

      # Take ratio of ratios between simulated and true
      # Ignore anything after the second dash in finding the true ratio name
      ratio_name_true = '-'.join(ratio_name.split('-')[:2])
      fn_true = 'LineMaps/ratio-{}.fits'.format(ratio_name_true)
      ratio_true = fits.open(fn_true)[0].data
      ratio_of_ratios = ratio/ratio_true
      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_of_ratios)
      outhdu.writeto(
          'NebulioMUSE/synthetic-over-true-ratio-{}.fits'.format(ratio_name),
          clobber=True)
      # And the same for the naive/true
      ratio_of_ratios = ratio_naive/ratio_true
      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_of_ratios)
      outhdu.writeto(
          'NebulioMUSE/synthetic-naive-over-true-ratio-{}.fits'.format(ratio_name),
          clobber=True)
      # And the same for the flat/true
      ratio_of_ratios = ratio_flat/ratio_true
      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_of_ratios)
      outhdu.writeto(
          'NebulioMUSE/synthetic-flat-over-true-ratio-{}.fits'.format(ratio_name),
          clobber=True)
          
#+END_SRC

#+BEGIN_SRC sh
export PYTHON_CDBS=~/Dropbox/CDBS
python muse-nebulio-line-ratios.py 1>&2
#+END_SRC

#+RESULTS:

+ Mostly looks OK
+ [X] But there is a strange problem with hb/ha
  + The synthetic value comes out too large by about 5 to 10%
  + I tried fiddling with the ktwiddle color terms, but that didn't seem to work
  + [2015-10-22 Thu] All sorted now - it was a problem with which CDBS I used

** STARTED Two-D histogram of MUSE synthetic filter vs MUSE true line ratios
:LOGBOOK:
- Note taken on [2016-03-22 Tue 08:53] \\
  Re-visiting this to improve it for the appendix
:END:
+ Planned improvements
  + [ ] Allow mask to restrict region
  + 

#+BEGIN_SRC python :tangle histo-muse-ratios.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.convolution import convolve, Gaussian2DKernel
  from matplotlib import pyplot as plt
  import seaborn as sns
  import pyregion
  from specplot1d_utils import plot_1d_spec_from_fits

  plotpars = {
      '6716-6731': {'line1': '[S II] 6716', 'line2': '[S II] 6731',
                    'min': 0.4, 'max': 0.8},
      '6716-6731-N': {'line1': '[S II] 6716', 'line2': '[S II] 6731',
                    'min': 0.4, 'max': 0.8},
      '5755-6583': {'line1': '[N II] 5755', 'line2': '[N II] 6583',
                    'min': 0.00, 'max': 0.05},
      '4861-6563': {'line1': 'H I 4861', 'line2': 'H I 6563',
                    'min': 0.2, 'max': 0.35},
    }

  titles_from_extra = {
      '': 'Fully continuum-corrected',
      '-naive': 'Uncorrected for continuum',
      '-flat': 'Continuum-corrected without color terms',
  }

  GAMMA = 1.0

  cmap = sns.light_palette((260, 50, 30), input="husl", as_cmap=True)
  # cmap = plt.cm.gray_r

  def histogram_ratio_images(ratio_name, pars, extra='', regionfile=None):
      ratio_name_true = '-'.join(ratio_name.split('-')[:2])
      fn_true = 'LineMaps/ratio-{}.fits'.format(ratio_name_true)
      fn_syn = 'NebulioMUSE/synthetic{}-ratio-{}.fits'.format(extra, ratio_name)
      pltname = 'NebulioMUSE/synthetic{}-vs-true-calib-{}.pdf'.format(extra, ratio_name)
      hdu_true = fits.open(fn_true)[0]
      hdu_syn = fits.open(fn_syn)[0]
      # Flux of a strong line to weight the pixels
      hduf = fits.open('LineMaps/linesum-N_II-6583.fits')[0]
      x, y, w = hdu_true.data, hdu_syn.data, hduf.data
      xmin, xmax = ymin, ymax = pars['min'], pars['max']
      # mask out silly values
      m = np.isfinite(x) & np.isfinite(y/x) & (np.abs(np.log10(y/x)) < 1.0)
      if regionfile is not None:
          m = m & pyregion.open(regionfile).get_mask(hdu=hduf)
      
      H, xedges, yedges = np.histogram2d(x[m], y[m], 50,
                                         [[xmin, xmax], [ymin, ymax]],
                                         weights=w[m])
      ratiotext = '{} / {}'.format(pars['line1'], pars['line2'])
      fig, ax = plt.subplots(1, 1)
      ax.imshow((H.T)**(1.0/GAMMA), extent=[xmin, xmax, ymin, ymax],
                interpolation='nearest', aspect='auto', origin='lower', 
                cmap=cmap, alpha=1.0)
      ax.plot([xmin, xmax], [xmin, xmax], '-', alpha=1.0,
              lw=1, c='r', label=None)
      ax.set_xlabel('MUSE spectrum-derived line ratio')
      ax.set_ylabel('MUSE synthetic WFC3 filter-derived line ratio')
      ax.set_xlim(xmin, xmax)
      ax.set_ylim(ymin, ymax)
      ax.text(0.5, 0.15, ratiotext,
              horizontalalignment='center', transform=ax.transAxes)
      ax.text(0.5, 0.05, titles_from_extra[extra],
              horizontalalignment='center', transform=ax.transAxes)

      fig.set_size_inches(4.5, 4.5)
      fig.tight_layout(pad=2)
      fig.savefig(pltname)

      return pltname


  if __name__ == '__main__':
      try:
          regionfile = sys.argv[1]
      except:
          regionfile = None
      for ratio_name, pars in plotpars.items():
          for extra in '', '-naive', '-flat':
              print(histogram_ratio_images(ratio_name, pars, extra, regionfile))

#+END_SRC

#+RESULTS:

+ This is now changed to use only the new restricted sweet spot
+ Along with some cosmetic improvements
#+BEGIN_SRC sh :results verbatim
python histo-muse-ratios.py new-combined-sweet.reg
#+END_SRC

#+RESULTS:
#+begin_example
NebulioMUSE/synthetic-vs-true-calib-6716-6731.pdf
NebulioMUSE/synthetic-naive-vs-true-calib-6716-6731.pdf
NebulioMUSE/synthetic-flat-vs-true-calib-6716-6731.pdf
NebulioMUSE/synthetic-vs-true-calib-6716-6731-N.pdf
NebulioMUSE/synthetic-naive-vs-true-calib-6716-6731-N.pdf
NebulioMUSE/synthetic-flat-vs-true-calib-6716-6731-N.pdf
NebulioMUSE/synthetic-vs-true-calib-4861-6563.pdf
NebulioMUSE/synthetic-naive-vs-true-calib-4861-6563.pdf
NebulioMUSE/synthetic-flat-vs-true-calib-4861-6563.pdf
NebulioMUSE/synthetic-vs-true-calib-5755-6583.pdf
NebulioMUSE/synthetic-naive-vs-true-calib-5755-6583.pdf
NebulioMUSE/synthetic-flat-vs-true-calib-5755-6583.pdf
#+end_example

#+BEGIN_SRC sh :result silent
open NebulioMUSE/synthetic-vs-true-calib-*.pdf
open NebulioMUSE/synthetic-naive-vs-true-calib-*.pdf
open NebulioMUSE/synthetic-flat-vs-true-calib-*.pdf
#+END_SRC

#+RESULTS:

#+RESULTS

** STARTED Now compare synthetic filter-derived ratios with real WFC3 filter-derived ones
:PROPERTIES:
:ID:       2FD346AB-80C2-4A4C-8448-DB7F16BE2AAD
:END:
:LOGBOOK:
- Note taken on [2016-03-22 Tue 13:51] \\
  Re-opening to do maps of these
CLOCK: [2015-10-21 Wed 21:19]--[2015-10-22 Thu 00:27] =>  3:08
:END:
+ [2015-10-21 Wed] I have using DS9
  + MUSE :: synthetic-ratio-5755-6583.fits
  + WFC3 :: newratio-5755-6583.fits
+ This works tolerably well now


*** Old comments
:PROPERTIES:
:ID:       770F8A60-75F6-4311-B920-9D4FA50114B5
:END:
+ They are significantly different
  + MUSE synthetic map has median ratio < 0.15 in faint parts
  + WFC3 map has median ratio > 0.15 in faint parts
+ But the real and synthetic filter images should be the same
  + If we look at =wfc3-over-muse-calib-ratio-F*.fits= then we find
    + F575N and F658N are fine
    + But F547M shows some discrepancies
      + Over most of the field the ratio is 0.9 rather than 1
      + Although I had interpreted that as a shift of origin
      + I think that is partly due to the hump of scattered light that comes down from Trapezium
    + F656N also shows a bit of a discrepancy
      + The ratio is 1.03 in the brighter part of the sweet spot (which is what we adopted from the straight line cuts)
      + But is more like 104 to 1.05 in the fainter parts
    + F673N is prety good at 1.0 apart from the hump
      + Not much justification for the 0.97, except for at the top, which is outsid ethe sweetspot
    + FQ672N looks like it has a gradient from 1.0 to 1.1 from the top left to bottom right, parallel to the chip - maybe there is a flat field error
      + We had interpreted this as an offset
      + But that does sort of fit too
    + FQ674N does not have this problem
+ *What would be the consequences of overestimating F547M?*
  + Means true continuum is higher than we had thought
  + So we should subtract more from the FQ575N filter, which will bring down the nii ratio
  + Which is what we want!

** Conclusions on spectra vs filters comparison with MUSE
1. In general it works very well
2. There are small residual correlations betwen line ratios and continuum color, which means the relations don't quite have unit slope
   - In the case of Hb/Ha this is probably due to the fact that continuum is reddened the same as the lines are - we could even correct for that
   - That same correction could even then be applied to the other filters
3. The [S II] ratio is best determined using the F673N filter to get the continuum
4. The [N II] ratio has a lot of noise, but then we knew that already
5. There was some strangeness with Hb/Ha
   - I had to bump up the color term a lot
   - At first I thought this was justified because the continuum looked blue
     - Even though the fig I had calculated from ODH said not
   - But now I realise that the relevant slope is in \lambda F_{\lambda}
     - Which is much flatter
   - So I am a bit confused, but going to move on anyhow

* Calibration of WFC3 filter using MUSE cube
:LOGBOOK:
CLOCK: [2015-10-07 Wed 09:58]--[2015-10-07 Wed 11:58] =>  2:00
:END:
+ The interesting sections are wavsec0 to wavsec3

** Extract subsets of the full cubes

*** Transposed cubes
+ These are taken from the section cubes that I made [[id:C2108CD1-EF28-4F63-9CA1-B7F9DA59C450][down here]]
  + Origina axis order is RA, Dec, Wav
+ They will look like longslit spectra in DS9 - at least that is the idea

**** TODO Stack of horizontal slits: Wav, RA, Dec
+ 1 2 3 -> 3 1 2
#+BEGIN_SRC sh :results verbatim
  MDIR=~/Source/Montage/bin
  $MDIR/mTranspose muse-hr-data-wavsec0.fits muse-hr-hslit-stack-wavsec0.fits 3 1 2
#+END_SRC

#+RESULTS:

+ Note that this takes a long time to run - even longer on my laptop
+ Best to do it in a terminal rather than with babel
+ They are too big (17GB each), so I have moved tham to a =BigFiles/= folder, which I am not synching with my laptop, only with hypatia

**** TODO Stack of vertical slits: Wav, Dec, RA
+ 1 2 3 -> 3 2 1

**** Bin them up to make them easier to use

***** DONE 1 arcsec pixels: 5x5 binning in RA and Dec
CLOSED: [2015-10-16 Fri 08:42]
+ First, work directly on the original cube sections
+ FITS order is RA, Dec, Wav
+ Python order is Wav, Dec, RA
+ Original NY, NX is 1476, 1766
  + If we chop off just 1 pixel on each axis, then we are divisible by 5
+ Work on one image at time to simplify things and reduce memory footprint
#+BEGIN_SRC python :tangle rebin_datacube.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits

  def rebin_xyimage(im, mx=5, my=5):
      ny, nx = im.shape
      # Shape of new rebinned array
      nny, nnx = ny//my, nx//mx
      # Shave a bit off original array so shape is multiple of m
      # And then concertina each axis to be 4-dimensional
      im4d = im[:nny*my, :nnx*mx].reshape((nny, my, nnx, mx))
      # Average along the mx, my axes
      return np.nansum(im4d, axis=(1, 3))


  def rebin_hdu(hdu, m=(5, 5)):
      mx, my = m                  # FITS axis order
      nv, ny, nx = hdu.data.shape  # Python axis order
      nny, nnx = ny//my, nx//mx
      newdata = np.empty((nv, nny, nnx))
      for k in range(nv):
          print('Rebinning plane {}/{}'.format(k+1, nv))
          newdata[k] = rebin_xyimage(hdu.data[k], mx, my)
      newhdu = fits.PrimaryHDU(header=hdu.header, data=newdata)
      # New pixel deltas are bigger
      if 'CDELT1' in newhdu.header:
          newhdu.header['CDELT1'] *= mx
          newhdu.header['CDELT2'] *= my
      else:
          # assume no rotation
          newhdu.header['CD1_1'] *= mx
          newhdu.header['CD2_2'] *= my
        
           # pix=0.5 is left edge of first pixel
      newhdu.header['CRPIX1'] = 0.5 + (newhdu.header['CRPIX1'] - 0.5)/mx
      newhdu.header['CRPIX2'] = 0.5 + (newhdu.header['CRPIX2'] - 0.5)/my

      return newhdu

  if __name__ == '__main__':
      try:
          infilename = sys.argv[1]
          m = int(sys.argv[2]), int(sys.argv[3])
      except IndexError:
          sys.exit('Usage: {} FITSFILE BINX BINY'.format(sys.argv[0]))

      hdu = fits.open(infilename)['DATA']
      newsuffix = '-rebin{:02d}x{:02d}.fits'.format(*m)
      outfilename = infilename.replace('.fits', newsuffix)
      rebin_hdu(hdu, m).writeto(outfilename, clobber=True)

#+END_SRC

+ These should all be run in an interactive shell
+ First, test it with a small file
  #+BEGIN_SRC sh :eval no
  python rebin_datacube.py muse-hr-window-wfc3-fq575n.fits 5 5
  #+END_SRC
+ Then do all the big sections
  #+BEGIN_SRC sh :eval no :tangle rebin-all-wavsecs.sh
    for i in $(seq 7); do
        python rebin_datacube.py muse-hr-data-wavsec$i.fits 5 5
    done
  #+END_SRC


***** Glue all the wavsecs back together again to make one big spectrum
If we demote the data arrays to 32 bit reals, then this should be still less than 2GB for the 5x5 spatial binning

#+BEGIN_SRC python :tangle reassemble-fullcube.py
  from __future__ import print_function
  import numpy as np
  from astropy.io import fits

  def reassemble(nsec=8, suffix='rebin05x05'):
      template = 'muse-hr-data-wavsec{isec}-{suffix}.fits'

      cubes = []
      for isec in range(nsec):
          fn = template.format(isec=isec, suffix=suffix)
          hdulist = fits.open(fn)
          hdu = hdulist[0]
          # The full cube will use the header from the first section
          if isec == 0:
              hdr = hdu.header.copy()
          # Save this section of the cube 
          cubes.append(hdu.data.astype(np.float32))
          print('Section', isec, 'saved')
          hdulist.close()
      newhdu = fits.PrimaryHDU(header=hdr, data=np.concatenate(cubes))
      outfile = 'muse-hr-fullcube-{suffix}.fits'.format(suffix=suffix)
      newhdu.writeto(outfile, clobber=True)
      return outfile

  if __name__ == '__main__':

      print('Reassembling cube ...')
      print('... done:', reassemble())
    
#+END_SRC

Run in interactive shell 
#+BEGIN_SRC sh :eval no
time python reassemble-fullcube.py
#+END_SRC


*** Spectral windows for each WFC3 filter
:PROPERTIES:
:header-args: :python /Users/will/anaconda/envs/py27/bin/python :preamble "from __future__ import print_function" :noweb yes
:END:

+ In principal the calibration can be done with just integrating the spectrum over the filter T reponse.
+ But we really need to fit Gaussians to the lines
+ Note that pysynphot requires Python 2.7
+ Also requires PYSYN_CDBS environment variable to be set
  + On linux server
#+BEGIN_SRC sh
export PYSYN_CDBS=/fs/nil/other0/will/CDBS
#+END_SRC


**** List of HST filters to use
:PROPERTIES:
:TABLE_EXPORT_FILE: all-filters-input.tab
:TABLE_EXPORT_FORMAT: orgtbl-to-tsv
:END:

Export this table to [[file:all-filters-input.tab]] with =C-c t e= after any modification. 

#+name: selected-filters
| Instrument | Filter |
|------------+--------|
| wfc3       | fq436n |
| wfc3       | fq437n |
| wfc3       | f469n  |
| wfc3       | f487n  |
| wfc3       | f502n  |
| wfc3       | f547m  |
| wfc3       | fq575n |
| wfc3       | f656n  |
| wfc3       | f658n  |
| wfc3       | fq672n |
| wfc3       | f673n  |
| wfc3       | fq674n |
|------------+--------|
| wfpc2      | f437n  |
| wfpc2      | f469n  |
| wfpc2      | f487n  |
| wfpc2      | f502n  |
| wfpc2      | f547m  |
| wfpc2      | f631n  |
| wfpc2      | f656n  |
| wfpc2      | f658n  |
| wfpc2      | f673n  |
|------------+--------|
| acs        | f658n  |
| acs        | f660n  |
| acs        | f435w  |
| acs        | f555w  |
| acs        | f775w  |
| acs        | f850lp |


Send all tables to linux server
#+BEGIN_SRC sh :results verbatim
rsync -aPq *.tab nil:/fs/nil/other0/will/orion-muse
#+END_SRC

#+RESULTS:

#+name: bandpass-fullname-function
#+BEGIN_SRC python
  def bp_fullname(instrument, filter_):
      if instrument.lower() == 'wfc3':
          return 'wfc3,uvis1,'+filter_.lower()
      elif instrument.lower() == 'acs':
          return 'acs,wfc1,'+filter_.lower()
      elif instrument.lower() == 'wfpc2':
          return 'wfpc2,'+filter_.lower()
      else:
          raise NotImplementedError('Unknown instrument: ' + instrument)
#+END_SRC


**** DONE [1/1] Print out the mean wavelength and rectangular width of each filter
CLOSED: [2015-10-08 Thu 11:25]
#+name: extract-bandpasses 
#+BEGIN_SRC python :return outtab
  import pysynphot
  from astropy.table import Table
  <<bandpass-fullname-function>>
  float_fmt = '{:.2f}'
  intab = Table.read('all-filters-input.tab', format='ascii.tab')
  outtab = [['Filter', 'Wav0', 'dWav'], None]
  for row in intab:
      fn = bp_fullname(row['Instrument'], row['Filter'])
      bp = pysynphot.ObsBandpass(fn)
      outtab.append([fn, float_fmt.format(bp.avgwave()), float_fmt.format(bp.rectwidth())])
#+END_SRC

#+RESULTS: extract-bandpasses
| Filter            |    Wav0 |    dWav |
|-------------------+---------+---------|
| wfc3,uvis1,fq436n | 4367.22 |   43.36 |
| wfc3,uvis1,fq437n | 4371.09 |   29.99 |
| wfc3,uvis1,f469n  | 4688.14 |   49.67 |
| wfc3,uvis1,f487n  | 4871.42 |   60.41 |
| wfc3,uvis1,f502n  | 5009.71 |   65.27 |
| wfc3,uvis1,f547m  | 5451.37 |  649.89 |
| wfc3,uvis1,fq575n | 5757.87 |   18.37 |
| wfc3,uvis1,f656n  | 6561.44 |   17.65 |
| wfc3,uvis1,f658n  | 6584.91 |   27.55 |
| wfc3,uvis1,fq672n | 6716.62 |   19.37 |
| wfc3,uvis1,f673n  | 6766.04 |  117.78 |
| wfc3,uvis1,fq674n | 6730.77 |   17.63 |
| wfpc2,f437n       | 4369.57 |   31.84 |
| wfpc2,f469n       | 4694.55 |   33.10 |
| wfpc2,f487n       | 4865.48 |   33.93 |
| wfpc2,f502n       | 5013.41 |   35.80 |
| wfpc2,f547m       | 5487.62 |  638.11 |
| wfpc2,f631n       | 6306.45 |   42.14 |
| wfpc2,f656n       | 6563.57 |   28.34 |
| wfpc2,f658n       | 6590.91 |   39.24 |
| wfpc2,f673n       | 6732.30 |   63.31 |
| acs,wfc1,f658n    | 6584.05 |   74.94 |
| acs,wfc1,f660n    | 6599.50 |   35.69 |
| acs,wfc1,f435w    | 4338.43 |  862.30 |
| acs,wfc1,f555w    | 5373.22 | 1124.61 |
| acs,wfc1,f775w    | 7705.71 | 1320.72 |
| acs,wfc1,f850lp   | 9049.59 | 1261.35 |

+ [X] Test that this works on linux server



**** Decomposing the components that go into the throughput curve

This is done in [[file:wfc3-throughput-components.py]]

Use the STScI python install for a change
#+BEGIN_SRC sh :results file :file wfc3-throughput-components.pdf
source ~/.bash_profile
ur_setup
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python wfc3-throughput-components.py
#+END_SRC

#+RESULTS:
[[file:wfc3-throughput-components.pdf]]

This is a plot of all the components that multiply together to make the filter throughput:
+ hst_ota :: Optical Telescope Assembly.  I think this is the primary mirror efficiency, accounting for fraction of circular area that is obscured by secondary. Roughly constant at about 0.65
+ wfc3_uvis_ccd1 :: Efficiency of CCD, roughly constant at ~ 0.87
  + Note that CCD2 is extremely similar.  The difference is less than 0.5%
+ wfc3_uvis_owin :: Outer window transmission, roughly 0.95
+ wfc3_uvis_cor :: Correction based on white dwarf photometry. Roughly 1.18 but falling to red.
+ wfc3_uvis_mir1 :: Internal camera mirror efficiency, roughly 0.9
+ wfc3_uvis_mir2 :: Another mirror efficiency, roughly 0.9
+ wfc3_uvis_iwin :: Internal window, roughly 0.95
+ wfc3_pom_001 :: Pick Off Mirror (45 deg mirror that diverts light into instrument), roughly 0.88
+ wfc3_uvis_f547m :: The filter itself, roughly 0.85 

Multiplying them all together gives the total transmission of src_calc{0.65 0.87 0.95 1.18 0.9 0.9 0.95 0.88 0.85} {{{results(=0.364878642843=)}}}, which matches what is expected for the total bandpass.


***** DONE Variation with time
CLOSED: [2015-10-13 Tue 09:23]
+ According to [[http://ssb.stsci.edu/pysynphot/docs/appendixb.html#pysynphot-appendixb][Appendix B of the pysynphot docs]] we can ask for the filter throughput for a particular MJD using e.g., 'wfc3,uvis1,f658n,mjd#49486'
+ Today's Julian date is src_calc{julian(<Tue Oct 13, 2015>) - 2400000} {{{results(=57307=)}}}
+ Orion S observations were around MJD=55933
+ Plot various dates in [[file:wfc3-throughput-evolution.py]]
#+BEGIN_SRC sh :results file :file wfc3-throughput-evolution.pdf
source ~/.bash_profile
ur_setup
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python wfc3-throughput-evolution.py
#+END_SRC

#+RESULTS:
[[file:wfc3-throughput-evolution.pdf]]

Upshot is that there is no discernible difference with time, and also that the Quantum Yield Correction makes no difference at the shortest wavelengths that we are interested in (4700 Angstrom), 

src_python{import sys; return sys.version.split(' ')[0]} {{{results(=2.7.10=)}}} 

**** TODO Converting surface brightness to predicted counts
+ Note that =bp.primary_area= is given as 45238.93416, which must be in sq cm.  This is same as src_calc{pi*(120)**2} {{{results(=45238.9342117=)}}} 
+ The units of the muse data is given as '10**(-20)*erg/s/cm**2/Angstrom'
  + This must be per pixel, I assume
  + Each pixel is 0.2 arcsec square, so this is src_calc{(0.2/206265)**2} {{{results(=9.40175455274e-13=)}}} steradian
+ [ ] We have summed this in wavelength, but we really should have multiplied by lambda first to convert from energy to photon units
  + And while we are at it we can use the C_{WFC3} to put it in electron/s



**** Air to vacuum wavelength conversion
+ This depends on refractive index of air, given by the following function
+ To convert air -> vacuum we multiply the wavelengths by the refractive index
+ 

#+name: air-refractive-index
#+BEGIN_SRC python
  from astropy import units as u
  def air_refractive_index(wav):
      """Equation (65) of Greisen et al 2006 for the refractive index of air
  at STP.  Input wavelength 'wav' should be in microns or in any
  'astropy.units' unit. It does not matter if 'wav' is on air or vacuum
  scale

      """
      try:
          # Convert to microns if necessary
          wavm = wav.to(u.micron).value
      except AttributeError:
          # Assume already in microns
          wavm = wav
      return 1.0 + 1e-6*(287.6155 + 1.62887/wavm**2 + 0.01360/wavm**4)

#+END_SRC
**** TODO [5/5] Process spectral windows for each filter
+ This could be the last step that we would have to run on the server
+ If the files are small enough then they can be copied over to the macs
+ Each of the following snippets is run interactively on the server
***** DONE Imports
CLOSED: [2015-10-08 Thu 12:00]
#+name: astro-imports
#+BEGIN_SRC python
  from astropy.io import fits
  from astropy import wcs
  from astropy.table import Table
  import pysynphot
  import numpy as np
#+END_SRC
***** DONE Read FITS cube
CLOSED: [2015-10-08 Thu 12:00]
#+BEGIN_SRC python
  hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_78380e1d.fits')
#+END_SRC
***** DONE Set up a vacuum wavelength scale
CLOSED: [2015-10-08 Thu 14:01]
#+namer: setup-wavs
#+BEGIN_SRC python
  <<air-refractive-index>>
  w = wcs.WCS(hdulist['DATA'].header)
  NV, NY, NX = hdulist['DATA'].data.shape
  # construct array of observed air wavelengths (at image center to be safe)
  _, _, wavs = w.all_pix2world([NX/2]*NV, [NY/2]*NV, np.arange(NV), 0) 
  # Make dimensional
  wavs *= u.m
  # Convert to vacuum scale
  wavs *= air_refractive_index(wavs)
#+END_SRC
***** DONE Read in the table of filters
CLOSED: [2015-10-08 Thu 14:08]
#+BEGIN_SRC python
  intab = Table.read('all-filters-input.tab', format='ascii.tab')
#+END_SRC
***** DONE Extract the windows for each filter
CLOSED: [2015-10-12 Mon 09:18]
#+BEGIN_SRC python
  <<bandpass-fullname-function>>
  for row in intab:
      bpname = bp_fullname(row['Instrument'], row['Filter'])
      bp = pysynphot.ObsBandpass(bpname)
      # extend a full rectwidth either side of the average wavelength to fit it all in
      wav_window = bp.avgwave() + bp.rectwidth()*np.array([-1, 1])
      # Add in the units (all are in Angstrom I hope)
      assert bp.waveunits.name == 'angstrom'
      wav_window *= u.Angstrom
      # convert to air wavelengths to agree with the WCS
      wav_window /= air_refractive_index(wav_window)
      # Now convert to fractional pixel coordinates
      _, _, [k1, k2] = w.all_world2pix([0, 0], [0, 0], wav_window.to(u.m), 0)
      # smallest slice that covers the window
      wavslice = slice(int(k1), int(k2) + 2)
      # tuple of slices for the 3 cube axes (in numpy array order: V, Y, X)
      cubeslices = [wavslice, slice(None, None), slice(None, None)]

      newhdr = hdulist['DATA'].header.copy()
      newhdr.update(w.slice(cubeslices).to_header())

      # Make a new HDUlist for the windowed spectrum and write it out
      fits.HDUList(
          [fits.PrimaryHDU(header=hdulist[0].header, data=None),
           fits.ImageHDU(header=newhdr, data=hdulist['DATA'].data[cubeslices])
          ]
      ).writeto('muse-hr-window-{}-{}.fits'.format(row['Instrument'], row['Filter']), clobber=True)
#+END_SRC


**** Cleaning up the window FITS files for DS9
:PROPERTIES:
:ID:       45AB8659-4D07-4EE5-A3DC-FECF9C10833D
:END:
For some reason, ds9 does not like the wavelength WCS, so we will try and fix it:
+ Put the physical scales in the CDELTi instead of in the PCi_j
+ Put it in angstrom instead of m
+ That's it to start with
#+BEGIN_SRC python :tangle clean_up_wav_wcs.py
  import sys
  from astropy.io import fits
  def clean_up_wav_wcs(filename):
      hdulist = fits.open(filename, mode='update')
      for hdu in hdulist:
          if hdu.header.get('CUNIT3') == 'm':
              # Change to Angstrom
              hdu.header['PC3_3'] *= 1e10
              hdu.header['CRVAL3'] *= 1e10
              hdu.header['CUNIT3'] = 'Angstrom'
              # And move scales to CDELT
              for i in '123':
                  CDELTi = 'CDELT'+i
                  # Sanity check
                  assert hdu.header.get(CDELTi) == 1.0
                  PCi_j = 'PC{0}_{0}'.format(i)
                  hdu.header[CDELTi], hdu.header[PCi_j] = hdu.header[PCi_j], hdu.header[CDELTi] 
      hdulist.flush()


  if __name__ == '__main__':
      try:
          fn = sys.argv[1]
          clean_up_wav_wcs(fn)
      except IndexError:
          print('Usage:', sys.argv[0], 'FITSFILE')
        
#+END_SRC
Export with =C-u C-c C-v C-t=

Test it on the WFC3 f656n file

#+BEGIN_SRC sh :results silent
python clean_up_wav_wcs.py muse-hr-window-wfc3-fq674n.fits
#+END_SRC

That seemed to work

#+BEGIN_SRC sh :results silent
python clean_up_wav_wcs.py muse-hr-window-wfc3-f487n.fits
#+END_SRC

**** DONE Convert from erg/cm2/s/Angstrom to electron/s
CLOSED: [2015-10-13 Tue 12:50]
:LOGBOOK:
- Note taken on [2015-10-13 Tue 09:58]
:END:
+ The fundamental equation is \(R_{}_j = C_{WFC3 }\int \lambda I_\lambda T_\lambda d\lambda\)
  + Where C_{WFC3 }= 0.0840241 if \lambda is in \AA
+ So, we need to multiply by lambda when we do the flattening
+ Also, we need to get from MUSE's flux-per-pixel to brightness (per-steradian)
  + This means we divide by the MUSE pixel area of 9.40175455274e-13 sr
+ AND we need to multiply by the MUSE bin width in \AA
+ Question is, do we apply this normalization to the =transwin= cubes?
  + Best not, so as to minimze churn of large files on Dropbox

#+name: flux-to-counts
#+BEGIN_SRC python
  from astropy import units as u
  WFC3_CONSTANT = 0.0840241
  MUSE_FLUX_UNITS = 1e-20 
  MUSE_PIXEL_AREA_SR = (0.2*u.arcsec).to(u.radian)**2

#+END_SRC
**** Fold the spectra through each filter to get simulated images
This does not have to be done on the server any more

#+BEGIN_SRC python :tangle filter-flatten.py 
  from __future__ import print_function
  import sys
  <<astro-imports>>
  <<air-refractive-index>>
  <<bandpass-fullname-function>>
  <<flux-to-counts>>

  def bandpass_flatten(instrument, bpname):
      filename = 'muse-hr-window-{}-{}.fits'.format(instrument, bpname)
      hdulist = fits.open(filename)
      hdu = hdulist['DATA']
      w = wcs.WCS(hdu.header)
      NV, NY, NX = hdu.data.shape
      # construct array of observed air wavelengths (at image center to be safe)
      _, _, wavs = w.all_pix2world([NX/2]*NV, [NY/2]*NV, np.arange(NV), 0) 
      # Make dimensional
      wavs *= u.m
      # Convert to vacuum scale
      wavs *= air_refractive_index(wavs)

      # Get bandpass for filter
      fn = bp_fullname(instrument, bpname)
      bp = pysynphot.ObsBandpass(fn)
      # Calculate transmission curve at the observed wavelengths
      T = bp(wavs.to(u.Angstrom).value)
      # Weight by transmission curve and save that
      hdu.data *= T[:, None, None]
      hdulist.writeto(filename.replace('-window-', '-transwin-'), clobber=True)
      # Integrate over wavelength, already weighted by transmission curve. But
      # now need to multiply by wavelength, put in brightness units, and
      # convert to WFC3 electron/s/pixel
      hdu.data *= WFC3_CONSTANT*MUSE_FLUX_UNITS/MUSE_PIXEL_AREA_SR
      hdu.data *= wavs.to(u.Angstrom).value[:, None, None]
      hdu.data = hdu.header['CDELT3']*np.sum(hdu.data, axis=0)
      hdu.header['BUNIT'] = 'electron/s/(0.03962 arcsec)**2'
      hdulist.writeto(filename.replace('-window-', '-image-'), clobber=True)

  if __name__ == '__main__':
      try:
          instrument, bpname = sys.argv[1:]
          bandpass_flatten(instrument, bpname)
      except IndexError:
          print('Usage:', sys.argv[0], 'INSTRUMENT FILTER')
  
#+END_SRC

New example of use, using STSCI python on laptop
#+BEGIN_SRC sh :results silent
source ~/.bash_profile
ur_setup
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python filter-flatten.py wfc3 fq575n
#+END_SRC


Check the same one using the Anaconda py27 on hypatia, but make sure that we are using the same version of CDBS
#+BEGIN_SRC sh :results silent
source activate py27
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python filter-flatten.py wfc3 fq575n
#+END_SRC
Exactly the same, which is a heartening.  

Now do it for all the filters
#+BEGIN_SRC sh
  source activate py27
  export PYSYN_CDBS=/Users/will/Dropbox/CDBS
  FILTERS="f469n f487n f502n f547m fq575n f656n f658n fq672n f673n fq674n"
  for f in $FILTERS; do
      echo Flattening $f
      python filter-flatten.py wfc3 $f
  done
#+END_SRC

#+RESULTS:
| Flattening | f469n  |
| Flattening | f487n  |
| Flattening | f502n  |
| Flattening | f547m  |
| Flattening | fq575n |
| Flattening | f656n  |
| Flattening | f658n  |
| Flattening | fq672n |
| Flattening | f673n  |
| Flattening | fq674n |
**** Comparing profiles by eye
:PROPERTIES:
:ID:       B1BF9964-0468-480C-8A10-B1885B5A2006
:END:
+ Took some profiles by eye on WFC3 and MUSE images of F547M
  + Cannot compare them in DS9 because the spatial axis is written in pixels, which are different sizes 
+ [[file:muse-f547m-cut.dat]]
+ [[file:wfc3-f547m-cut.dat]]
** DONE [4/4] Compare the real and predicted count-rate images on a common grid
CLOSED: [2015-10-15 Thu 12:05]
+ We want to put everything on the MUSE pixel grid, since that will make smaller files by a factor of src_calc{(0.2/0.03962)**2} {{{results(=25.4818555174=)}}}
+ We could use
  1. astrodrizzle
     - [[file:~/Dropbox/OrionHST-2012/HST-ACS/acs-ramp-filters.org][acs-ramp-filters.org]]
  2. montage
     - [[https://montage-wrapper.readthedocs.org]]
     - I had already done that in the t-squared [[id:A237AB1D-270E-497F-BB6B-2FD78C43E668][project]]
     - And I hadn't even used the python bindings
*** DONE Check that I have a working Montage installation
CLOSED: [2015-10-14 Wed 09:10]
+ I already have version 3.3 but version 4 is out
+ Cloning from github into [[file:~/Source/Montage/]]
+ Compiled with =make -j8= - that was fast!
*** DONE Testing out Montage
CLOSED: [2015-10-14 Wed 09:10]
#+BEGIN_SRC sh :results verbatim
PATH=$PATH:~/Source/Montage/bin
err=$(mProjectPP --help)
echo $err
#+END_SRC

#+RESULTS:
: [struct stat="ERROR", msg="Usage: mProjectPP [-z factor][-d level][-b border][-s statusfile][-o altout.hdr][-i altin.hdr][-h hdu][-x scale][-w weightfile][-t threshold][-X(expand)] in.fits out.fits template.hdr"]
*** DONE Script to resample WFC3 image onto MUSE grid
CLOSED: [2015-10-14 Wed 09:12]
:LOGBOOK:
CLOCK: [2016-03-17 Thu 20:05]--[2016-03-18 Fri 09:58] => 13:53
:END:
+ Header for MUSE full frame grid: [[file:muse-full-frame.hdr]]
+ This does not expand the WFC3 image beyond its original borders
  + So we will have to extract a section of the MUSE image for comparison
  + On the other hand, it does maintain the same reference pixel
    + But with different values of CRPIX because the image lower left corner is different
    + So it has the same values of CRVAL
    + This will make it easy to slice the MUSE image
+ Smoothing needs to be improved
  + No smoothing is too little
  + The =s120= images that I already have are too much (this was 1.2 arcsec I assume)
  + In the [[id:2E0AC321-C544-4E65-9D59-9A11F96E94BD][t2 notes]] I calculated FWHM of 4 pixels = 0.8 arcsec
  + Actually 0.7 arcsec was better - this is now done in [[id:0CF5E394-36D0-4589-9E02-93EEDE7CF151][the orion-t2.org notes]]
#+BEGIN_SRC sh :tangle wfc3-resample-to-muse.sh
F=$1
MDIR=~/Source/Montage/bin
TDIR=~/Work/RubinWFC3/Tsquared
$MDIR/mProjectPP -h 0 -X $TDIR/newsmooth-${F}-s080.fits wfc3-new-resample-muse-$F.fits muse-full-frame.hdr
#+END_SRC

Test with a single image
#+BEGIN_SRC sh :results verbatim
time sh wfc3-resample-to-muse.sh F547M 2>&1 
#+END_SRC

#+RESULTS:


Do all of the images
#+BEGIN_SRC sh :results verbatim
  FILTERS="f487n f547m fq575n f656n f658n fq672n f673n fq674n"
  for f in $FILTERS; do
      echo "Resampling $f"
      time sh wfc3-resample-to-muse.sh $f
  done
#+END_SRC

#+RESULTS:
#+begin_example
Resampling f487n
[struct stat="OK", time=3]
Resampling f547m
[struct stat="OK", time=3]
Resampling fq575n
[struct stat="OK", time=2]
Resampling f656n
[struct stat="OK", time=3]
Resampling f658n
[struct stat="OK", time=3]
Resampling fq672n
[struct stat="OK", time=2]
Resampling f673n
[struct stat="OK", time=3]
Resampling fq674n
[struct stat="OK", time=2]
#+end_example
*** DONE [2/2] Crop MUSE image to the WFC3 field
CLOSED: [2015-10-15 Thu 12:05]
:PROPERTIES:
:ID:       1B689511-B4ED-42AD-8C76-70638FEA13BE
:END:
+ [X] This is the final step required before we can do things like take ratio maps or calculate 2d histogram images
+ [X] [2015-10-15 Thu] Also, write out the integrated spectrum times filter throughput for the cropped region
#+BEGIN_SRC python :tangle crop_muse.py
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.wcs import WCS, WCSSUB_SPECTRAL
  import astropy.units as u

  def crop_muse_to_wfc3(fid, no_spec=False):
      """Cut out a section of the MUSE image to match the WFC3 field"""
      wname = 'wfc3-new-resample-muse-{}.fits'.format(fid)
      mname = 'muse-hr-image-wfc3-{}.fits'.format(fid)
      whdu = fits.open(wname)[0]
      mhdu = fits.open(mname)['DATA']
      if not no_spec:
          # Also get the spectral data cube multiplied by filter throughput
          shdu = fits.open(mname.replace('-image-', '-transwin-'))['DATA']
      wcs_w = WCS(whdu.header).celestial
      wcs_m = WCS(mhdu.header).celestial
      # Check that the two images have the same reference point in RA, DEC
      assert np.all(wcs_w.wcs.crval == wcs_m.wcs.crval)
      # And that the pixel scales are the same
      assert np.all(wcs_w.wcs.cdelt == wcs_m.wcs.cdelt)
      assert np.all(wcs_w.wcs.pc == wcs_m.wcs.pc)

      # The shapes of the two grids: (nx, ny) in FITS axis order
      shape_w = np.array([whdu.header['NAXIS1'], whdu.header['NAXIS2']])
      shape_m = np.array([mhdu.header['NAXIS1'], mhdu.header['NAXIS2']])

      # The difference in CRPIX values tells us the start indices (i, j)
      # for the crop window on the MUSE grid. Note that this is in
      # zero-based array indices
      start = wcs_m.wcs.crpix - wcs_w.wcs.crpix
      # The stop indices for the crop window 
      stop = start + shape_w

      # Shift 1 pixel to the right to do a coarse alignment correction
      start[0] += -1
      stop[0] += -1

      # Check that these are within bounds of the original MUSE grid
      assert np.all(start >= 0.0)
      assert np.all(stop < shape_m)

      # Crop the MUSE data array to the start:stop indices, remembering
      # that python axis order is backwards with respect to FITS axis
      # order
      mhdu.data = mhdu.data[start[1]:stop[1], start[0]:stop[0]]

      # And copy the WFC3 wcs into the new MUSE header
      mhdu.header.update(wcs_w.to_header())

      # Write out the new cropped MUSE image
      oname = mname.replace('-image-', '-new-cropimage-')
      mhdu.writeto(oname, clobber=True)

      if not no_spec:
          # Finally, as a bonus, calculate the 1-D average spectrum from the cube
          spec = np.nanmean(shdu.data[:, start[1]:stop[1], start[0]:stop[0]],
                            axis=(-1, -2))
          # Convert from 1e-20 flux-per-pixel to surface brightness units (flux per sr)
          pixel_area_sr = np.product(np.abs(wcs_m.wcs.cdelt))*(u.deg.to(u.radian))**2
          spec *= 1e-20/pixel_area_sr
          # extract only the spectral part of the cube's WCS
          wcs_s = WCS(shdu.header).sub([WCSSUB_SPECTRAL])
          oshdu = fits.PrimaryHDU(header=wcs_s.to_header(), data=spec)
          oshdu.header['BUNIT'] = 'erg/s/cm**2/sr/Angstrom'
          # Fix up the wavelngth units to angstrom
          oshdu.header['CDELT1'] *= 1e10
          oshdu.header['CRVAL1'] *= 1e10
          oshdu.header['CUNIT1'] = 'Angstrom'
          # And record the window from the MUSE full field that was extracted
          oshdu.header['MUSE_X1'] = start[0] + 1, 'Extracted window: start X pixel' 
          oshdu.header['MUSE_X2'] = stop[0] + 1, 'Extracted window: stop X pixel' 
          oshdu.header['MUSE_Y1'] = start[1] + 1, 'Extracted window: start Y pixel' 
          oshdu.header['MUSE_Y2'] = stop[0] + 1, 'Extracted window: stop Y pixel' 
          oshdu.writeto(mname.replace('-image-', '-cropspec1d-'), clobber=True)

      return oname


  if __name__ == '__main__':
      try:
          filter_id = sys.argv[1]
      except:
          print('Usage:', sys.argv[0], 'FILTER')

      try:
          no_spec = 'no' in sys.argv[2]
      except:
          no_spec = False

      print(crop_muse_to_wfc3(filter_id, no_spec))

#+END_SRC

#+BEGIN_SRC sh :results silent
python crop_muse.py fq575n
#+END_SRC

#+BEGIN_SRC sh :tangle all-crop-muse.sh
  FILTERS="f487n f547m fq575n f656n f658n fq672n f673n fq674n"
  for f in $FILTERS; do
      time python crop_muse.py $f
  done
#+END_SRC

#+BEGIN_SRC sh :tangle all-crop-muse-nospec.sh
  FILTERS="f487n f547m fq575n f656n f658n fq672n f673n fq674n"
  for f in $FILTERS; do
      time python crop_muse.py $f nospec
  done
#+END_SRC

#+BEGIN_SRC sh :results verbatim
sh all-crop-muse-nospec.sh
#+END_SRC

#+RESULTS:
: muse-hr-new-cropimage-wfc3-f487n.fits
: muse-hr-new-cropimage-wfc3-f547m.fits
: muse-hr-new-cropimage-wfc3-fq575n.fits
: muse-hr-new-cropimage-wfc3-f656n.fits
: muse-hr-new-cropimage-wfc3-f658n.fits
: muse-hr-new-cropimage-wfc3-fq672n.fits
: muse-hr-new-cropimage-wfc3-f673n.fits
: muse-hr-new-cropimage-wfc3-fq674n.fits

** Plot the cropped 1D spectra
#+BEGIN_SRC python :tangle specplot1d_utils.py
  from __future__ import print_function
  import sys
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy import units as u
  from matplotlib import pyplot as plt
  import seaborn as sns

  def plot_1d_spec_from_fits(fn, ax, fontsize=None):
      """Plots spectrum from filename `fn` onto pre-existing axis `ax`"""
      hdu = fits.open(fn)[0]
      spec = hdu.data/1e-3
      w = WCS(hdu.header)
      nwav = len(spec)
      wavs, = w.all_pix2world(range(nwav), 0)
      wavs *= u.m.to(u.Angstrom)
      #ax.plot(wavs, spec, drawstyle='steps-mid')
      ax.bar(wavs, spec, align='center', linewidth=0)
      ax.set_xlim(wavs.min(), wavs.max())
      ax.set_xlabel('Observed Air Wavelength, Angstrom', fontsize=fontsize)
      ax.set_ylabel('Filter Throughput x Brightness\n 0.001 erg/s/cm^2/sr/Angstrom', fontsize=fontsize)


  if __name__ == '__main__':
      try:
          filt = sys.argv[1]
      except IndexError:
          print('Usage:', sys.argv[0], 'FILTER')
      fig, ax = plt.subplots(1, 1)
      fn = 'muse-hr-cropspec1d-wfc3-{}.fits'.format(filt)
      plot_1d_spec_from_fits(fn, ax)
      # ax.set_yscale('log')
      # ax.set_ylim(1e-7, None)
      fig.savefig(sys.argv[0].replace('.py', '-test-{}.pdf'.format(filt)))

#+END_SRC

#+BEGIN_SRC sh
FILTERS="f469n f487n f502n f547m fq575n f656n f658n fq672n f673n fq674n"
for f in $FILTERS; do
    python specplot1d_utils.py $f
done
#+END_SRC

#+RESULTS:

** Visualizations of throughput calibration quality
The final count-rate images to be compared are 
+ Smoothed WFC3 :: wfc3-resample-muse-FILTER.fits
+ Cropped MUSE :: muse-hr-cropimage-wfc3-FILTER.fits
*** Ratios of the images
+ This will allow us to see how important misalignment is, and if there are any spatial trends

#+BEGIN_SRC python :tangle make-wfc3-muse-ratio-images.py
  from astropy.io import fits

  filters_ = ["FQ575N", "FQ672N", "FQ674N", "F673N",
              "F487N", "F656N", "F658N", "F547M"]

  def divide_fits_images(name1, name2, outname):
      hdu1 = fits.open(name1)[0]
      hdu2 = fits.open(name2)['DATA']
      fits.PrimaryHDU(header=hdu1.header, data=hdu1.data/hdu2.data).writeto(outname, clobber=True)
      print(outname)

  if __name__ == '__main__':
      for f in filters_:
          divide_fits_images(
              'wfc3-new-resample-muse-{}.fits'.format(f),
              'muse-hr-new-cropimage-wfc3-{}.fits'.format(f),
              'wfc3-over-muse-new-calib-ratio-{}.fits'.format(f)
          )
    
#+END_SRC

#+BEGIN_SRC sh :results verbatim
python make-wfc3-muse-ratio-images.py
#+END_SRC

#+RESULTS:
: wfc3-over-muse-new-calib-ratio-FQ575N.fits
: wfc3-over-muse-new-calib-ratio-FQ672N.fits
: wfc3-over-muse-new-calib-ratio-FQ674N.fits
: wfc3-over-muse-new-calib-ratio-F673N.fits
: wfc3-over-muse-new-calib-ratio-F487N.fits
: wfc3-over-muse-new-calib-ratio-F656N.fits
: wfc3-over-muse-new-calib-ratio-F658N.fits
: wfc3-over-muse-new-calib-ratio-F547M.fits


*** Ds9 region files for the good and bad areas
:PROPERTIES:
:noweb:    yes
:END:
:LOGBOOK:
CLOCK: [2016-03-20 Sun 11:03]--[2016-03-20 Sun 11:03] =>  0:00
:END:

This goes at the top of all the files
#+name: ds9-region-header
#+BEGIN_SRC conf
# Region file format: DS9 version 4.1
global color=black dashlist=8 3 width=1 font="helvetica 10 normal roman" select=1 highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1
fk5
#+END_SRC


+ These are the good squares for each of the quad filters
#+BEGIN_SRC conf :tangle FQ672N-good.reg
<<ds9-region-header>>
polygon(5:35:14.072,-5:23:34.69,5:35:10.267,-5:24:07.60,5:35:12.775,-5:25:03.20,5:35:16.463,-5:24:30.54) # edit=0 move=0
#+END_SRC

#+BEGIN_SRC conf :tangle FQ674N-good.reg
<<ds9-region-header>>
polygon(5:35:13.654,-5:23:22.26,5:35:09.807,-5:23:55.58,5:35:12.279,-5:24:52.98,5:35:15.866,-5:24:16.59) # edit=0 move=0
#+END_SRC

#+BEGIN_SRC conf :tangle FQ575N-good.reg
<<ds9-region-header>>
polygon(5:35:14.985,-5:23:25.04,5:35:11.483,-5:24:02.45,5:35:13.810,-5:24:55.60,5:35:17.494,-5:24:21.14) # edit=0 move=0
#+END_SRC

+ These are the bad regions for the FQ575N, F547M, F673N filters
+ We will show them in dark red
#+BEGIN_SRC conf :tangle FQ575N-bad.reg
<<ds9-region-header>>
box(5:35:13.980,-5:23:43.20,46.2011",6.08098",327) # color=red
box(5:35:11.855,-5:24:09.64,34.7559",63.372",359.998) # color=red
#+END_SRC

#+BEGIN_SRC conf :tangle F547M-bad.reg
<<ds9-region-header>>
box(5:35:14.743,-5:24:11.89,6.98829",108.595",17) # color=red
#+END_SRC

#+BEGIN_SRC conf :tangle F673N-bad.reg
<<ds9-region-header>>
box(5:35:14.743,-5:24:11.89,6.98829",108.595",17) # color=red
#+END_SRC

And this is the combined sweet spot

#+BEGIN_SRC conf :tangle new-combined-sweet.reg
<<ds9-region-header>>
polygon(5:35:14.415,-5:23:42.66,5:35:13.018,-5:23:56.15,5:35:13.018,-5:24:37.65,5:35:13.251,-5:24:42.97,5:35:14.018,-5:24:35.40,5:35:14.866,-5:23:53.49) # color=yellow width=2 dash=1
polygon(5:35:15.674,-5:24:12.10,5:35:15.209,-5:24:01.26,5:35:14.634,-5:24:29.07,5:35:15.510,-5:24:20.07) # color=yellow width=2 dash=1
polygon(5:35:14.196,-5:23:37.55,5:35:14.072,-5:23:34.89,5:35:13.018,-5:23:46.13,5:35:13.018,-5:23:48.79) # color=yellow width=2 dash=1
#+END_SRC




*** Figures of the ratio images
:LOGBOOK:
CLOCK: [2016-03-19 Sat 23:54]--[2016-03-20 Sun 11:03] => 11:09
:END:
#+BEGIN_SRC python :eval no :tangle plot-calib-ratios.py
  import matplotlib
  matplotlib.use('Agg')
  import matplotlib.pyplot as plt
  import aplpy
  from astropy.io import fits
  import pyregion
  import numpy as np

  filters_ = ["FQ575N", "FQ672N", "FQ674N", "F673N",
              "F487N", "F656N", "F658N", "F547M"]
  cmap = matplotlib.cm.RdYlBu_r
  ra0, dec0 = 83.80716, -5.403
  dra, ddec = 0.025, 0.025
  sweet_region = 'new-combined-sweet.reg'
  for filter_ in filters_:
      fitsfile = 'wfc3-over-muse-new-calib-ratio-{}.fits'.format(filter_) 
      f = aplpy.FITSFigure(fitsfile) 
      f.recenter(ra0, dec0, width=dra, height=ddec)
      f.show_colorscale(interpolation='none', vmin=0.5, vmax=1.5, cmap=cmap)
      for goodbad in 'good', 'bad':
          try:
              regfile = '{}-{}.reg'.format(filter_, goodbad)
              f.show_regions(regfile)
          except IOError:
              pass
      f.add_label(0.1, 0.1, filter_, relative=True)
      f.add_colorbar()
      f.colorbar.set_axis_label_text('WFC3 / MUSE')
      f.axis_labels.hide()
      f.tick_labels.hide()
      figfile = fitsfile.replace('.fits', '.jpg')
      plt.gcf().set_size_inches(6, 5)
      plt.gcf().savefig(figfile, dpi=300)
      print(figfile)

  # Now plot all the regions on top of one another
  fitsfile = 'wfc3-over-muse-new-calib-ratio-{}.fits'.format('F673N')
  hdu = fits.open(fitsfile)[0]
  hdu.data[np.isfinite(hdu.data)] = 1.0
  hdu.data[~np.isfinite(hdu.data)] = 0.0
  badregions = []
  for filter_ in filters_:
      try:
          goodregion = pyregion.open(filter_ + '-good.reg')
          mask = goodregion.get_mask(hdu=hdu)
          hdu.data[mask] += 1.0
      except IOError:
          pass
  for filter_ in filters_:
      try:
          badregion = pyregion.open(filter_ + '-bad.reg')
          mask = badregion.get_mask(hdu=hdu)
          hdu.data[mask] *= 0.3
          badregions.append(badregion)
      except IOError:
          pass
  f = aplpy.FITSFigure(hdu)
  f.recenter(ra0, dec0, width=dra, height=ddec)
  f.show_grayscale(interpolation='none', invert=True)
  f.add_colorbar()
  #for region in badregions:
  #    f.show_regions(region)
  f.show_regions(sweet_region)
  f.axis_labels.hide()
  f.tick_labels.hide()
  figfile = 'wfc3-over-muse-new-calib-ratio-SWEET.jpg'
  plt.gcf().set_size_inches(6, 5)
  plt.gcf().savefig(figfile, dpi=300)
  print(figfile)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
python plot-calib-ratios.py
#+END_SRC

#+RESULTS:
#+begin_example
wfc3-over-muse-new-calib-ratio-FQ575N.jpg
wfc3-over-muse-new-calib-ratio-FQ672N.jpg
wfc3-over-muse-new-calib-ratio-FQ674N.jpg
wfc3-over-muse-new-calib-ratio-F673N.jpg
wfc3-over-muse-new-calib-ratio-F487N.jpg
wfc3-over-muse-new-calib-ratio-F656N.jpg
wfc3-over-muse-new-calib-ratio-F658N.jpg
wfc3-over-muse-new-calib-ratio-F547M.jpg
INFO: Auto-setting vmin to -4.000e-01 [aplpy.core]
INFO: Auto-setting vmax to  4.440e+00 [aplpy.core]
wfc3-over-muse-new-calib-ratio-SWEET.jpg
#+end_example

#+BEGIN_SRC sh :results silent
open wfc3-over-muse-new-calib-ratio-*.jpg
#+END_SRC
*** STARTED Revisiting MUSE calibration [2016-03-17 Thu]
+ There are three major outstanding issues:
  1. A severe slope in the FQ672N WFC3/MUSE ratio
     - This is about 1 to 1.1 in the ratio, going from top left to bottom right
     - It seems aligned with the WFC3 chip axes, suggesting it is a flat field problem with WFC3
     - We should just divide by a linear function
  2. There is a jump in the FQ575N WFC3/MUSE ratio on the W side of the sweet spot
     - Goes up to about 1.1
     - On the one hand, it seems to correspond with some sort of instrumental boundary in MUSE
       - Other lines show a clear jump at this position
       - E.g., F469N, F502N, F487N
       - but it is generally much smaller in magnitude: 1.03 or less, implying it is not the same thing
     - On the other hand, it gives a faint high-T blob in the 2D histograms, which looks very suspicious
       - So the temptation is to just cut it out
     - /NEW/ [2016-03-23 Wed] This whole area turns out to be suspect in the ratio of ratios [N II] image
       - I am trying to get to the bottom of it
  3. What was the third issue?
+ Also, there is a small slope in the F656N ratio, from top to bottom but seeming aligned with WFC3 chip axes
+ Finally, there is the issue of the effects of bias-level errors in the MUSE data
  + Since the F547M filter is so broad, a tiny error per wavelength pixel in MUSE could mount up
  + Whereas the other pixels would not be affected so much
  + The conversion factor from MUSE flux units to HST counts is
    + WFC3_CONSTANT * MUSE_FLUX_UNITS / MUSE_PIXEL_AREA_SR
    + 0.0840241 * 1e-20 / (0.2 / 206265)**2 = 8.93706589857e-10
  + But we also need to multiply by WAV * DWAV
    + On average this will be 5500 * 0.85 = 4675
  + Looking at the datacubes, the faintest pixels have a flux of about 500 in MUSE units, so an error in the bias of 100 might be possible
    + In WFC3 units, this would be 100 * 4675 * 8.93706589857e-10 = 4.18e-4 per wavelength pixel
    + For the narrow filters, we have NV = 45 to 100, so this would give an offset of about 0.02 to 0.04
    + But for F547M, we have NV = 1530, giving an offset of 0.63954
    + The actual offset we require is about 0.1 in F547M (1.5% of range), which is 6 times smaller
      + So, bias error of 15 in MUSE units, which is 3% of the faintest signal
      + So offset of 0.003 in quad filters and 0.02 in F673N
        + Quad filters: 0.003/0.4 => 0.7 % of range
        + F673N: 0.02/0.6 => 3% of range
  + The conclusion is that this is unlikely since it affects F547M and FQ575N equally, which is no good for us
  + /New conclusions/ [2016-03-23 Wed]
    + There may well be a MUSE bias offset - it turns out to make almost no difference to the final calibration
+ An alternative is that it may be a bias/dark error in the WFC3 images
  + Dark current is 6e/hr/pixel, corresponding to 0.002 e/s/pixel
  + This unlikely, as discussed in paper text

***** DONE Finding a better sweet spot 
CLOSED: [2016-03-18 Fri 09:59]
:LOGBOOK:
CLOCK: [2016-03-18 Fri 09:58]--[2016-03-18 Fri 09:59] =>  0:01
:END:
+ I have laid the groundwork for this with some regions
  + All are in the Tsquared directory
  + Separate polygons for the "good" bit of each quad filter
    + [[file:~/Work/RubinWFC3/Tsquared/sweet-conservative.reg]] has extra junk in too
    + [[file:~/Work/RubinWFC3/Tsquared/sweet-polygons.reg]] may be an older version - not sure
  + Bad regions in F547M and F575N
    + [[file:~/Work/RubinWFC3/Tsquared/new-bad-547.reg]]
    + [[file:~/Work/RubinWFC3/Tsquared/new-bad-575.reg]]
  + Polygons for the union of the "good" parts with the exclusion of the "bad" part
    + [[file:~/Work/RubinWFC3/Tsquared/sweet-3regions.reg]]
    + This is 3 separate regions, one of which is biggish
***** NEXT Finishing the appendix on MUSE calibration
+ [X] The plan now will be to make images of the WFC3/MUSE ratio images
  + Use aplpy
  + Overlay the various regions
  + Talk about the good bits that are left
  + Also fix the linear trends in F672N and F656N
+ [ ] Then we have the part that compares the spectrum-derived and the synthetic filter-derived line ratios for the MUSE data
+ [ ] And finally a new section that compares the actual ratios from MUSE and from WFC3
  + Taking into account the linear gradient correction
  + And using just the reduced sweet spot
+ So then we can go back to the "real" WFC3-derived ratios

***** TODO Finding color terms from the MUSE maps
:LOGBOOK:
CLOCK: [2016-03-22 Tue 08:38]--[2016-03-22 Tue 18:38] => 10:00
:END:
+ [X] Copy over the continuum maps from the linux server
+ [ ] Work out what to do with them
  + Or do we want to use the EW files
+ For the time being, we will leave this and just write up what we already have
***** DONE Fix the linear gradients
CLOSED: [2016-03-18 Fri 22:26]
+ Do this directly on the =*-align-square_drz.fits= files eventually
+ But first try it on the =wfc3-over-muse*= files to check it works
+ Probably easiest to actually fit for the gradient using =astropy.modeling= 

#+BEGIN_SRC python :eval no :tangle fit-surface-calib-ratio.py
  import numpy as np
  from astropy.modeling import models, fitting
  from astropy.io import fits
  from astropy.wcs import WCS
  import pyregion

  ZMIN, ZMAX = 0.5, 1.5
  def fit_surf_to_image(hdu, goodregion=None, badregion=None):
      wcs = WCS(hdu.header)
      ny, nx = hdu.data.shape

      xpix, ypix = np.meshgrid(np.arange(nx), np.arange(ny))
      x, y = wcs.all_pix2world(xpix, ypix, 0)
      z = hdu.data
      z[z < ZMIN] = np.nan
      z[z > ZMAX] = np.nan
      mask = np.isfinite(z)
      if goodregion is not None:
          mask = mask & goodregion.get_mask(hdu=hdu)
      if badregion is not None:
          mask = mask & (~badregion.get_mask(hdu=hdu))
        
      p_init = models.Polynomial2D(degree=1)
      fit_p = fitting.LinearLSQFitter()
      p = fit_p(p_init, x[mask], y[mask], z[mask])
      zfit = p(x, y)
      zfit_mean = np.nanmean(zfit)
      zfit /= zfit_mean
      print(p.parameters/zfit_mean)
      return zfit


      
  FILTERS = ['FQ575N', 'FQ672N', 'FQ674N', 'F656N', 'F658N', 'F487N', 'F547M', 'F673N']

  T2DIR = '/Users/will/Work/RubinWFC3/Tsquared/'

  if __name__ == '__main__':
      for filter_ in FILTERS:
          fn = 'wfc3-over-muse-new-calib-ratio-{}.fits'.format(filter_)
          hdu, = fits.open(fn)
          try:
              goodregion = pyregion.open('{}-good.reg'.format(filter_))
          except:
              goodregion = None
          try:
              badregion = pyregion.open('{}-bad.reg'.format(filter_))
          except:
              badregion = None
          print(filter_)
          surface = fit_surf_to_image(hdu, goodregion, badregion)
          hdu.data /= surface
          hdu.writeto(fn.replace('-new-', '-correct-'), clobber=True)
          hdu.data = surface
          hdu.writeto(fn.replace('-new-', '-surface-'), clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results verbatim
python fit-surface-calib-ratio.py
#+END_SRC

#+RESULTS:
#+begin_example
FQ575N
[ 111.77105842   -1.36158382   -0.61799185]
FQ672N
[ 443.7931065    -5.40565763   -1.89480616]
FQ674N
[ 170.34330971   -2.17419652   -2.38209071]
F656N
[ 118.25351065   -1.41248386   -0.20765711]
F658N
[  7.99555035e+01  -9.45035885e-01  -4.52843570e-02]
F487N
[-35.91129978   0.47530767   0.54099846]
F547M
[ -2.21740055e+02   2.67103968e+00   2.05546243e-01]
F673N
[ 56.25499129  -0.76103302  -1.57797884]
#+end_example

+ To get an idea of the magnitudes involved, multiply the linear terms by the field size, which is 0.025 degrees
  + So typical values of 1 give 2.5% variation across the field
  + Biggest difference is for FQ672N, where it is 15%

**** DONE Recalculate the MUSE/WFC3 calibration 
CLOSED: [2016-03-18 Fri 23:41]
+ This is done in [[id:CFD0478A-C87C-4E6F-A152-D554C973DB07][Two-d histogram of WFC3 vs MUSE-predicted count rates]]
+ Changes we are making:
  1. Reading in the new smoothed and resampled images
  2. Looking for a flat-field corrected one if it is there
  3. Restricting the fit to the new sweet spot
     - this automatically excludes the regions contaminated with stray light

*** Two-d histogram of WFC3 vs MUSE-predicted count rates
:PROPERTIES:
:ID:       CFD0478A-C87C-4E6F-A152-D554C973DB07
:END:

#+BEGIN_SRC python :tangle histocalib.py
  from __future__ import print_function
  import numpy as np
  from astropy.io import fits
  from astropy.convolution import convolve, Gaussian2DKernel
  from matplotlib import pyplot as plt
  import pyregion
  import seaborn as sns
  from specplot1d_utils import plot_1d_spec_from_fits

  maxcount = {
      "fq575n": 0.4,
      "fq672n": 0.6,
      "fq674n": 0.75,
      "f673n" : 2.5,
      # "f469n" : 0.5,
      "f487n" : 7.0,
      "f656n" : 32.0, 
      "f658n" : 11.0, 
      "f547m" : 7.0, 
      # "f502n" : 20.0,
  }
  GAMMA = 2.0
  T2DIR = '/Users/will/Work/RubinWFC3/Tsquared/'

  # CORRECT_LINEAR_GRADIENT = ['fq672n', ]
  CORRECT_LINEAR_GRADIENT = ["fq575n", "fq672n", "fq674n", "f673n",
                             "f487n" , "f656n" , "f658n" , "f547m"]
  cmap = sns.light_palette((260, 50, 30), input="husl", as_cmap=True)
  # cmap = plt.cm.gray_r

  def histogram_calib_images(f, vmax=1.0, muse_shift=0.0):
      name1 = 'wfc3-new-resample-muse-{}.fits'.format(f)
      name2 = 'muse-hr-new-cropimage-wfc3-{}.fits'.format(f)
      if muse_shift == 0.0:
          pltname = 'wfc3-vs-muse-new-calib-{}.pdf'.format(f)
      else:
          pltname = 'wfc3-vs-muse-new-calib-{}-bias-shift.pdf'.format(f)

      hdu1 = fits.open(name1)[0]
      name3 = 'wfc3-over-muse-surface-calib-ratio-{}.fits'.format(f)
      if f in CORRECT_LINEAR_GRADIENT:
          # Linear correction surface to fix flat field
          hdus = fits.open(name3)[0]
          hdu1.data /= hdus.data
      hdu2 = fits.open(name2)['DATA']
      hduc = fits.open('wfc3-new-resample-muse-f547m.fits')[0]
      sweet_region = pyregion.open(T2DIR + 'sweet-3regions.reg')
      x, y = hdu2.data - muse_shift, hdu1.data
      xmin, xmax = ymin, ymax = 0.0, vmax
      ew = y/hduc.data
      # mask out silly values
      m = np.isfinite(x) & np.isfinite(y/x) & (np.abs(np.log10(y/x)) < 1.0)
      m = m & sweet_region.get_mask(hdu=hdu1)
      H, xedges, yedges = np.histogram2d(x[m], y[m], 100,
                                         [[xmin, xmax], [ymin, ymax]],
                                         weights=y[m])

      # Just take the median and weighted means of the ratio
      mm = m & (np.abs(np.log10(y/x)) < 0.3) # More restrictive mask
      median_slope = np.median(y[mm]/x[mm])
      weighted_mean_slope = np.average(y[mm]/x[mm], weights=y[mm])
      # And then take mean +/- std of those two to give the final answer
      slope = np.mean([median_slope, weighted_mean_slope])
      dslope = abs(median_slope - weighted_mean_slope)
      # Convert to a polynomial: linear with zero intercept
      pbest = np.poly1d([slope, 0.0])

      # Distribution of ratio, divided into two subsamples on EW or counts
      ratio = y/x
      # if f == 'f547m':
      if True:
          # Divide into high and low continuum counts
          s = 'counts'
          mlo = (y < y[mm].mean()) & mm
          mhi = (y >= y[mm].mean()) & mm
      else:
          # Divide into high and low EW
          s = f.upper() + '/F547M'
          mlo = (ew < np.median(ew[mm])) & mm
          mhi = (ew >= np.median(ew[mm])) & mm
      assert mlo.sum() > 0, f

      # Separate averages for the two subsamples
      ratio_hi = np.average(ratio[mhi], weights=y[mhi])
      ratio_lo = np.average(ratio[mlo], weights=y[mlo])
      # Difference in subsamples ... 
      ddslope = 0.5*np.abs(ratio_hi - ratio_lo)
      # ... which feeds in to the uncertainty in slope
      dslope = max(dslope, ddslope)

      # H = convolve(H, Gaussian2DKernel(1.0))
      fitcolor = (1.0, 0.5, 0.0)
      fitlabel = "y = ({:.3f} +/- {:.3f}) x".format(slope, dslope)
      fig, ax = plt.subplots(1, 1)
      ax.imshow((H.T)**(1.0/GAMMA), extent=[xmin, xmax, ymin, ymax],
                interpolation='none', aspect='auto', origin='lower', 
                cmap=cmap, alpha=1.0)
      ax.plot([0.0, x[m].max()], [0.0, x[m].max()], '-', alpha=1.0,
              lw=1, c='w', label=None)
      ax.plot([0.0, x[m].max()], pbest([0.0, x[m].max()]), '-', alpha=1.0,
              lw=1, c=fitcolor, label=fitlabel)

      leg = ax.legend(loc='upper left', title='Best Fit', frameon=True, fancybox=True)
      leg.get_title().set_fontsize('small')
      ax.set_ylabel(
          'Observed WFC3 {} count rate, electron/s/pixel'.format(f.upper()))
      ax.set_xlabel(
          'MUSE-predicted WFC3 {} count rate, electron/s/pixel'.format(f.upper()))
      ax.set_xlim(xmin, xmax)
      ax.set_ylim(ymin, ymax)


      # Now do 1-D histogram of the ratios 
      # inset axis at the top left
      ax2 = fig.add_axes([0.2, 0.55, 0.25, 0.25])
      ax2.hist(ratio[mlo], bins=100, range=(0.5, 1.5),
               normed=True, weights=y[mlo], alpha=0.7, label='Low '+s)
      ax2.hist(ratio[mhi], bins=100, range=(0.5, 1.5),
               normed=True, weights=y[mhi], color='red', alpha=0.3, label='High '+s)
      ax2.set_xlim(0.5, 1.5)
      # leave more space at top
      y1, y2 = ax2.get_ylim()
      y2 *= 1.2
      ax2.set_ylim(y1, y2)
      ax2.legend(loc='upper left', fontsize='xx-small')
      ax2.tick_params(labelleft=False, labelsize='x-small')
      ax2.set_xlabel('Observed / Predicted', fontsize='xx-small')
      ax2.set_ylabel('Weighted PDF Histograms', fontsize='xx-small')
  #    ax2.set_title('PDF', fontsize='x-small')

  # inset axis at the bottom right
      ax3 = fig.add_axes([0.6, 0.2, 0.3, 0.3])
      fn = 'muse-hr-cropspec1d-wfc3-{}.fits'.format(f)
      plot_1d_spec_from_fits(fn, ax3, fontsize='xx-small')
      ax3.tick_params(labelsize='xx-small')
      ax3.set_title(f.upper())


      fig.set_size_inches(6, 6)
      fig.savefig(pltname)

      return [pltname, fitlabel]


  if __name__ == '__main__':
      for f, vmax in maxcount.items():
          print(histogram_calib_images(f, vmax))

#+END_SRC

#+RESULTS:


#+BEGIN_SRC sh
python histocalib.py 
#+END_SRC

#+RESULTS:
| ['wfc3-vs-muse-new-calib-f487n.pdf'  | 'y = (0.971 +/- 0.009) x'] |
| ['wfc3-vs-muse-new-calib-f658n.pdf'  | 'y = (0.984 +/- 0.009) x'] |
| ['wfc3-vs-muse-new-calib-f547m.pdf'  | 'y = (0.941 +/- 0.012) x'] |
| ['wfc3-vs-muse-new-calib-fq674n.pdf' | 'y = (1.022 +/- 0.003) x'] |
| ['wfc3-vs-muse-new-calib-f656n.pdf'  | 'y = (1.035 +/- 0.002) x'] |
| ['wfc3-vs-muse-new-calib-fq672n.pdf' | 'y = (1.048 +/- 0.005) x'] |
| ['wfc3-vs-muse-new-calib-fq575n.pdf' | 'y = (1.013 +/- 0.006) x'] |
| ['wfc3-vs-muse-new-calib-f673n.pdf'  | 'y = (0.993 +/- 0.005) x'] |


Only correcting linear gradient for FQ672N
#+RESULTS:
| ['wfc3-vs-muse-new-calib-f487n.pdf'  | 'y = (0.972 +/- 0.011) x'] |
| ['wfc3-vs-muse-new-calib-f658n.pdf'  | 'y = (0.982 +/- 0.008) x'] |
| ['wfc3-vs-muse-new-calib-f547m.pdf'  | 'y = (0.946 +/- 0.017) x'] |
| ['wfc3-vs-muse-new-calib-fq674n.pdf' | 'y = (1.018 +/- 0.012) x'] |
| ['wfc3-vs-muse-new-calib-f656n.pdf'  | 'y = (1.032 +/- 0.001) x'] |
| ['wfc3-vs-muse-new-calib-fq672n.pdf' | 'y = (1.048 +/- 0.005) x'] |
| ['wfc3-vs-muse-new-calib-fq575n.pdf' | 'y = (1.010 +/- 0.005) x'] |
| ['wfc3-vs-muse-new-calib-f673n.pdf'  | 'y = (0.993 +/- 0.001) x'] |


#+BEGIN_SRC sh :results silent
open wfc3-vs-muse-new-calib-f*.pdf
#+END_SRC

Before I fiddled with the bi-linear surfaces
#+RESULTS:
| ['wfc3-vs-muse-new-calib-f487n.pdf'  | 'y = (0.979 +/- 0.011) x'] |
| ['wfc3-vs-muse-new-calib-f658n.pdf'  | 'y = (0.990 +/- 0.010) x'] |
| ['wfc3-vs-muse-new-calib-f547m.pdf'  | 'y = (0.954 +/- 0.018) x'] |
| ['wfc3-vs-muse-new-calib-fq674n.pdf' | 'y = (1.026 +/- 0.010) x'] |
| ['wfc3-vs-muse-new-calib-f656n.pdf'  | 'y = (1.044 +/- 0.003) x'] |
| ['wfc3-vs-muse-new-calib-fq672n.pdf' | 'y = (1.055 +/- 0.001) x'] |
| ['wfc3-vs-muse-new-calib-fq575n.pdf' | 'y = (1.014 +/- 0.005) x'] |
| ['wfc3-vs-muse-new-calib-f673n.pdf'  | 'y = (1.001 +/- 0.002) x'] |



Old results from last time we ran it ages ago
| ['wfc3-vs-muse-calib-f487n.pdf'  | 'y = (0.99 +/- 0.01) x + (-0.02 +/- 0.02)'] |
| ['wfc3-vs-muse-calib-f658n.pdf'  | 'y = (1.00 +/- 0.01) x + (-0.02 +/- 0.02)'] |
| ['wfc3-vs-muse-calib-f469n.pdf'  | 'y = (0.94 +/- 0.03) x + (-0.00 +/- 0.01)'] |
| ['wfc3-vs-muse-calib-fq674n.pdf' | 'y = (0.98 +/- 0.01) x + (0.01 +/- 0.00)']  |
| ['wfc3-vs-muse-calib-f656n.pdf'  | 'y = (1.02 +/- 0.01) x + (0.18 +/- 0.07)']  |
| ['wfc3-vs-muse-calib-fq672n.pdf' | 'y = (0.97 +/- 0.02) x + (0.01 +/- 0.00)']  |
| ['wfc3-vs-muse-calib-fq575n.pdf' | 'y = (1.00 +/- 0.02) x + (-0.00 +/- 0.00)'] |
| ['wfc3-vs-muse-calib-f673n.pdf'  | 'y = (0.97 +/- 0.01) x + (0.02 +/- 0.01)']  |
| ['wfc3-vs-muse-calib-f547m.pdf'  | 'y = (1.01 +/- 0.01) x + (-0.11 +/- 0.03)'] |
| ['wfc3-vs-muse-calib-f502n.pdf'  | 'y = (0.98 +/- 0.01) x + (-0.01 +/- 0.04)'] |


And do it for a shift in the bias per voxel of the MUSE data
+ MUSE_BIAS is in units of the original MUSE cube, which is 1e-20 erg/s/cm2/AA/pixel
+ 
#+BEGIN_SRC python :tangle histocalib-bias.py
  from astropy.io import fits
  from histocalib import histogram_calib_images, maxcount
  MUSE_BIAS = 20.0
  CONVERSION_FACTOR = 4.2e-6
  if __name__ == '__main__':
      for f, vmax in maxcount.items():
          fn = 'muse-hr-cropspec1d-wfc3-{}.fits'.format(f)
          nv = fits.open(fn)[0].header['NAXIS1']
          muse_shift = MUSE_BIAS*CONVERSION_FACTOR*nv 
          print(histogram_calib_images(f, vmax, muse_shift))


#+END_SRC

#+BEGIN_SRC sh
python histocalib-bias.py 
#+END_SRC

#+RESULTS:
| ['wfc3-vs-muse-new-calib-f487n-bias-shift.pdf'  | 'y = (0.976 +/- 0.008) x'] |
| ['wfc3-vs-muse-new-calib-f658n-bias-shift.pdf'  | 'y = (0.987 +/- 0.008) x'] |
| ['wfc3-vs-muse-new-calib-f547m-bias-shift.pdf'  | 'y = (0.992 +/- 0.001) x'] |
| ['wfc3-vs-muse-new-calib-fq674n-bias-shift.pdf' | 'y = (1.040 +/- 0.009) x'] |
| ['wfc3-vs-muse-new-calib-f656n-bias-shift.pdf'  | 'y = (1.035 +/- 0.001) x'] |
| ['wfc3-vs-muse-new-calib-fq672n-bias-shift.pdf' | 'y = (1.071 +/- 0.012) x'] |
| ['wfc3-vs-muse-new-calib-fq575n-bias-shift.pdf' | 'y = (1.059 +/- 0.017) x'] |
| ['wfc3-vs-muse-new-calib-f673n-bias-shift.pdf'  | 'y = (1.027 +/- 0.006) x'] |


Previous version, without correction of linear gradient
#+RESULTS:
| ['wfc3-vs-muse-new-calib-f487n-bias-shift.pdf'  | 'y = (0.977 +/- 0.010) x'] |
| ['wfc3-vs-muse-new-calib-f658n-bias-shift.pdf'  | 'y = (0.985 +/- 0.007) x'] |
| ['wfc3-vs-muse-new-calib-f547m-bias-shift.pdf'  | 'y = (0.997 +/- 0.005) x'] |
| ['wfc3-vs-muse-new-calib-fq674n-bias-shift.pdf' | 'y = (1.037 +/- 0.019) x'] |
| ['wfc3-vs-muse-new-calib-f656n-bias-shift.pdf'  | 'y = (1.032 +/- 0.002) x'] |
| ['wfc3-vs-muse-new-calib-fq672n-bias-shift.pdf' | 'y = (1.071 +/- 0.012) x'] |
| ['wfc3-vs-muse-new-calib-fq575n-bias-shift.pdf' | 'y = (1.056 +/- 0.020) x'] |
| ['wfc3-vs-muse-new-calib-f673n-bias-shift.pdf'  | 'y = (1.026 +/- 0.011) x'] |


#+BEGIN_SRC sh :results silent
open wfc3-vs-muse-new-calib-f*-bias-shift.pdf
#+END_SRC


*** New summary of calibration results [2016-03-19 Sat]
+ We now do not allow an offset from the origin
+ We plot the distributions of the ratio, divided into two sub-samples for faint and bright pixels
  + That is, we dumped the division by EW - too hard to explain!
+ And we use the difference between the average ratio in each subsample as the nominal uncertainty, taking the higher of that and the diff between the median and flux-weighted average
+ This works fine in all cases, except maybe F547M
  + In that case there is still some evidence for a systematic variation with strength
  + However, I am totally fed up with this, so we are not going to investigate further

**** Old summary of calibration results
+ Calibration constant is unity in most cases!
  + Exceptions are
    + F469N :: slope = 0.94
    + F673N :: slope = 0.97
    + F547M :: intercept = -0.11
+ Also no evidence of trend with EW



*** DONE Calculating the line ratios from the resampled WFC3 maps
CLOSED: [2016-03-22 Tue 18:53]
:LOGBOOK:
CLOCK: [2016-03-22 Tue 18:38]--[2016-03-22 Tue 18:53] =>  0:15
:END:
+ This is for direct comparison with the MUSE line ratio maps
  + The files have names like =wfc3-new-resample-muse-FQ575N.fits=
+ [X] We have to remember to correct for the linear trend
  + Almost forgot this
+ And we can investigate the different sets of bandpass corrections
  + Possibly have a grid of ratio-of-ratios maps, where we show successive sets, including the case of no corrections
+ This can also be a model for how we will need to redo everything for the full resolution WFC3 maps, once we have it all wrapped
+ Ideally we would re-use library components, but it is easier to just copy the source and edit it
  + Although we will import the Tsquared version of the color terms


#+BEGIN_SRC python :tangle wfc3-resample-muse-line-ratios.py
  from __future__ import print_function
  import sys
  from misc_utils import sanitize_string
  from astropy.io import fits
  T2DIR = '/Users/will/Work/RubinWFC3/Tsquared/'
  sys.path.append(T2DIR)
  import nebulio
  import nebulio_adjustments_muse
  from nebulio_adjustments_muse import set_transmission
  from new_color_terms import get_color_term

  print(nebulio.__version__)

  filtersets = {
      "5755-6583": {"line1": "[N II] 5755", "line2": "[N II] 6583",
                           "I": "FQ575N", "II": "F658N", "III": "F547M"},
      "6716-6731": {"line1": "[S II] 6716", "line2": "[S II] 6731",
                           "I": "FQ672N", "II": "FQ674N", "III": "F547M"}, 
      "6716-6731-N": {"line1": "[S II] 6716", "line2": "[S II] 6731",
                           "I": "FQ672N", "II": "FQ674N", "III": "F673N"}, 
      "4861-6563": {"line1": "H I 4861", "line2": "H I 6563",
                           "I": "F487N", "II": "F656N", "III": "F547M"},
  }


  def get_fits_data(fn='FQ575N'):
      hdu = fits.open('wfc3-new-resample-muse-{}.fits'.format(fn))[0]
      return hdu.data

  def get_fits_header(fn='FQ575N'):
      hdu = fits.open('wfc3-new-resample-muse-{}.fits'.format(fn))[0]
      return hdu.header

  heliocentric_correction = 22.40
  default_velocity =  25.0 + heliocentric_correction
  default_width = 20.0
  all_of_the_filters = ['fq575n', 'fq672n', 'fq674n', 'f673n',
                        'f487n' , 'f656n' , 'f658n' , 'f547m']
  CORRECT_LINEAR_GRADIENT = {
      'nominal': [],
      '2016-03': ['fq672n'],
      '2016-03-allgrads': all_of_the_filters,
      '2016-03-bias': all_of_the_filters,
  }

  for transmission_set in 'nominal', '2016-03-bias', '2016-03-allgrads':
      set_transmission(transmission_set=transmission_set)
      for ratio_name, filterset in filtersets.items():
          FI, FII, FIII = [filterset[J] for J in ("I", "II", "III")]
          RI = get_fits_data(FI)
          RII = get_fits_data(FII)
          RIII = get_fits_data(FIII)
          for F, R in zip([FI, FII, FIII], [RI, RII, RIII]):
              name3 = 'wfc3-over-muse-surface-calib-ratio-{}.fits'.format(F)
              if F.lower() in CORRECT_LINEAR_GRADIENT[transmission_set]:
                  # Linear correction surface to fix flat field
                  print('Gradient correction for', F, transmission_set)
                  hdus = fits.open(name3)[0]
                  R /= hdus.data

          lineids = filterset['line1'], filterset['line2']
          bpnames = ['wfc3,uvis1,' + F for F in (FI, FII, FIII)]
          fset = nebulio.Filterset(bpnames, lineids,
                                   velocity=default_velocity, fwhm_kms=default_width)
          kI = get_color_term(FI)/get_color_term(FIII)
          kII = get_color_term(FII)/get_color_term(FIII)
          ratio = fset.find_line_ratio(rates=[RI, RII, RIII],
                                       colors=(kI, kII), naive=False)
          outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio)
          fn = 'NebulioMUSE/wfc3-resample-{}-{}.fits'.format(transmission_set, ratio_name)
          print(fn)
          outhdu.writeto(fn, clobber=True)

#+END_SRC

#+BEGIN_SRC sh :tangle all-resample-line-ratios.sh
source activate py27
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python wfc3-resample-muse-line-ratios.py
#+END_SRC

#+BEGIN_SRC sh :results verbatim
sh all-resample-line-ratios.sh
#+END_SRC

#+RESULTS:
#+begin_example
0.1a5
NebulioMUSE/wfc3-resample-nominal-6716-6731.fits
NebulioMUSE/wfc3-resample-nominal-5755-6583.fits
NebulioMUSE/wfc3-resample-nominal-4861-6563.fits
NebulioMUSE/wfc3-resample-nominal-6716-6731-N.fits
Gradient correction for FQ672N 2016-03-bias
Gradient correction for FQ674N 2016-03-bias
Gradient correction for F547M 2016-03-bias
NebulioMUSE/wfc3-resample-2016-03-bias-6716-6731.fits
Gradient correction for FQ575N 2016-03-bias
Gradient correction for F658N 2016-03-bias
Gradient correction for F547M 2016-03-bias
NebulioMUSE/wfc3-resample-2016-03-bias-5755-6583.fits
Gradient correction for F487N 2016-03-bias
Gradient correction for F656N 2016-03-bias
Gradient correction for F547M 2016-03-bias
NebulioMUSE/wfc3-resample-2016-03-bias-4861-6563.fits
Gradient correction for FQ672N 2016-03-bias
Gradient correction for FQ674N 2016-03-bias
Gradient correction for F673N 2016-03-bias
NebulioMUSE/wfc3-resample-2016-03-bias-6716-6731-N.fits
Gradient correction for FQ672N 2016-03-allgrads
Gradient correction for FQ674N 2016-03-allgrads
Gradient correction for F547M 2016-03-allgrads
NebulioMUSE/wfc3-resample-2016-03-allgrads-6716-6731.fits
Gradient correction for FQ575N 2016-03-allgrads
Gradient correction for F658N 2016-03-allgrads
Gradient correction for F547M 2016-03-allgrads
NebulioMUSE/wfc3-resample-2016-03-allgrads-5755-6583.fits
Gradient correction for F487N 2016-03-allgrads
Gradient correction for F656N 2016-03-allgrads
Gradient correction for F547M 2016-03-allgrads
NebulioMUSE/wfc3-resample-2016-03-allgrads-4861-6563.fits
Gradient correction for FQ672N 2016-03-allgrads
Gradient correction for FQ674N 2016-03-allgrads
Gradient correction for F673N 2016-03-allgrads
NebulioMUSE/wfc3-resample-2016-03-allgrads-6716-6731-N.fits
#+end_example


*** DONE Crop the MUSE ratio maps to the WFC3 field
CLOSED: [2016-03-22 Tue 19:55]
:LOGBOOK:
CLOCK: [2016-03-22 Tue 18:53]--[2016-03-22 Tue 19:06] =>  0:13
:END:
This is very similar to [[id:1B689511-B4ED-42AD-8C76-70638FEA13BE][{2/2} Crop MUSE image to the WFC3 field]], except for different files
#+BEGIN_SRC python :tangle crop_muse_ratios.py
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.wcs import WCS, WCSSUB_SPECTRAL
  import astropy.units as u

  def crop_muse_to_wfc3(
          fid,
          muse_pattern='LineMaps/ratio-{}-bin004.fits',
          wfc3_pattern='NebulioMuse/wfc3-resample-2016-03-{}.fits',
          crop_pattern='crop-ratio-{}-bin004.fits',
          wfc3_hduname=0, muse_hduname='SCALED'
          ):
      """Cut out a section of the MUSE image to match the WFC3 field"""
      wname = wfc3_pattern.format(fid)
      mname = muse_pattern.format(fid)
      whdu = fits.open(wname)[wfc3_hduname]
      mhdu = fits.open(mname)[muse_hduname]
      wcs_w = WCS(whdu.header).celestial
      wcs_m = WCS(mhdu.header).celestial
      # Check that the two images have the same reference point in RA, DEC
      assert np.all(wcs_w.wcs.crval == wcs_m.wcs.crval)
      # And that the pixel scales are the same
      wcd = wcs_w.wcs.cdelt*wcs_w.wcs.pc
      mcd = wcs_m.wcs.cdelt*wcs_m.wcs.pc
      assert np.all(wcd == mcd), '{} differs from {}'.format(repr(wcd), repr(mcd)) 

      # The shapes of the two grids: (nx, ny) in FITS axis order
      shape_w = np.array([whdu.header['NAXIS1'], whdu.header['NAXIS2']])
      shape_m = np.array([mhdu.header['NAXIS1'], mhdu.header['NAXIS2']])

      # The difference in CRPIX values tells us the start indices (i, j)
      # for the crop window on the MUSE grid. Note that this is in
      # zero-based array indices
      start = wcs_m.wcs.crpix - wcs_w.wcs.crpix
      # The stop indices for the crop window 
      stop = start + shape_w

      # Shift 1 pixel to the right to do a coarse alignment correction
      start[0] += -1
      stop[0] += -1

      # Check that these are within bounds of the original MUSE grid
      assert np.all(start >= 0.0)
      assert np.all(stop < shape_m)

      # Crop the MUSE data array to the start:stop indices, remembering
      # that python axis order is backwards with respect to FITS axis
      # order
      newview = (slice(start[1], stop[1]), slice(start[0], stop[0]))
      mhdu.data = mhdu.data[newview]

      # And crop the WCS object in the same way
      wcs_new = wcs_m.slice(newview)
      # And copy the new cropped wcs into the new MUSE header
      mhdu.header.update(wcs_new.to_header())

      # Write out the new cropped MUSE image
      oname = crop_pattern.format(fid)
      mhdu.writeto(oname, clobber=True)

      return oname


  if __name__ == '__main__':
      try:
          ratio_id = sys.argv[1]
      except:
          print('Usage:', sys.argv[0], 'RATIO')

      print(crop_muse_to_wfc3(ratio_id))


#+END_SRC

#+BEGIN_SRC sh :results verbatim
python crop_muse_ratios.py 6716-6731
#+END_SRC

#+RESULTS:
: crop-ratio-6716-6731-bin004.fits

#+BEGIN_SRC sh :results verbatim
python crop_muse_ratios.py 5755-6583
#+END_SRC

#+RESULTS:
: crop-ratio-5755-6583-bin004.fits

#+BEGIN_SRC sh :results verbatim
python crop_muse_ratios.py 4861-6563
#+END_SRC

#+RESULTS:
: crop-ratio-4861-6563-bin004.fits


*** DONE Take ratios of ratios between MUSE and WFC3
CLOSED: [2016-03-23 Wed 13:42]
:LOGBOOK:
CLOCK: [2016-03-22 Tue 19:57]--[2016-03-22 Tue 23:17] =>  3:20
:END:
#+BEGIN_SRC python :tangle make-wfc3-muse-ratio-of-ratios.py
  from astropy.io import fits

  ratios = ['5755-6583', '6716-6731', '4861-6563', '6716-6731-N']

  def divide_fits_images(name1, name2, outname):
      hdu1 = fits.open(name1)[0]
      hdu2 = fits.open(name2)['SCALED']
      fits.PrimaryHDU(header=hdu1.header,
                      data=hdu1.data/hdu2.data).writeto(outname, clobber=True)
      print(outname)

  if __name__ == '__main__':
      for Tset in 'nominal', '2016-03-bias', '2016-03-allgrads':
          for r in ratios:
              # remove third element for MUSE ratio file
              rr = '-'.join(r.split('-')[:2]) 
              divide_fits_images(
                  'NebulioMUSE/wfc3-resample-{}-{}.fits'.format(Tset, r),
                  'crop-ratio-{}-bin004.fits'.format(rr),
                  'NebulioMUSE/wfc3-over-muse-ratio-of-ratios-{}-{}.fits'.format(Tset, r)
          )
  
#+END_SRC

#+BEGIN_SRC sh :results verbatim
python make-wfc3-muse-ratio-of-ratios.py
#+END_SRC

#+RESULTS:
#+begin_example
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-5755-6583.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-6716-6731.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-4861-6563.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-6716-6731-N.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-5755-6583.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-6716-6731.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-4861-6563.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-6716-6731-N.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-5755-6583.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-6716-6731.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-4861-6563.fits
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-6716-6731-N.fits
#+end_example


*** DONE Make plots of the ratios of ratios
CLOSED: [2016-03-23 Wed 16:15]
:LOGBOOK:
CLOCK: [2016-03-22 Tue 23:17]--[2016-03-23 Wed 01:17] =>  2:00
:END:
#+BEGIN_SRC python :eval no :tangle plot-ratio-of-ratios.py
  import matplotlib
  matplotlib.use('Agg')
  import matplotlib.pyplot as plt
  import aplpy
  from astropy.io import fits
  import pyregion
  import numpy as np

  Tsets = ['nominal', '2016-03-bias', '2016-03-allgrads']
  ratios = ['5755-6583', '6716-6731', '4861-6563', '6716-6731-N']
  vmin = {'5755-6583': 0.005, '6716-6731': 0.4, '4861-6563': 0.15}
  vmax = {'5755-6583': 0.035, '6716-6731': 0.9, '4861-6563': 0.3}
  cmap = matplotlib.cm.RdYlBu_r
  ra0, dec0 = 83.80716, -5.403
  dra, ddec = 0.025, 0.025
  for r in ratios:
      rr = '-'.join(r.split('-')[:2])
      rlabel = rr.replace('-', ' / ')
      mfile = 'crop-ratio-{}-bin004.fits'.format(rr)
      for Tset in Tsets:
          wfiles = ['NebulioMUSE/wfc3-resample-{}-{}.fits'.format(Tset, r)
                    for Tset in Tsets]
          rfiles = ['NebulioMUSE/wfc3-over-muse-ratio-of-ratios-{}-{}.fits'.format(Tset, r)
                    for Tset in Tsets]
          for fitsfile in [mfile] + wfiles + rfiles:
              f = aplpy.FITSFigure(fitsfile) 
              f.recenter(ra0, dec0, width=dra, height=ddec)
              if 'ratio-of-ratios' in fitsfile:
                  sweet_region = 'new-combined-sweet-black.reg'
                  f.show_colorscale(interpolation='none', vmin=0.0, vmax=2.0, cmap=cmap)
              else:
                  sweet_region = 'new-combined-sweet.reg'
                  f.show_grayscale(interpolation='none', vmin=vmin[rr], vmax=vmax[rr])
              f.show_regions(sweet_region)
              f.add_label(0.2, 0.05, rlabel, 
                          horizontalalignment='left', relative=True)
              f.add_colorbar()
              figfile = fitsfile.replace('.fits', '.jpg')
              plt.gcf().set_size_inches(6, 5)
              plt.gcf().tight_layout()
              plt.gcf().savefig(figfile, dpi=300)
              print(figfile)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
python plot-ratio-of-ratios.py
#+END_SRC

#+RESULTS:
#+begin_example
crop-ratio-5755-6583-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-5755-6583.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-5755-6583.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-5755-6583.jpg
crop-ratio-5755-6583-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-5755-6583.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-5755-6583.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-5755-6583.jpg
crop-ratio-5755-6583-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-5755-6583.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-5755-6583.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-5755-6583.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-5755-6583.jpg
crop-ratio-6716-6731-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-6716-6731.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-6716-6731.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-6716-6731.jpg
crop-ratio-6716-6731-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-6716-6731.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-6716-6731.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-6716-6731.jpg
crop-ratio-6716-6731-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-6716-6731.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-6716-6731.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-6716-6731.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-6716-6731.jpg
crop-ratio-4861-6563-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-4861-6563.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-4861-6563.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-4861-6563.jpg
crop-ratio-4861-6563-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-4861-6563.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-4861-6563.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-4861-6563.jpg
crop-ratio-4861-6563-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-4861-6563.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-4861-6563.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-4861-6563.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-4861-6563.jpg
crop-ratio-6716-6731-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-6716-6731-N.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-6716-6731-N.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-6716-6731-N.jpg
crop-ratio-6716-6731-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-6716-6731-N.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-6716-6731-N.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-6716-6731-N.jpg
crop-ratio-6716-6731-bin004.jpg
NebulioMUSE/wfc3-resample-nominal-6716-6731-N.jpg
NebulioMUSE/wfc3-resample-2016-03-bias-6716-6731-N.jpg
NebulioMUSE/wfc3-resample-2016-03-allgrads-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-nominal-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-6716-6731-N.jpg
NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-allgrads-6716-6731-N.jpg
#+end_example

#+BEGIN_SRC sh :results silent
open NebulioMUSE/wfc3-over-muse-ratio-of-ratios-*allgrads*.jpg
#+END_SRC

#+BEGIN_SRC sh :results silent
open NebulioMUSE/wfc3-over-muse-ratio-of-ratios-*bias*.jpg
#+END_SRC

#+BEGIN_SRC sh :results silent
open NebulioMUSE/wfc3-over-muse-ratio-of-ratios-*nominal*.jpg
#+END_SRC

#+BEGIN_SRC sh :results silent
open crop-ratio-*-bin004.jpg
#+END_SRC

#+BEGIN_SRC sh :results silent
open NebulioMUSE/wfc3-resample-*allgrads*.jpg
#+END_SRC
#+BEGIN_SRC sh :results silent
open NebulioMUSE/wfc3-resample-*bias*.jpg
#+END_SRC

*** STARTED [#A] Resolving issues with the [N II] ratio of ratios
:LOGBOOK:
CLOCK: [2016-03-23 Wed 14:33]--[2016-03-24 Thu 14:36] => 24:03
- Note taken on [2016-03-23 Wed 16:21] \\
  This is the principal outstanding issue
:END:

**** The evidence for a problem 
+ [[file:NebulioMUSE/wfc3-over-muse-ratio-of-ratios-2016-03-bias-5755-6583.jpg][Image of 5755/6583 ratio of ratios]]
+ This shows an increase in the ratio-of-ratios from ~1 in the bright part of the WFC3 field to ~1.2 in the faint part
+ The transition occurs across about 5 arcsec
+ And it seems to be parallel to the chip axis - maybe
**** What I have discovered from looking at the ratio images in DS9
+ Summarised in this image
  + [[file:WFC3%20-%20MUSE%20ratio%20discrepancies.jpg]]
+ The image shows the 5755/6583 ratio of ratios, which has a problematic climb in the lower right portion.
  + Profile is shown on left (third one down, yellow text)
  + Orange horizontal lines show the 1.0 and 1.2 level
+ The rise on the far right can be explained by deviations from unity in the FQ575N WFC3/MUSE photometry ratio
  + Shown in second profile, green text and green ellipse/arrow
  + This seems to be a feature of unknown origin in the WFC3 FQ575N image
  + It is the triangular area that we shave off on the W side of the sweet spot
+ The rise closer to the middle, coincides with deviations seen in two other ratios:
  1. A dip in the F547M WFPC3/MUSE photometry ratio
     + Top right panel, blue text
     + This is clearly an artifact in the MUSE synthetic F547M filter image, and not in the WFC3 F547M image, and so *it should not affect* the 5755/6583 ratio of ratios
  2. An increase (albeit very noisy) in the MUSE 5755/6583 synthetic filter/spectrum ratio of ratios
     + This could potentially (*A*) be caused by the MUSE F547M artifact
     + Or it could be (*B*) due to some continuum color variation in the nebula
+ If *A* is correct, then the first rise from ~1.0 to ~1.15 in the WFC3/MUSE ratio of ratios is entirely unexplained
+ if *B* is correct, then it /might/ also explain the WFC3/MUSE ratio of ratios
  + /BUT/ the sense of the deviation is that we are overestimating 5755, which would mean we are underestimating the continuum at 5755, which means the continuum color must be *redder* than we are assuming
  + This seems unlikely, since I would expect the continuum color to become bluer in the fainter regions
    + Because dust-scattered continuum is more uniform than the atomic continuum
  + Although the other possibility is that the color term is just generally redder, but that it has more effect in the fainter regions
+ The only thing to do is to actually map the color
**** STARTED Maps of continuum color 
:LOGBOOK:
CLOCK: [2016-03-24 Thu 16:38]--[2016-03-24 Thu 18:38] =>  2:00
:END:
***** Simplest way, ratio of 5755 cont to F547M synthetic 
#+BEGIN_SRC python :tangle find-cont-ratio-5755-to-F547M.py
from astropy.io import fits
hduA = fits.open('LineMaps/continuum-N_II-5755-bin016.fits')['SCALED']
hduB = fits.open('muse-hr-image-wfc3-f547m-bin016.fits')['SCALED']
hduA.data /= hduB.data
hduA.writeto('cont-ratio-5755-to-F547M-bin016.fits', clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results silent
python find-cont-ratio-5755-to-F547M.py
#+END_SRC

+ This is quite noisy still at 4x4 - may be necessary to go to 16x16
+ It smoothly declines from about 1050 to about 1030 across the sweet spot
  + Change of about 2%
+ We could also do the ratio with the continuum at Hb

#+BEGIN_SRC python :tangle find-cont-ratio-5755-to-5270.py
  from astropy.io import fits
  hduA = fits.open('LineMaps/continuum-N_II-5755-bin016.fits')['SCALED']
  hduB = fits.open('LineMaps/continuum-Fe_III-5270-bin016.fits')['SCALED']
  hduA.data /= hduB.data
  hduA.writeto('cont-ratio-5755-to-5270-bin016.fits', clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results silent
python find-cont-ratio-5755-to-5270.py
#+END_SRC

***** Putting that ratio in more useful units
+ The LineMaps file is in MUSE units of 1e-20 erg/s/cm2/AA/muse-pixel
  + To get a \(\langle \lambda I_{\lambda }\rangle\) we multiply by 5755 1e-20 and divide by (0.2 arcsec/radian)**2 = 9.40175455274e-13
  + So lamIlam = 6.12119787612e-5 continuum signal
+ The F547M file is in units of counts/s/wfc3-pixel
  + This is C_{WFC3} T_{m} W_{j} lamIlam
  + C = 0.0840241
  + Tm = 0.26165068543583586
  + Wj = 649.89 AA
  + So C Tm Wj = 14.2878078368
+ So k = 6.12119787612e-5 14.2878078368 continuum-5755 / counts-F547M
+ k = 8.7458498985e-4 1050 = 0.918
  + Yay, that looks good
  + Falling to 8.7458498985e-4 1030 = 0.901
+ We had it as 0.922 +/- 0.03
  + Which is 0.95 / 1.03
  + So that is almost the same
+ But the denominator should not include the 5755 line itself
  + EW(5755) = 4 to 40 AA
  + Nebulio gives Wtwiddle as 901 AA
  + So E/W = 0.004 to 0.044
***** A more accurate map of ktwiddle for 5755 wrt F547M
+ Building on calcs of previous section
| Line          | EW            |  Wtwid | E/W              |
|---------------+---------------+--------+------------------|
| [N II] 5755   | [4 .. 40]     |    901 | [0.004 .. 0.044] |
|---------------+---------------+--------+------------------|
| He I 5876     | [120 .. 150]  |  11715 | [0.010 .. 0.013] |
| [Fe III] 5270 | [1.5 .. 13]   |    652 | [0.002 .. 0.020] |
| [Cl III] 5518 | [3 .. 4]      |    703 | [0.004 .. 0.006] |
| [Cl III] 5538 | [5 .. 7]      |    711 | [0.007 .. 0.010] |
| [N I] 5199    | [3 .. 4]      |    670 | [0.004 .. 0.006] |
| [O III] 5007  | [900 .. 1000] | 476000 | [0.002 .. 0.002] |
|---------------+---------------+--------+------------------|
|               |               |        | [0.029 .. 0.057] |
#+TBLFM: $4=$2/$3;f3::@9$4=vsum(@II..@III);f3
+ So we have ktwiddle = 1.03 to 1.057, even without 5755 
+ We can calculate the Sum(1 + E/W) term for F547M 

#+BEGIN_SRC python :tangle make-color-maps.py
  """Generate E/W maps for all the non-target lines
  """
  import numpy as np
  from astropy.io import fits
  import nebulio
  from misc_utils import sanitize_string

  def fix_up_lineid(lineid):
      """Convert '[O III] 5007' to 'O_III-5007', etc"""
      pieces = lineid.split(' ')
      wavid = pieces[-1]
      ionid = sanitize_string(' '.join(pieces[:-1]))
      return '-'.join([ionid, wavid])


  target_line_id = "[N II] 5755"
  non_target_line_ids = [
      'He I 5876',
      '[Fe III] 5270',
      '[Cl III] 5518',
      '[Cl III] 5538',
      '[N I] 5199',
      '[O III] 5007',
  ]
  FILTER_ID = 'f547m'
  SUFFIX = '-bin016'
  velocity = 25.0 - 16.2
  width = 20.0

  sanid = fix_up_lineid(target_line_id)
  fn_I ='LineMaps/continuum-{}{}.fits'.format(sanid, SUFFIX) 
  contI_hdu = fits.open(fn_I)['SCALED']
  fn_III = 'muse-hr-image-wfc3-{}{}.fits'.format(FILTER_ID, SUFFIX)
  R_III_hdu = fits.open(fn_III)['SCALED']

  bp = nebulio.Bandpass('wfc3,uvis1,' + FILTER_ID)

  C_WFC3 = 0.0840241
  em = nebulio.EmissionLine(target_line_id, velocity=velocity, fwhm_kms=width)
  lamIlam_cont_I = contI_hdu.data * 1e-20*em.wav0[0] / (0.2/206265)**2
  lamIlam_III = R_III_hdu.data / (C_WFC3*bp.Tm*bp.Wj)
  ktwiddle = lamIlam_cont_I / lamIlam_III
  kfile = 'Linemaps/ktwid-{}-{}{}.fits'.format(sanid, FILTER_ID, SUFFIX)
  contI_hdu.data = ktwiddle
  fits.PrimaryHDU(header=contI_hdu.header, data=ktwiddle).writeto(kfile, clobber=True)

  one_plus_sum_E_over_W = np.ones_like(ktwiddle)
  for line_id in [target_line_id] + non_target_line_ids:
      sanid = fix_up_lineid(line_id)
      ewfile = 'LineMaps/ew-{}{}.fits'.format(sanid, SUFFIX)
      em = nebulio.EmissionLine(line_id, velocity=velocity, fwhm_kms=width)
      W = bp.Wtwid(em)[0]
      Ehdu = fits.open(ewfile)['SCALED']
      Ehdu.data /= W
      Ehdu.writeto(ewfile.replace('ew-', 'E_over_W-'), clobber=True)
      if line_id != target_line_id:
          one_plus_sum_E_over_W += Ehdu.data

  fits.PrimaryHDU(header=contI_hdu.header,
                  data=one_plus_sum_E_over_W
  ).writeto(
      'LineMaps/one_plus_sum_E_over_W-{}{}.fits'.format(
          FILTER_ID, SUFFIX),
      clobber=True)

  fits.PrimaryHDU(header=contI_hdu.header,
                  data=ktwiddle*one_plus_sum_E_over_W
  ).writeto(kfile.replace('ktwid', 'knorm'), clobber=True)

    
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC sh :results silent
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
source activate py27
python make-color-maps.py
#+END_SRC

+ This does exactly what we expect.
+ ktwiddle falls from 0.95 to 0.92 across the sweet spot


***** STARTED [#A] Just for a laugh, subtracting He I from C II 
+ This sums together the C II 7236 + 7231 lines
+ And then subtracts a scaled version of the He I 6678 line
  + Divides by 13
+ The idea is that the C II emission is the sum of recombination and fluorescence
+ The recombination portion should be more or less proprtional to the He I emission
  + Except for the slight Ne and Te dependence of He I
  + And fact that He+ ionization zone only imperfectly overlaps with the C^{++} ionization zone
    + There will be an inner C^{+++} zone, but that should not matter too much
+ [ ] [2019-08-31 Sat] This would be better using the 6462 C II line, since that should be pure recombination
  + But I need to make a map of that line


#+BEGIN_SRC python :tangle c-ii-fluorescent.py
from astropy.io import fits
hduA = fits.open('LineMaps/linesum-C_II-7236-multibin-SN0010.fits')['SCALED']
hduAA = fits.open('LineMaps/linesum-C_II-7231-multibin-SN0010.fits')['SCALED']
hduB = fits.open('LineMaps/linesum-He_I-6678-multibin-SN0005.fits')['SCALED']
hduA.data += hduAA.data
hduA.data -= hduB.data/13.0
hduA.writeto('C_II-723X-fluorescent.fits', clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results silent
python c-ii-fluorescent.py
#+END_SRC

I need to make an aply figure of this and all my other rgb images

****** [2019-06-21 Fri] Do the same, but for the unbinned data

We now need to be more careful about the data folder, since we have removed the symbolic link to the external disk from Dropbox

#+BEGIN_SRC python :tangle c-ii-fluorescent-bin001.py
  from astropy.io import fits
  datadir = "/Volumes/SSD-1TB/OrionMuse/LineMaps"
  hduA = fits.open(f'{datadir}/linesum-C_II-7236-bin001.fits')['SCALED']
  hduAA = fits.open(f'{datadir}/linesum-C_II-7231-bin001.fits')['SCALED']
  hduB = fits.open(f'{datadir}/linesum-He_I-6678-bin001.fits')['SCALED']
  hduA.data += hduAA.data
  hduA.data -= hduB.data/13.0
  hduA.writeto('C_II-723X-fluorescent-bin001.fits', clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results silent
python c-ii-fluorescent-bin001.py
#+END_SRC



***** Extracting channel maps for doing an aplpy rgb figure
+ Adapted from similar script for Alba stuff


****** Actually making the RGB figure
#+name: rgb-muse-image
#+header: :var TAB=rgb-limits-hi SUFFIX="hi"
#+BEGIN_SRC python :return figfile :results file :tangle rgb-muse-image.py
  from astropy.io import fits
  import aplpy

  figfile = 'rgb-muse-{}.pdf'.format(SUFFIX)

  # Unpack the channel info from the table
  [rf, r1, r2, rs], [gf, g1, g2, gs], [bf, b1, b2, bs] = TAB
  rgbfiles = [rf + '.fits', gf + '.fits', bf + '.fits']

  # aplpy can only deal with the primary headers, so sort that out first
  template = 'rgb-for-aplpy-{}.fits'
  channels = ['red', 'green', 'blue']
  newfiles = [template.format(chan) for chan in channels]
  for newfn, fn in zip(newfiles, rgbfiles):
      hdu = fits.open(fn)['SCALED']
      fits.PrimaryHDU(data=hdu.data, header=hdu.header).writeto(newfn, overwrite=True)

  aplpy.make_rgb_image(newfiles, 'rgb-for-aplpy.png',
                       vmin_r=r1, vmin_g=g1, vmin_b=b1,
                       vmax_r=r2, vmax_g=g2, vmax_b=b2,
                       stretch_r=rs, stretch_g=gs, stretch_b=bs, 
                       make_nans_transparent=True)
  f = aplpy.FITSFigure(newfiles[0])
  f.show_rgb('rgb-for-aplpy.png')
  # f.recenter(83.6875, -5.4167, width=0.25, height=0.167)
  f.add_grid()
  f.grid.set_color('white')
  f.grid.set_alpha(0.2)
  f.save(figfile)
#+END_SRC

#+name: rgb-limits-hi
| C_II-723X-fluorescent                                                  | 0 | 31000 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-Cl_IV-8046-multibin-SN0005 | 0 |  8200 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-Ar_IV-4740-multibin-SN0005 | 0 |  9900 | linear |

#+call: rgb-muse-image(TAB=rgb-limits-hi, SUFFIX="hi") :results file

#+RESULTS:
[[file:rgb-muse-hi.pdf]]

#+name: rgb-limits-mod
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-Ar_III-7751-multibin-SN0005 | 0 |   435000 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-He_I-6678-multibin-SN0005   | 0 |   357000 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-O_III-5007-multibin-SN0005  | 0 | 16250000 | linear |

#+call: rgb-muse-image(TAB=rgb-limits-mod, SUFFIX="mod") :results file

#+RESULTS:
[[file:rgb-muse-mod.pdf]]

#+name: rgb-limits-lowish
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-O_II-7318-multibin-SN0005 | 0 |  900000 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-N_II-6583-multibin-SN0005 | 0 | 7500000 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-N_II-5755-multibin-SN0005 | 0 |  100000 | linear |

#+call: rgb-muse-image(TAB=rgb-limits-lowish, SUFFIX="lowish") :results file

#+RESULTS:
[[file:rgb-muse-lowish.pdf]]

#+name: rgb-limits-lowest
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-O_I-8446-multibin-SN0005  | 0 | 200000 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-O_I-6300-multibin-SN0005  | 0 | 200000 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-S_II-6731-multibin-SN0005 | 0 | 900000 | linear |

#+call: rgb-muse-image(TAB=rgb-limits-lowest, SUFFIX="lowest") :results file

#+RESULTS:
[[file:rgb-muse-lowest.pdf]]


[2019-06-21 Fri] Make a version with no binning, just to show how bad it is

#+name: rgb-limits-hi-bin001
| C_II-723X-fluorescent-bin001                                  | 0 | 31000 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-Cl_IV-8046-bin001 | 0 |  8200 | linear |
| /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-Ar_IV-4740-bin001 | 0 |  9900 | linear |

#+call: rgb-muse-image(TAB=rgb-limits-hi-bin001, SUFFIX="hi-bin001") :results file

#+RESULTS:
[[file:rgb-muse-hi-bin001.pdf]]

****** Utility script for getting info from DS9 about current frame
#+name: get-rgb-info-from-ds9
#+BEGIN_SRC sh :results verbatim
  for chan in red green blue; do
      echo "#### $chan channel ####"
      xpaset -p ds9 rgb $chan
      xpaget ds9 file
      xpaget ds9 scale limits
  done
#+END_SRC

******* Highest ionization regions

#+call: get-rgb-info-from-ds9()

#+RESULTS:
: #### red channel ####
: /Users/will/Dropbox/OrionMuse/C_II-723X-fluorescent.fits[SCALED]
: -2830.4907 31035.947
: #### green channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-Cl_IV-8046-multibin-SN0005.fits[SCALED]
: -801.86713 8158.6085
: #### blue channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-Ar_IV-4740-multibin-SN0005.fits[SCALED]
: 0 9892.3398


******* Moderate ionization

#+call: get-rgb-info-from-ds9()

#+RESULTS:
: #### red channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-Ar_III-7751-multibin-SN0005.fits[SCALED]
: 0 435286.36
: #### green channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-He_I-6678-multibin-SN0005.fits[SCALED]
: 0 356631.6
: #### blue channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-O_III-5007-multibin-SN0005.fits[SCALED]
: 0 16258925


******* Lowish ionization
#+call: get-rgb-info-from-ds9()

#+RESULTS:
: #### red channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-N_II-5755.fits
: 0 100000
: #### green channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-O_II-7318.fits
: 0 1264714
: #### blue channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-N_II-6583.fits
: 0 7402224.7


******* Lowest ionization
#+call: get-rgb-info-from-ds9()

#+RESULTS:
: #### red channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-O_I-8446-multibin-SN0005.fits[SCALED]
: 0 234906.83
: #### green channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-O_I-6300-multibin-SN0005.fits[SCALED]
: 0 296253.8
: #### blue channel ####
: /Volumes/SSD-1TB/OrionMuse/LineMaps/linesum-S_II-6731-multibin-SN0005.fits[SCALED]
: 0 820155.68

** Useful scripts
:PROPERTIES:
:header-args: :results silent
:END:
#+name: new-blank-ds9
#+BEGIN_SRC sh :results silent :var DS9="ds9"
open -n -a SAOImage\ DS9 --args -title $DS9
sleep 1
xpaset -p $DS9 view buttons no
xpaset -p $DS9 frame delete all
#+END_SRC

#+call: new-blank-ds9("cube") :results silent

#+BEGIN_SRC sh
xpaset -p cube frame new
xpaset -p cube fits $PWD/muse-hr-fullcube-rebin05x05.fits
#+END_SRC

#+BEGIN_SRC sh
xpaset -p ds9 frame new
xpaset -p ds9 fits $PWD/muse-hr-data-wavsec3.fits
#+END_SRC

#+RESULTS:


* DONE Line ratios -> T, N diagnostics for the MUSE data
CLOSED: [2015-10-26 Mon 09:18]
+ This will allow us to extend the t2 spatial scale analysis to larger scales
+ And will give us another window onto the effects of noise on the results
+ Will also be practise for redoing everything with WFC3

** De-redden the nii line ratio
#+BEGIN_SRC python :tangle muse-deredden.py
  import sys
  from astropy.io import fits

  sys.path.append('/Users/will/Work/RubinWFC3/Tsquared')
  from deredden import deredden_nii_ratio

  hb_ha = fits.open('Linemaps/ratio-4861-6563.fits')[0].data
  nii_hdu = fits.open('Linemaps/ratio-5755-6583.fits')[0]
  nii_hdu.data = deredden_nii_ratio(nii_hdu.data, hb_ha)
  nii_hdu.writeto('Linemaps/ratio-5755-6583-deredden-2874.fits', clobber=True)

  hb_ha = fits.open('NebulioMUSE/synthetic-ratio-4861-6563.fits')[0].data
  nii_hdu = fits.open('NebulioMUSE/synthetic-ratio-5755-6583.fits')[0]
  nii_hdu.data = deredden_nii_ratio(nii_hdu.data, hb_ha)
  nii_hdu.writeto('NebulioMUSE/synthetic-ratio-5755-6583-deredden-2874.fits', clobber=True)

#+END_SRC

#+BEGIN_SRC sh :results silent
python muse-deredden.py
#+END_SRC


** Plot histogram of [N II] vs [S II] line ratios
:PROPERTIES:
:ID:       012A7F6B-BC6B-433E-A5A8-E1453B1E3FCA
:END:
Based on a [[id:D15B6745-A22C-420C-A669-E39FD7954AC7][very similar program for WFC3 data]]
#+BEGIN_SRC python :tangle muse-rnii-rsii-histogram.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from matplotlib import pyplot as plt
  import pyregion
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from pyneb_utils import rsii_T_den, rnii_T_den

  try:
      region = sys.argv[1]
  except IndexError:
      sys.exit('Usage: {} REGION [SUFFIX]'.format(sys.argv[0]))

  try:
      suffix = '-' + sys.argv[2]
  except IndexError:
      suffix = ''
  
  snii_hdu = fits.open("Linemaps/linesum-N_II-6583{}.fits".format(suffix))['SCALED']
  hduA = fits.open("Linemaps/ratio-6716-6731{}.fits".format(suffix))['SCALED']
  hduB = fits.open("Linemaps/ratio-5755-6583{}-deredden-2874.fits".format(suffix))['SCALED']
  # hduB = fits.open(prefix + "ratio-5755-6583.fits")[0]

  xmin, xmax, ymin, ymax = 0.4, 1.0, 0.0, 0.05

  m = np.isfinite(hduA.data) & np.isfinite(hduB.data)
  m = m & (hduA.data > 0.0) & (hduB.data > 0.0) 
  if 'sweet' in region.lower():
      title = 'Orion S'
      include = pyregion.open(t2dir + '/will-nii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-nii-exclude-wcs.reg')
      m = m & include.get_mask(hdu=snii_hdu) & (~exclude.get_mask(hdu=snii_hdu))

      include = pyregion.open(t2dir + '/will-sii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-sii-exclude-wcs.reg')
      m = m & include.get_mask(hdu=snii_hdu) & (~exclude.get_mask(hdu=snii_hdu))
  else:
      title = 'Full nebula'
    
  x = hduA.data[m]
  y = hduB.data[m]
  w = snii_hdu.data[m]
  gamma = 1.5
  fig, ax = plt.subplots(1, 1)
  H, xedges, yedges = np.histogram2d(x, y, 50,
                                     [[xmin, xmax], [ymin, ymax]],
                                     weights=w)
  ax.imshow((H.T)**(1.0/gamma), extent=[xmin, xmax, ymin, ymax],
            interpolation='nearest', aspect='auto', origin='lower', 
            cmap=plt.cm.gray_r, alpha=1.0)

  denrange = np.linspace(0.0, 8.e4, 200)
  for tem in [7e3, 9e3, 1.1e4, 1.3e4, 1.5e4, 1.7e4]:
      ax.plot(rsii_T_den(tem, denrange), rnii_T_den(tem, denrange),
              label="T = {:.0f} K".format(tem))

  temrange = np.linspace(5000.0, 20000.0, 100)
  for den in [1000, 2000, 4000, 8000, 16000, 32000]:
      ax.plot(rsii_T_den(temrange, den), rnii_T_den(temrange, den),
              '--', label="n = {:.0f} pcc".format(den))

  ax.set_xlim(xmin, xmax)
  ax.set_ylim(ymin, ymax)
  ax.set_xlabel('[S II] 6716 / 6731')
  ax.set_ylabel('Dereddened [N II] 5755 / 6584')
  ax.grid()
  ax.legend(ncol=2, fontsize='x-small', handlelength=2.2, numpoints=1)

  fig.set_size_inches(7, 7)
  pltfile = 'muse-rnii-rsii-histogram-{}{}.pdf'.format(region, suffix)

  fig.savefig(pltfile)
  print(pltfile)
#+END_SRC

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py sweet bin001
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-sweet-bin001.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin001
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin001.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin004
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin004.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin016
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin016.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin064
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin064.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin256
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin256.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py NebulioMUSE/synthetic-
#+END_SRC

#+RESULTS:
[[file:muse-synthetic-rnii-rsii-histogram.pdf]]


** Use pyneb to calculate the Te, ne from [S II], [N II]
#+BEGIN_SRC python :tangle muse-make-te-ne-maps.py
  import sys
  import numpy as np
  from astropy.io import fits
  from derive_ne_te_1phase import T_den_from_rsii_rnii

  prefix = 'Linemaps/'
  hduA = fits.open(prefix + "ratio-6716-6731.fits")[0]
  hduB = fits.open(prefix + "ratio-5755-6583-deredden-2874.fits")[0]

  Te = np.empty_like(hduA.data)
  Ne = np.empty_like(hduA.data)
  m = np.isfinite(hduA.data) & np.isfinite(hduB.data) & (hduA.data > 0) & (hduB.data > 0)
  Te[m], Ne[m] = T_den_from_rsii_rnii(hduA.data[m], hduB.data[m])
  Te[~m], Ne[~m] = np.nan, np.nan
  fits.PrimaryHDU(header=hduA.header, data=Te).writeto(
      prefix + 'muse-derived-Te.fits', clobber=True)
  fits.PrimaryHDU(header=hduA.header, data=Ne).writeto(
      prefix + 'muse-derived-Ne.fits', clobber=True)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
time python muse-make-te-ne-maps.py
#+END_SRC

#+RESULTS:


** DONE Extension to [Cl III], [S III] pair
CLOSED: [2015-10-25 Sun 21:58]
+ We can use [Cl III] 5538/5518 for density
+ And [S III] 6312/9069 for Te
  + But it needs correcting for extinction
  + We can use the Balmer-Paschen line ratio to correct for this
  + For instance 6563/9299
  + 6563/6312 = 1.04 whereas 9299/9069 = 1.025 so not too far off
  + Dereddening is done down [[id:89D30B56-E005-4846-8CD2-FBA8C008109D][here]]
*** Plot histogram of [S III] vs [Cl III] line ratios
#+BEGIN_SRC python :tangle muse-rsiii-rcliii-histogram.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from matplotlib import pyplot as plt
  import pyregion
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from pyneb_utils import rcliii_T_den, rsiii_T_den

  try:
      region = sys.argv[1]
  except IndexError:
      sys.exit('Usage: {} REGION [SUFFIX]'.format(sys.argv[0]))
  
  try:
      suffix = '-' + sys.argv[2]
  except IndexError:
      suffix = ''
  
  ssiii_hdu = fits.open("Linemaps/linesum-S_III-9069{}.fits".format(suffix))['SCALED']
  hduA = fits.open("Linemaps/ratio-5538-5518{}.fits".format(suffix))['SCALED']
  hduB = fits.open("Linemaps/ratio-6312-9069-deredden{}.fits".format(suffix))['SCALED']
  # hduB = fits.open(prefix + "ratio-5755-6583.fits")[0]

  xmin, xmax, ymin, ymax = 0.5, 2.5, 0.02, 0.08

  m = np.isfinite(hduA.data) & np.isfinite(hduB.data)
  if 'sweet' in region.lower():
      title = 'Orion S'
      include = pyregion.open(t2dir + '/will-nii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-nii-exclude-wcs.reg')
      m = m & include.get_mask(hdu=ssiii_hdu) & (~exclude.get_mask(hdu=ssiii_hdu))
       
      include = pyregion.open(t2dir + '/will-sii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-sii-exclude-wcs.reg')
      m = m & include.get_mask(hdu=ssiii_hdu) & (~exclude.get_mask(hdu=ssiii_hdu))
  else:
      title = 'Full nebula'

  x = hduA.data[m]
  y = hduB.data[m]
  w = ssiii_hdu.data[m]
  gamma = 1.5
  fig, ax = plt.subplots(1, 1)
  H, xedges, yedges = np.histogram2d(x, y, 50,
                                     [[xmin, xmax], [ymin, ymax]],
                                     weights=w)
  ax.imshow((H.T)**(1.0/gamma), extent=[xmin, xmax, ymin, ymax],
            interpolation='nearest', aspect='auto', origin='lower', 
            cmap=plt.cm.gray_r, alpha=1.0)

  denrange = np.linspace(0.0, 8.e4, 200)
  for tem in [7.5e3, 8e3, 8.5e3, 9e3, 9.5e3, 1e4]:
      ax.plot(rcliii_T_den(tem, denrange), rsiii_T_den(tem, denrange),
              label="T = {:.0f} K".format(tem))

  temrange = np.linspace(0.0, 20000.0, 100)
  for den in [1000, 2000, 4000, 8000, 16000, 32000]:
      ax.plot(rcliii_T_den(temrange, den), rsiii_T_den(temrange, den),
              '--', label="n = {:.0f} pcc".format(den))

  ax.set_xlim(xmin, xmax)
  ax.set_ylim(ymin, ymax)
  ax.set_xlabel('[Cl III] 5538 / 5518')
  ax.set_ylabel('Dereddened [S III] 6300 / 9069')
  ax.grid()
  ax.legend(ncol=2, fontsize='x-small', handlelength=2.2, numpoints=1)

  fig.set_size_inches(7, 7)
  pltfile = 'muse-rsiii-rcliii-histogram-{}{}.pdf'.format(region, suffix)


  fig.savefig(pltfile)
  print(pltfile)

#+END_SRC

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py sweet bin001
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-sweet-bin001.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin001
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin001.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin004
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin004.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin016
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin016.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin064
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin064.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin256
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin256.pdf]]



#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py sweet bin016
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-sweet-bin016.pdf]]

** DONE Look at extinction curve in more detail
CLOSED: [2015-10-24 Sat 15:02]
+ We have the following extinction-sensitive ratios
  + Balmer decrement Hb 4861/Ha 6563
  + Balmer-Paschen decrement Ha 6563/Pa-9 9229
  + Decrements within the Pa series
    + 8545/9229
    + 8598/9229
    + 8750/9229 - contaminated with something high ionization
    + 8863/9229
    + 9015/9229 - contaminated with blueshifted something else
+ [ ] Why did we miss out 8665
+ There is broad agreement of all ratios in the main extinction features: dark bay plus sw cloud
+ But there are some interesting differences, some discussed [[id:236AC762-7034-42E9-83BC-754A68346A23][above]]
  + More relevant here is that over in the far NE, where we should be in the Dark Bay, the apparent extinction measured by the non-contaminated inter-Paschen ratios (8545/9229, 8598/9229, 8863/9229) all show /low/ extinction
  + This may be due to a foreground emission component, with low extinction
    + This makes a relatively larger contribution to the higher Pa lines
    + But why is the same effect not seen in 6563/9229?
+ Since we have 3 Pa ratios, we can fit pixel-by-pixel for:
  1. Magnitud of extinction
  2. Slope of extinction
  3. Foreground contamination
+ But we would probably best off making (3) fixed at least, and maybe (2) too
*** Pyneb calculations of the intrinsic Balmer and Paschen decrements
+ Based on Balmer decrement calculation I did [[id:6FCC69BB-E453-4B3F-A9F6-DC6A1203542F][here]]
+ So none of these vary much unless T < 4000 K
+ Previously we had taken 1/2.874 = 0.3479 for Hb/Ha, which applies for T = 1e4 K over a large range of n
+ It looks like we should use an 6563/9229 intrinsic ratio of 113.0
#+BEGIN_SRC python :tangle intrinsic-H-line-ratios.py
  import numpy as np
  from matplotlib import pyplot as plt
  import pyneb
  h1 = pyneb.RecAtom('H', 1)
  tems = [2000, 4000, 8000, 12000, 16000, 20000]
  den = np.logspace(2.0, 6.0)
  linepairs = [
      [(2, 4), (2, 3)],
      [(2, 3), (3, 9)],
      [(3, 10), (3, 9)],
      [(3, 11), (3, 9)],
      [(3, 12), (3, 9)],
      [(3, 13), (3, 9)],
      [(3, 14), (3, 9)],
      [(3, 15), (3, 9)],
      [(3, 16), (3, 9)],
      [(3, 17), (3, 9)],
  ]
  for levelsA, levelsB in linepairs:
      wavA = h1.getWave(*levelsA)
      wavB = h1.getWave(*levelsB)
      fig, ax = plt.subplots(1, 1)
      for T in tems:
          # Level order is backward for emissivity
          emA = h1.getEmissivity(T, den, *levelsA[::-1])
          emB = h1.getEmissivity(T, den, *levelsB[::-1])
          ax.plot(den, emA/emB, label='T = {:.0f} K'.format(T))
      ax.set_xscale('log')
      ax.set_xlim(den.min(), den.max())
      ax.set_ylim(0.0, None)
      ax.set_xlabel('Density, pcc')
      ax.set_ylabel('Line Ratio H({}-{})/H({}-{})'.format(*(levelsA[::-1]+levelsB[::-1])))
      ax.set_title('H I {:.2f} / {:.2f}'.format(wavA, wavB))
      ax.legend(loc='lower right', fontsize='small')
      fig.set_size_inches(7, 7)
      fig.savefig('intrinsic-ratio-H_I_{}_{}.pdf'.format(int(wavA+0.5), int(wavB+0.5)))
#+END_SRC

#+BEGIN_SRC sh :results silent
python intrinsic-H-line-ratios.py && open intrinsic-ratio-H_I_*.pdf
#+END_SRC
** DONE De-redden the [S III] ratio
CLOSED: [2015-10-25 Sun 11:42]
:PROPERTIES:
:ID:       89D30B56-E005-4846-8CD2-FBA8C008109D
:END:
+ E(lam1-lam2) = E(lam1-Hb) - E(lam2-Hb)
+ E(lam-Hb) = f(lam) A(Hb)
+ => E(lam1-lam2) = (f(lam1) - f(lam2)) A(Hb)
+ observed ratio r12 = r0 10^[-0.4 E(lam1-lam2)]
  + e.g r(6312/9069) = r0(6312/9069) 10^[-0.4 E(6312-9069)]
  + E(6312-9069) = -2.5 log(r(6312/9069) / r0(6312/9069))
  + We want to find r0(6312/9069)
+ Same for reddening diagnostic lines:
  + E(lamA-lamB) = (f(lamA) - f(lamB)) A(Hb)
  + => E(lam1-lam2) = E(lamA-lamB) (f(lam1) - f(lam2)) / (f(lamA) - f(lamB))
  + or E(lam1-lam2) = F E(lamA-lamB) where f is that ratio of f differences
  + And also E(lamA-lamB) = -2.5 log(rAB/rAB0)
+ Therefore -2.5 log(r(6312/9069) / r0(6312/9069)) = -2.5 F log(rAB/rAB0)
  + => r(6312/9069) / r0(6312/9069) = (rAB/rAB0)^F
  + => r0(6312/9069) = r(6312/9069) (rAB0/rAB)^F

#+BEGIN_SRC python :tangle deredden_siii.py
  import sys
  import numpy as np
  from astropy.io import fits

  # Blagrave extinction law interpolated on table
  # -0.138 + (6312 - 5876)*(-0.218 - (-0.138))/(6548 - 5876)
  f_6312 = -0.1899
  # -0.309 + (9069 - 7330)*(-0.507 - (-0.309))/(9229 - 7330)
  f_9069 = -0.4903
  f_6563 = -0.220
  f_9229 = -0.507

  F_siii_ha_pa9 = (f_6312 - f_9069) / (f_6563 - f_9229) # Should be 1.0467

  def deredden_siii_ratio(rsiii, rha_pa9, ha_pa9_intrinsic=113.0):
      """Uses the Blagrave reddening law"""
      return rsiii*(ha_pa9_intrinsic/rha_pa9)**F_siii_ha_pa9

  if __name__ == '__main__':
      try:
          suffix = '-' + sys.argv[1]
      except IndexError:
          suffix = ''
        
      rha_pa9 = fits.open('LineMaps/ratio-6563-9229{}.fits'.format(suffix))['SCALED'].data
      siii_hdu = fits.open('LineMaps/ratio-6312-9069{}.fits'.format(suffix))['SCALED']
      siii_hdu.data = deredden_siii_ratio(siii_hdu.data, rha_pa9)
      siii_hdu.writeto('LineMaps/ratio-6312-9069-deredden{}.fits'.format(suffix),
                      clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results verbatim
  for binning in 001 002 004 008 016 032 064 128 256; do
      python deredden_siii.py bin$binning
  done
#+END_SRC

#+RESULTS:

Do the same for first 3 fuzzed ratio maps
#+BEGIN_SRC sh :results verbatim
  for binning in 001 002 004 008 016 032 064 128 256; do
      for fuzz in 000 001 002; do
          python deredden_siii.py fuzz${fuzz}-bin$binning
      done
  done
#+END_SRC

#+RESULTS:
* Making images and figures of the maps
** STARTED fig_utils.py: Utility functions to make figures from MUSE maps
:PROPERTIES:
:ID:       DF6370DF-79C4-4B48-B862-27B74302F9A0
:END:
#+BEGIN_SRC python :tangle fig_utils.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from matplotlib import pyplot as plt
  from astropy.wcs import WCS
  # import seaborn as sns

  def fig_ax_im_from_fits(fn, vmin=None, vmax=None, cmap=plt.cm.gray):
      '''Make a basic grayscale plot of a FITS file'''
      #sns.set_style("white")

      # Try first HDU
      hdu = fits.open(fn)[0]
      if hdu.data is None:
          # Or failing that, 2nd HDU
          hdu = fits.open(fn)[1]
      wcs = WCS(hdu.header)
      fig = plt.figure()
      ax = fig.add_axes([0.18, 0.1, 0.8, 0.8], projection=wcs)
      tr = ax.get_transform(wcs)
      ra, dec = ax.coords
      dec.set_major_formatter('dd:mm:ss.s')
      ra.set_major_formatter('hh:mm:ss.ss')
      if vmax is None:
          vmax = hdu.data.max()
      if vmin is None:
          vmin = 0.0
      im = ax.imshow(hdu.data, vmin=vmin, vmax=vmax, cmap=cmap,
                     origin='lower', interpolation='nearest')
      plt.colorbar(im)
      ax.coords.grid(color='red', alpha=0.2, lw=0.2, linestyle='solid')
      ax.set_xlabel('RA, J2000')
      ax.set_ylabel('Dec, J2000')
      ax.set_title(fn, fontsize='small')
  
      return fig, ax, im


  if __name__ == '__main__':
      try:
          fn = 'LineMaps/' + sys.argv[1] + '.fits'
      except IndexError:
          fn = 'LineMaps/linesum-Fe_III-4658-multibin-SN0010.fits'

      try:
          vmin, vmax = float(sys.argv[2]), float(sys.argv[3])
      except IndexError:
          vmin, vmax = None, None
          
      fig, ax, im = fig_ax_im_from_fits(fn, vmin, vmax)
      figfile = fn.replace('.fits', '.jpg')
      fig.set_size_inches(8, 6)
      fig.savefig(figfile, dpi=200)
      print(figfile, end='')
#+END_SRC

#+RESULTS:


#+BEGIN_SRC sh :results output file
python fig_utils.py
#+END_SRC

#+RESULTS:

** Make a whole load of figures
#+BEGIN_SRC python :tangle figs-multibin-Te-Ne.py
  import os
  from fig_utils import fig_ax_im_from_fits
  import matplotlib.pyplot as plt

  quantities = {
      'muse-derived-Te': (6500, 14000),
      'muse-derived-Te-iii': (6500, 14000),
      'muse-derived-Ne': (0.0, 2.0e4),
      'muse-derived-Ne-iii': (0.0, 2.0e4),
  }

  datadir = "/Volumes/SSD-1TB/OrionMuse/LineMaps"

  for SN in 3, 10, 30, 100, 300:
      for quant, (vmin, vmax) in quantities.items():
          fn = (f'{datadir}/{quant}-multibin-SN{SN:04d}.fits')
          try:
              fig, ax, im = fig_ax_im_from_fits(fn, vmin=vmin, vmax=vmax, cmap=plt.cm.gray_r)
          except IOError:
              continue
          figfile = os.path.basename(fn).replace('.fits', '.pdf')
          fig.set_size_inches(8, 6)
          fig.savefig(figfile, dpi=200)
  
#+END_SRC


#+BEGIN_SRC sh
time python figs-multibin-Te-Ne.py
#+END_SRC

#+RESULTS:

** [2019-06-21 Fri] Do the figures at each bin level too

#+BEGIN_SRC python :tangle figs-binned-Te-Ne.py
  import os
  from fig_utils import fig_ax_im_from_fits
  import matplotlib.pyplot as plt


  quantities = {
      'muse-derived-Te': (6500, 14000),
      'muse-derived-Te-iii': (6500, 14000),
      'muse-derived-Ne': (0.0, 2.0e4),
      'muse-derived-Ne-iii': (0.0, 2.0e4),
  }

  datadir = "/Volumes/SSD-1TB/OrionMuse/LineMaps"

  for nbin in 1, 2, 4, 8, 16, 32, 64:
      for quant, (vmin, vmax) in quantities.items():
          fn = (f'{datadir}/{quant}-bin{nbin:03d}.fits')
          try:
              fig, ax, im = fig_ax_im_from_fits(fn, vmin=vmin, vmax=vmax, cmap=plt.cm.gray_r)
          except IOError:
              continue
          figfile = os.path.basename(fn).replace('.fits', '.pdf')
          fig.set_size_inches(8, 6)
          fig.savefig(figfile)

#+END_SRC


#+BEGIN_SRC sh
time python figs-binned-Te-Ne.py
#+END_SRC

#+RESULTS:


*** Absorption lines

Mystery 6634 line 
#+BEGIN_SRC sh :results file
python fig_utils.py ew-N_III-6634-multibin-SN0007 -0.5 0.0
#+END_SRC

#+RESULTS:

He II 4886 line
#+BEGIN_SRC sh :results file
python fig_utils.py ew-He_II-4686-multibin-SN0007 -0.5 0.0
#+END_SRC

#+RESULTS:
[[file:LineMaps/ew-He_II-4686-multibin-SN0007.jpg]]

He II 5785 line
#+BEGIN_SRC sh :results file
python fig_utils.py ew-He_II-5785-multibin-SN0007 -0.5 0.0
#+END_SRC

#+RESULTS:
[[file:LineMaps/ew-He_II-5785-multibin-SN0007.jpg]]


C IV 5812 line
#+BEGIN_SRC sh :results export file
python fig_utils.py ew-C_IV-5812-multibin-SN0005 -0.2 0.0
#+END_SRC

#+RESULTS:
[[file:LineMaps/ew-C_IV-5812-multibin-SN0005.jpg]]


Si III 6663 line
#+BEGIN_SRC sh :results export file
python fig_utils.py ew-Si_III-6663-multibin-SN0005 -0.2 0.0
#+END_SRC

#+RESULTS:
[[file:LineMaps/ew-Si_III-6663-multibin-SN0005.jpg]]

#+BEGIN_SRC sh :results export file
python fig_utils.py linesum-Si_III-6663-bin064 -400 200.0
#+END_SRC

#+RESULTS:
[[file:LineMaps/linesum-Si_III-6663-bin064.jpg]]

So-called diffuse interstellar band
#+BEGIN_SRC sh :results export file
python fig_utils.py linesum-DIB-5781-multibin-SN0005 -1000 0.0
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh
for f in LineMaps/linesum-DIB-5781-bin*.fits; do
    python muse-ew.py $f
done
#+END_SRC

#+RESULTS:


N III 5896 line
#+BEGIN_SRC sh :results file
python fig_utils.py ratio-7236-6563-multibin-SN0030 2.2e-4 2.2e-3
#+END_SRC

#+RESULTS:
[[file:LineMaps/ratio-7236-6563-multibin-SN0030.jpg]]




* TODO Multi-resolution MUSE line maps
:PROPERTIES:
:ID:       3D36AC7E-5321-420E-B0A4-29EC2068083D
:END:
+ This is stolen from a [[id:EAE1FA1C-7D1B-484D-9B4A-FF42DE7D8594][similar program for the Alba project]]
+ The difference is that we are starting from a simple image, not from a superposition of slits
+ Extra inspiration (e.g., star mask) is taken from [[id:B8D31952-3114-4FE8-B2D7-A0CC32287FA2][here]]
+ We need to run these on my laptop in order to use the rebinning on the iMac, since it doesn't have access to the =~/Work/RubinWFC3/Tsquared/= folder
  + src_sh{cp /Users/will/Work/RubinWFC3/Tsquared/rebin_utils.py .}
  + src_sh{cp /Users/will/Work/RubinWFC3/Tsquared/derive_ne_te_1phase.py .} 
  + src_sh{cp /Users/will/Work/RubinWFC3/Tsquared/pyneb_utils.py .}  
  + src_sh{cp /Users/will/Work/RubinWFC3/Tsquared/deredden.py .}   
  + src_sh{cp /Users/will/Work/RubinWFC3/Tsquared/will-*.reg .}
+ [2015-10-31 Sat] Removed the =hdu.data > 0= condition on the mask since I suspect it is causing upward bias on brightness with increased binning
+ [2015-11-03 Tue] Do some padding on the data array to multiple of 256 so that all the binned maps are the same size
+ [2015-11-04 Wed] Combine multiple binning levels at constant s/n level




** multibin-map.py - Perform binning of a line map
:PROPERTIES:
:ID:       D49AD965-AFDC-4D58-9341-8202DD8508D3
:END:
This has now been moved to its [[id:D2B1D238-7058-406B-93FD-60AD6BACA97A][own project]]


*** Shell scripts to do multibinning of observed and fuzzed maps
:PROPERTIES:
:ID:       8E91B82E-9A07-4DE7-8EDC-5157FB5EEA99
:END:
Do them all
#+BEGIN_SRC sh :tangle all-lines-multibin.sh
linelist=LineMaps/linesum-*-[0-9][0-9][0-9][0-9].fits
D=../multibin-maps
for line in $linelist; do
    echo "Processing $line"
    time python $D/multibin-map.py $line > ${line}-multibin.log 2>&1
done
#+END_SRC

#+BEGIN_SRC sh :tangle all-continuum-multibin.sh
linelist=LineMaps/continuum-*-[0-9][0-9][0-9][0-9].fits
D=../multibin-maps
for line in $linelist; do
    echo "Processing $line"
    time python $D/multibin-map.py $line > ${line}-multibin.log 2>&1
done
#+END_SRC

#+RESULTS:
#+begin_example
Processing LineMaps/linesum-Ar_III-5192.fits
Processing LineMaps/linesum-Ar_III-7136.fits
Processing LineMaps/linesum-Ar_III-7751.fits
Processing LineMaps/linesum-C_I-8727.fits
Processing LineMaps/linesum-C_II-5890.fits
Processing LineMaps/linesum-C_II-6578.fits
Processing LineMaps/linesum-Ca_I-9052.fits
Processing LineMaps/linesum-Ca_I-9095.fits
Processing LineMaps/linesum-Cl_II-8579.fits
Processing LineMaps/linesum-Cl_III-5518.fits
Processing LineMaps/linesum-Cl_III-5538.fits
Processing LineMaps/linesum-Cl_IV-8046.fits
Processing LineMaps/linesum-Fe_II-5262.fits
Processing LineMaps/linesum-Fe_II-6133.fits
Processing LineMaps/linesum-Fe_II-7453.fits
Processing LineMaps/linesum-Fe_II-8617.fits
Processing LineMaps/linesum-Fe_III-4658.fits
Processing LineMaps/linesum-Fe_III-4702.fits
Processing LineMaps/linesum-Fe_III-5270.fits
Processing LineMaps/linesum-H_I-4861.fits
Processing LineMaps/linesum-H_I-6563.fits
Processing LineMaps/linesum-H_I-8438.fits
Processing LineMaps/linesum-H_I-8467.fits
Processing LineMaps/linesum-H_I-8502.fits
Processing LineMaps/linesum-H_I-8545.fits
Processing LineMaps/linesum-H_I-8598.fits
Processing LineMaps/linesum-H_I-8665.fits
Processing LineMaps/linesum-H_I-8750.fits
Processing LineMaps/linesum-H_I-8863.fits
Processing LineMaps/linesum-H_I-9015.fits
Processing LineMaps/linesum-H_I-9229.fits
Processing LineMaps/linesum-He_I-5016.fits
Processing LineMaps/linesum-He_I-5048.fits
Processing LineMaps/linesum-He_I-5876.fits
Processing LineMaps/linesum-He_I-6678.fits
Processing LineMaps/linesum-He_I-7065.fits
Processing LineMaps/linesum-N_I-5199.fits
Processing LineMaps/linesum-N_I-8680.fits
Processing LineMaps/linesum-N_II-5755.fits
Processing LineMaps/linesum-N_II-5932.fits
Processing LineMaps/linesum-N_II-5942.fits
Processing LineMaps/linesum-N_II-5952.fits
Processing LineMaps/linesum-N_II-6548.fits
Processing LineMaps/linesum-N_II-6583.fits
Processing LineMaps/linesum-O_I-5577.fits
Processing LineMaps/linesum-O_I-6046.fits
Processing LineMaps/linesum-O_I-6300.fits
Processing LineMaps/linesum-O_I-6364.fits
Processing LineMaps/linesum-O_I-7002.fits
Processing LineMaps/linesum-O_I-8446.fits
Processing LineMaps/linesum-O_II-4650.fits
Processing LineMaps/linesum-O_II-7318.fits
Processing LineMaps/linesum-O_II-7330.fits
Processing LineMaps/linesum-O_III-4959.fits
Processing LineMaps/linesum-O_III-5007.fits
Processing LineMaps/linesum-S_II-6716.fits
Processing LineMaps/linesum-S_II-6731.fits
Processing LineMaps/linesum-S_III-6312.fits
Processing LineMaps/linesum-S_III-9069.fits
Processing LineMaps/linesum-Si_II-5041.fits
Processing LineMaps/linesum-Si_II-5056.fits
Processing LineMaps/linesum-Si_II-5958.fits
Processing LineMaps/linesum-Si_II-5979.fits
Processing LineMaps/linesum-Si_II-6347.fits
Processing LineMaps/linesum-Si_II-6371.fits
#+end_example

+ And do the fuzzed ones too (this takes ages, so run it in an interactive shell)
+ [2015-11-08 Sun] This does not have to be so careful now, since it will only rebuild files where needed
+ [ ] Actually it is still very slow, mainly because it takes over a second to start the python process and load libraries
  + So I should re-write it to do the globbing in python instead of shell script
  + That way, it only needs to start python once, so it will be much quicker
#+BEGIN_SRC sh :eval no :tangle all-fuzz-multibin.sh
linelist=LineMaps/linesum-*[0-9][0-9][0-9][0-9]-fuzz$1.fits
for line in $linelist; do
    echo "Processing $line"
    time python multibin-map.py $line > ${line}-multibin.log 2>&1
done
#+END_SRC

Usage example

#+BEGIN_SRC sh :eval no
nohup sh all-fuzz-multibin.sh 000 > all-fuzz-000-multibin.log &
nohup sh all-fuzz-multibin.sh 001 > all-fuzz-001-multibin.log &
nohup sh all-fuzz-multibin.sh 002 > all-fuzz-002-multibin.log &
nohup sh all-fuzz-multibin.sh 003 > all-fuzz-003-multibin.log &
nohup sh all-fuzz-multibin.sh 004 > all-fuzz-004-multibin.log &
nohup sh all-fuzz-multibin.sh 005 > all-fuzz-005-multibin.log &
nohup sh all-fuzz-multibin.sh 006 > all-fuzz-006-multibin.log &
nohup sh all-fuzz-multibin.sh 007 > all-fuzz-007-multibin.log &
nohup sh all-fuzz-multibin.sh 008 > all-fuzz-008-multibin.log &
nohup sh all-fuzz-multibin.sh 009 > all-fuzz-009-multibin.log &
#+END_SRC

Note that I have now put it up to 10 fuzzes again to improve the noise estimates

And slice things the other way - this does all fuzzes for a single line
#+BEGIN_SRC sh :eval no :tangle one-line-fuzz-multibin.sh
linelist=LineMaps/linesum-$1-fuzz???.fits
for line in $linelist; do
    echo "Processing $line"
    time python multibin-map.py $line
done
#+END_SRC




** Dealing with the pattern noise in the velocity maps
+ [2016-12-18 Sun] This has now been spun out to its own project
+ See [[file:~/Dropbox/depattern-maps/depattern.org]]
** Combining multibinned maps to give constant s/n ratio
+ [2015-11-05 Thu] Planned improvements
  + [X] Create maps of s/n for each binning. Perhaps smooth it before doing the multi bin combine step.
  + [X] Be more aggressive with the dilations. Make the kernel be the size of the big pixels. Maybe don't do the dilation.
  + [-] Do more realizations of the fuzzing to improve the estimates of the s-n-r.
+ [2015-11-05 Thu] This is now split into three stages for greater control
  1. First [[id:DED61F19-3303-4D94-BB1C-12B4BC789D65][make maps]] of signal-to-noise ratio for each binning with [[file:multibin-signal-to-noise.py]]
  2. Then [[id:95C0D60F-5553-40F1-A3B4-57517D4C5512][create masks]] at a given S/N with [[file:multibin-mask-s-n.py]]. At this stage we can finesse the masks with erosion/dilation to avoid single-pixel islands at any binning level (at least for the smaller binnings)
  3. Finally [[id:CFEF861F-1888-435B-B2F0-B6C80AAD1448][combine all the binning levels]] by stacking the brightness maps while applying the minimum s/n masks with [[file:multibin-combine-s-n.py]]
*** multibin-signal-to-noise.py - Write maps of s/n estimated from fuzzing
:PROPERTIES:
:ID:       DED61F19-3303-4D94-BB1C-12B4BC789D65
:END:
+ We estimate s/n by using the fuzzed line maps
+ Note that we do /not/ calculate std_{i}(Fuzzed_{i} - Observed), which would be no different from std_{i}(Fuzzed_{i}) since Observed is a constant, so it will be small if all the Fuzzed_{i} are close to one another even if they are all far from Observed - not good!
+ Instead we calculate rms_{i}(Fuzzed_{i} - Observed)
+ Also, we want the s/n to be always positive, even for an absorption line, so we take the absolute value of the map data
+ [2015-11-06 Fri] Also write out the noise, since this may come in useful later

#+BEGIN_SRC python :tangle multibin-signal-to-noise.py 
  from __future__ import print_function
  import sys
  import glob
  from distutils.dep_util import newer, newer_group
  import numpy as np
  from astropy.io import fits
  try: 
      fileroot = sys.argv[1]
  except IndexError:
      sys.exit('Usage: {} FILEROOT')

  prefix = 'LineMaps/'
  nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]
  for n in reversed(nlist):
      fn = prefix + '{}-bin{:03d}.fits'.format(fileroot, n)
      out_fn = fn.replace('-bin', '-SN-bin')
      if not newer(fn, out_fn):
          print(out_fn, 'already up to date - skipping')
          continue
      hdu = fits.open(fn)['SCALED']
      hdr = hdu.header
      fuzz_pattern = fn.replace('-bin', '-fuzz???-bin')
      fuzz_files = glob.glob(fuzz_pattern)
      if len(fuzz_files) == 0:
          sys.exit('No fuzzed files found. '
                   'Try running extract-em-line-fuzz.py and all-fuzz-multibin.sh ')
      hdr['NFUZZ'] = len(fuzz_files), 'Number of fuzzed images used to estimate noise'
      fuzz_deltas = []
      for fuzz_fn in fuzz_files:
          fuzz_hdu = fits.open(fuzz_fn)['SCALED']
          fuzz_deltas.append(fuzz_hdu.data - hdu.data)
      fuzz_std = np.sqrt(np.mean(np.square(np.dstack(fuzz_deltas)), axis=-1))
      signal_to_noise = np.abs(hdu.data)/fuzz_std
      # Write out signal/noise
      fits.PrimaryHDU(header=hdr, data=signal_to_noise).writeto(out_fn, clobber=True)
      # Write out noise too
      out_fn = fn.replace('-bin', '-STD-bin')
      fits.PrimaryHDU(header=hdr, data=fuzz_std).writeto(out_fn, clobber=True)

#+END_SRC

#+BEGIN_SRC sh
source activate py27
python multibin-signal-to-noise.py ew-N_III-6634
#+END_SRC

#+RESULTS:

**** Script to run on the server for s/n of all the lines
+ [2015-11-06 Fri] This was tricky to get the glob pattern matching right
+ The naive approach with =*= was catching things like =linesum-N_III-6634-multibin-SN0005=, which we didn't want
+ This is since the S/N ratio is also 4 digits (as well as the line wavelength)
+ I solved it by setting the =extglob= shell option and using the extended pattern matching operators: =+(PATTERN)= matches one or more instances of =PATTERN=
#+BEGIN_SRC sh :eval no :tangle all-signal-to-noise.sh
shopt -s extglob
files=LineMaps/linesum-+([^-])-[0-9][0-9][0-9][0-9].fits
for file in $files; do
    prefix=$(basename $file .fits)
    echo "Calculating S/N for $prefix"
    python multibin-signal-to-noise.py $prefix
done
#+END_SRC


**** And another script to do s/n of all the ratios
#+BEGIN_SRC sh :eval no :tangle all-ratios-signal-to-noise.sh
files=LineMaps/ratio-[0-9][0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]-bin001.fits
for file in $files; do
    prefix=$(basename $file -bin001.fits)
    echo "Calculating S/N for $prefix"
    python multibin-signal-to-noise.py $prefix
done
#+END_SRC


*** multibin-mask-s-n.py - create masks at roughly constant s/n 
:PROPERTIES:
:ID:       95C0D60F-5553-40F1-A3B4-57517D4C5512
:END:
+ We pass each mask through a erosion/dilation so that we don't have single-pixel islands 
+ Instead of morphology.erosion we are trying filters.rank.modal, which takes the most common value in the neighborhood around each pixel - we use a 3x3 square as the selection element
#+BEGIN_SRC python :tangle multibin-mask-s-n.py
  from __future__ import print_function
  import sys
  import glob
  from distutils.dep_util import newer, newer_group
  import numpy as np
  from skimage.morphology import binary_dilation, binary_erosion, square, diamond
  from skimage.filters.rank import modal
  from astropy.io import fits
  from rebin_utils import oversample

  def minify(a, n):
      return a[::n, ::n]

  try: 
      fileroot = sys.argv[1]
      target_signal_to_noise = int(sys.argv[2])
  except IndexError:
      sys.exit('Usage: {} FILEROOT S/N')

  prefix = 'LineMaps/'
  nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]
  # selection element for filtering out isolated pixels
  element = square(3)
  for n in reversed(nlist):
      fn = prefix + '{}-SN-bin{:03d}.fits'.format(fileroot, n)
      out_fn = fn.replace('SN', 'mask-SN{:04d}'.format(target_signal_to_noise))
      if not newer(fn, out_fn):
          print(out_fn, 'already up to date - skipping')
          continue
      print('Extracting mask from', fn)
      try:
          hdu = fits.open(fn)['SCALED']
      except IOError:
          sys.exit(fn + ' not found. Try running multibin-signal-to-noise.py first.')
      hdr = hdu.header
      signal_to_noise = hdu.data
      mask = signal_to_noise >= target_signal_to_noise
      # Shrink down to its true size at the binning we are at
      mask = minify(mask, n).astype(np.uint8)
      # Eliminate small islands
      mask = mask & modal(mask, element)
      # mask = binary_erosion(mask, element)
      # expand borders slightly
      # mask = binary_dilation(mask, element)

      # Expand back to the size of the full-res image
      mask = oversample(mask, n).astype(np.uint8)
      # Save to FITS file
      fits.PrimaryHDU(header=hdr, data=mask).writeto(out_fn, clobber=True)


#+END_SRC


#+BEGIN_SRC sh :results verbatim
source activate py27
python multibin-mask-s-n.py ew-O_III-5592 5
#+END_SRC

#+RESULTS:
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin256.fits
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin128.fits
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin064.fits
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin032.fits
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin016.fits
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin008.fits
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin004.fits
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin002.fits
: Extracting mask from LineMaps/ew-O_III-5592-SN-bin001.fits


*** multibin-combine-s-n.py - combine multiple binning levels for constant s/n
:PROPERTIES:
:ID:       CFEF861F-1888-435B-B2F0-B6C80AAD1448
:END:
+ [2015-11-05 Thu] Whether or not to mask out the negative map pixels is problematic
  + On the one hand it seemed to improve things with the [Fe III] lines
  + But it obviously does not work for absorption lines
  + [ ] So I have currently disabled it, but I need to do something cleverer
#+BEGIN_SRC python :tangle multibin-combine-s-n.py
  from __future__ import print_function
  import sys
  import glob
  import numpy as np
  from skimage.morphology import erosion, dilation
  from astropy.io import fits
  try: 
      fileroot = sys.argv[1]
      target_signal_to_noise = int(sys.argv[2])
  except IndexError:
      sys.exit('Usage: {} FILEROOT S/N')

  prefix = 'LineMaps/'
  snlabel = 'SN{:04d}'.format(target_signal_to_noise)
  outim = None
  nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]
  for n in reversed(nlist):
      # Read in data
      fn = prefix + '{}-bin{:03d}.fits'.format(fileroot, n)
      hdu = fits.open(fn)['SCALED']
      # Read in s/n too
      sn_hdu = fits.open(fn.replace('-bin', '-SN-bin'))['SCALED']
      if outim is None:
          # One-time setup to do on first iteration
          hdr = hdu.header
          # set up image for output
          outim = np.empty_like(hdu.data)
          # and for s/n achieved
          out_sn = np.empty_like(hdu.data)

      # Read in mask
      mfn = fn.replace('-bin', '-mask-{}-bin'.format(snlabel))
      try:
          mask = fits.open(mfn)['SCALED'].data.astype(np.bool)
      except IOError:
          sys.exit(mfn + ' not found. Try running multibin-mask-s-n.py first.')
      # mask = mask & (hdu.data > 0.0)

      # Paste into image and into saved s/n
      outim[mask] = hdu.data[mask]
      out_sn[mask] = sn_hdu.data[mask]

  out_fn = '{}{}-multibin-{}.fits'.format(prefix, fileroot, snlabel)
  fits.PrimaryHDU(header=hdr, data=outim).writeto(out_fn, clobber=True)
  fits.PrimaryHDU(header=hdr, data=out_sn).writeto(
      out_fn.replace('.fits', '-SN.fits'), clobber=True)

#+END_SRC

The fuzzed files need to have been created first using [[file:all-fuzz-multibin.sh]] (see above)

#+BEGIN_SRC sh
source activate py27
python multibin-combine-s-n.py ew-O_III-5592 5
#+END_SRC

#+RESULTS:

*** Create all the combined images on the server
:PROPERTIES:
:ID:       92671F18-9117-4B7E-8315-8C74DC4FF786
:END:

+ Give target S/N as command-line argument to shell script 
+ Skips lines where the SN file does not exist
#+BEGIN_SRC sh :eval no :tangle all-combine-s-n.sh
  shopt -s extglob
  SN=$1
  TYPE=${2:linesum}
  files=LineMaps/${TYPE}-+([^-])-[0-9][0-9][0-9][0-9].fits
  for file in $files; do
      prefix=$(basename $file .fits)
      if [ -f LineMaps/${prefix}-SN-bin256.fits ]; then
          echo "+++ Calculating S/N masks for $prefix at S/N = $SN"
          python multibin-mask-s-n.py $prefix $SN
          echo "+++ Calculating combined image for $prefix at S/N = $SN"
          python multibin-combine-s-n.py $prefix $SN
          echo "+++"
      fi
  done
#+END_SRC

And the same for ratios:
#+BEGIN_SRC sh :eval no :tangle all-ratios-combine-s-n.sh
  SN=$1
  files=LineMaps/ratio-[0-9][0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]-bin001.fits
  for file in $files; do
      prefix=$(basename $file -bin001.fits)
      if [ -f LineMaps/${prefix}-SN-bin256.fits ]; then
          echo "+++ Calculating S/N masks for $prefix at S/N = $SN"
          python multibin-mask-s-n.py $prefix $SN
          echo "+++ Calculating combined image for $prefix at S/N = $SN"
          python multibin-combine-s-n.py $prefix $SN
          echo "+++"
      fi
  done
#+END_SRC

** Ratio of multibin maps
:PROPERTIES:
:ID:       125BB238-D032-4FAD-B6DA-FBFB14DAD3AF
:END:
#+name: ratio-pairs
+ N_II-5755;N_II-6583
+ S_III-6312;S_III-9069
+ Cl_III-5538;Cl_III-5518
+ S_II-6716;S_II-6731
+ H_I-6563;H_I-4861
+ H_I-4861;H_I-6563
+ H_I-6563;H_I-9229
+ H_I-8545;H_I-9229
+ H_I-8598;H_I-9229
+ H_I-8750;H_I-9229
+ H_I-8863;H_I-9229
+ H_I-9015;H_I-9229
+ O_II-7318;O_II-7330
+ He_I-5876;He_I-6678
+ Ar_III-7136;Ar_III-7751
+ O_I-7002;O_I-8446
+ Fe_III-4658;H_I-4861

What a palaver it is to deal with array variables in bash
#+name: ratio-multibin
#+BEGIN_SRC sh :var list=ratio-pairs :results verbatim
for pair in $list; do
    arr_pair=(${pair//;/ })
    echo ${arr_pair[0]} ${arr_pair[1]} 
    for binning in 001 002 004 008 016 032 064 128 256; do
        python muse_line_ratio.py ${arr_pair[0]} ${arr_pair[1]} linesum bin$binning > /dev/null
    done
done
#+END_SRC

#+RESULTS: ratio-multibin
#+begin_example
N_II-5755 N_II-6583
S_III-6312 S_III-9069
Cl_III-5538 Cl_III-5518
S_II-6716 S_II-6731
H_I-6563 H_I-4861
H_I-4861 H_I-6563
H_I-6563 H_I-9229
H_I-8545 H_I-9229
H_I-8598 H_I-9229
H_I-8750 H_I-9229
H_I-8863 H_I-9229
H_I-9015 H_I-9229
O_II-7318 O_II-7330
He_I-5876 He_I-6678
Ar_III-7136 Ar_III-7751
O_I-7002 O_I-8446
Fe_III-4658 H_I-4861
#+end_example

#+name: more-ratio-pairs
+ O_I-6300;O_I-8446
+ O_I-6300;O_II-7318
+ O_III-5007;O_II-7318
+ O_I-8446;O_II-7318
+ O_I-8446;H_I-8545
+ Ar_III-5192;Ar_III-7136 
+ Ar_III-7751;Ar_III-7136
+ Fe_III-4702;Fe_III-4658 
+ Fe_III-5270;Fe_III-4658 
+ O_III-5007;O_III-4959
+ N_II-6583;N_II-6548

#+call: ratio-multibin[:results output verbatim](list=more-ratio-pairs)

#+RESULTS:
#+begin_example
O_I-6300 O_I-8446
O_I-6300 O_II-7318
O_III-5007 O_II-7318
O_I-8446 O_II-7318
O_I-8446 H_I-8545
Ar_III-5192 Ar_III-7136
Ar_III-7751 Ar_III-7136
Fe_III-4702 Fe_III-4658
Fe_III-5270 Fe_III-4658
O_III-5007 O_III-4959
N_II-6583 N_II-6548
#+end_example

#+name: yet-more-ratio-pairs
+ O_I-6364;O_I-6300
+ N_I-5199;O_I-8446
+ N_I-5199;O_I-7002
#+call: ratio-multibin[:results output verbatim](list=yet-more-ratio-pairs)

#+RESULTS:
: O_I-6364 O_I-6300
: N_I-5199 O_I-8446
: N_I-5199 O_I-7002



#+BEGIN_SRC sh :results verbatim
for binning in 001 002 004 008 016 032 064 128 256; do
    python muse_line_ratio.py N_II-5755 N_II-6583 linesum bin$binning 
done
#+END_SRC

#+RESULTS:
: LineMaps/linesum-N_II-5755-bin001.fits LineMaps/linesum-N_II-6583-bin001.fits
: LineMaps/linesum-N_II-5755-bin002.fits LineMaps/linesum-N_II-6583-bin002.fits
: LineMaps/linesum-N_II-5755-bin004.fits LineMaps/linesum-N_II-6583-bin004.fits
: LineMaps/linesum-N_II-5755-bin008.fits LineMaps/linesum-N_II-6583-bin008.fits
: LineMaps/linesum-N_II-5755-bin016.fits LineMaps/linesum-N_II-6583-bin016.fits
: LineMaps/linesum-N_II-5755-bin032.fits LineMaps/linesum-N_II-6583-bin032.fits
: LineMaps/linesum-N_II-5755-bin064.fits LineMaps/linesum-N_II-6583-bin064.fits
: LineMaps/linesum-N_II-5755-bin128.fits LineMaps/linesum-N_II-6583-bin128.fits
: LineMaps/linesum-N_II-5755-bin256.fits LineMaps/linesum-N_II-6583-bin256.fits
** Ratio of multibin fuzzed maps
:PROPERTIES:
:ID:       55C78FE2-2D64-4EE3-9222-FA65A68FC55A
:END:
#+name: ratio-pairs-fuzz
+ N_II-5755;N_II-6583
+ S_III-6312;S_III-9069
+ Ar_III-5192;Ar_III-7751
+ Cl_III-5538;Cl_III-5518
+ S_II-6716;S_II-6731
+ H_I-4861;H_I-6563
+ H_I-6563;H_I-9229
+ O_III-5007;O_III-4959
+ N_II-6583;N_II-6548
+ Fe_III-4702;Fe_III-4658
+ Cl_IV-8046;Cl_III-5538
+ Ar_III-7136;Ar_III-7751

To start off with, we will just do three fuzzes

#+name: ratio-multibin-fuzz
#+BEGIN_SRC sh :var list=ratio-pairs-fuzz :results verbatim
  for pair in $list; do
      arr_pair=(${pair//;/ })
      echo ${arr_pair[0]} ${arr_pair[1]} 
      for binning in 001 002 004 008 016 032 064 128 256; do
          for fuzz in 000 001 002; do
              python muse_line_ratio.py ${arr_pair[0]} ${arr_pair[1]} linesum fuzz${fuzz}-bin$binning > /dev/null
          done
      done
  done
#+END_SRC

#+RESULTS: ratio-multibin-fuzz
#+begin_example
N_II-5755 N_II-6583
S_III-6312 S_III-9069
Ar_III-5192 Ar_III-7751
Cl_III-5538 Cl_III-5518
S_II-6716 S_II-6731
H_I-4861 H_I-6563
H_I-6563 H_I-9229
O_III-5007 O_III-4959
N_II-6583 N_II-6548
Fe_III-4702 Fe_III-4658
Cl_IV-8046 Cl_III-5538
Ar_III-7136 Ar_III-7751
#+end_example

#+name: ratio-pairs-fuzz-extras

#+call: ratio-multibin-fuzz(list=ratio-pairs-fuzz-extras)

#+RESULTS:
: Ar_III-7136 Ar_III-7751
** Rewrite of multibin and fuzzed ratios
:PROPERTIES:
:ID:       07D1CD25-8319-4634-904D-A3A4CBC10E8D
:END:
+ What I had previously is a bit of a mess
+ I want to make a table of all the ratios
  + Write to a TSV file
+ And have a python script that does them all, instead of the shell scripts
*** List of ratios: line-ratio-list.tab
:PROPERTIES:
:TABLE_EXPORT_FILE: line-ratio-list.tab
:TABLE_EXPORT_FORMAT: orgtbl-to-tsv
:ID:       026A1878-E6AC-4E5B-8180-AEE71DC9C829
:END:
+ Export with =C-c t e= after editing
+ The =Group= column is to allow selecting certain subsets of the ratios for recalculation as needed

#+name: line-ratio-list
| Group       | Numerator   | Denominator | Comment                            |
|-------------+-------------+-------------+------------------------------------|
| Basic       | S_III-6312  | S_III-9069  | [S III] T sensitive                |
| Basic       | Cl_III-5538 | Cl_III-5518 | [Cl III] N sensitive               |
| Basic       | N_II-5755   | N_II-6583   | [N II] T sensitive                 |
| Basic       | S_II-6716   | S_II-6731   | [S II] N sensitive                 |
| Basic       | H_I-4861    | H_I-6563    | Reddening Balmer decrement         |
|-------------+-------------+-------------+------------------------------------|
| Extra-N-T   | Ar_III-5192 | Ar_III-7751 | [Ar III] T sensitive               |
| Extra-N-T   | Fe_III-4702 | Fe_III-4658 | [Fe III] N sensitive               |
|-------------+-------------+-------------+------------------------------------|
| Paschen     | H_I-6563    | H_I-9229    | Reddening Paschen-Balmer           |
| Paschen     | H_I-8545    | H_I-9229    | Reddening Paschen decrement        |
| Paschen     | H_I-8750    | H_I-9229    | Reddening Paschen decrement        |
| Paschen     | H_I-8863    | H_I-9229    | Reddening Paschen decrement        |
|-------------+-------------+-------------+------------------------------------|
| Doublet     | N_II-6548   | N_II-6583   | [N II] sanity check                |
| Doublet     | O_III-4959  | O_III-5007  | [O III] sanity/reddening           |
| Doublet     | O_II-7318   | O_II-7330   | [O II] red doublet                 |
| Doublet     | Ar_III-7136 | Ar_III-7751 | [Ar III] sanity/reddening          |
|-------------+-------------+-------------+------------------------------------|
| Helium      | He_I-5876   | He_I-6678   | He Triplet/Singlet                 |
|-------------+-------------+-------------+------------------------------------|
| Ionization  | O_I-6300    | O_I-8446    | [O I] Collisional/ O I Fluorescent |
| Ionization  | O_II-7318   | O_I-6300    | [O II] / [O I]                     |
| Ionization  | O_III-5007  | O_II-7318   | [O III] /[O II]                    |
| Ionization  | Ar_IV-4740  | Ar_III-7751 | [Ar IV] / [Ar III]                 |
| Ionization  | Cl_IV-8046  | Cl_III-5518 | [Cl IV] / [Cl III]                 |
| Ionization  | Cl_III-5518 | Cl_II-8579  | [Cl III] / Cl II                   |
|-------------+-------------+-------------+------------------------------------|
| Fluorescent | N_I-5199    | O_I-7002    | [N I] / O I                        |
| Fluorescent | O_I-7002    | O_I-8446    | O I red / far red                  |
|-------------+-------------+-------------+------------------------------------|
| Permitted   | C_II-7236   | H_I-6563    | C II / H I                         |
| Permitted   | C_II-7231   | C_II-7236   | C II fluor indicator               |
*** Calculate line ratios for entries in table
#+BEGIN_SRC python :tangle ratios-from-table.py
  import sys
  from astropy.table import Table
  from muse_line_ratio import save_line_ratio_map

  try:
      suffix = sys.argv[1]
  except:
      suffix = ''

  ratiotab = Table.read('line-ratio-list{}.tab'.format(suffix), format='ascii.tab')

  # Only do the lines, not continuum
  prefix = 'linesum'

  try:
      suffix = '-' + sys.argv[1]
  except IndexError:
      suffix = ''

  try:
      group = sys.argv[2]
  except IndexError:
      group = None

  for row in ratiotab:
      if group is None or group in row['Group']:
          save_line_ratio_map(row['Numerator'], row['Denominator'],
                              prefix, suffix)

#+END_SRC
** Te, Ne from multibin maps
:PROPERTIES:
:ID:       4DD175B0-88A8-4F96-B7B7-1DB2B241A3F6
:END:
#+BEGIN_SRC python :tangle muse-make-te-ne-maps-rebin.py
  import sys
  import numpy as np
  from astropy.io import fits
  from derive_ne_te_1phase import T_den_from_rsii_rnii
  from deredden import deredden_nii_ratio

  prefix = 'LineMaps/'
  nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]

  try:
      extra = sys.argv[1]
  except IndexError:
      extra = ''

  for n in nlist:
      suffix = '{}-bin{:03d}'.format(extra, n)

      hduA = fits.open(prefix + "ratio-6716-6731{}.fits".format(suffix))[1]
      hduB = fits.open(prefix + "ratio-5755-6583{}.fits".format(suffix))[1]
      hb_ha = fits.open(prefix + "ratio-4861-6563{}.fits".format(suffix))[1].data
      hduB.data = deredden_nii_ratio(hduB.data, hb_ha)
      hduB.writeto(prefix + 'ratio-5755-6583{}-deredden-2874.fits'.format(suffix),
                   clobber=True)

      Te = np.empty_like(hduA.data)
      Ne = np.empty_like(hduA.data)
      m = (np.isfinite(hduA.data) & np.isfinite(hduB.data)
           & (hduA.data > 0) & (hduB.data > 0))
      Te[m], Ne[m] = T_den_from_rsii_rnii(hduA.data[m], hduB.data[m])
      Te[~m], Ne[~m] = np.nan, np.nan
      fits.PrimaryHDU(header=hduA.header, data=Te).writeto(
          prefix + 'muse-derived-Te{}.fits'.format(suffix), clobber=True)
      fits.PrimaryHDU(header=hduA.header, data=Ne).writeto(
          prefix + 'muse-derived-Ne{}.fits'.format(suffix), clobber=True)

#+END_SRC

Run these in an interactive shell. They take about a minute.
#+BEGIN_SRC sh :eval no
source activate py27
time python muse-make-te-ne-maps-rebin.py
#+END_SRC

#+BEGIN_SRC sh :eval no
source activate py27
time python muse-make-te-ne-maps-rebin.py -fuzz000
#+END_SRC

#+RESULTS:

And the same for [Cl III] and [S III]
#+BEGIN_SRC python :tangle muse-make-te-ne-maps-iii-rebin.py
  import sys
  import numpy as np
  from astropy.io import fits
  from derive_ne_te_1phase import T_den_from_rcliii_rsiii

  prefix = 'LineMaps/'
  nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]

  try:
      extra = sys.argv[1]
  except IndexError:
      extra = ''


  for n in nlist:
      suffix = '{}-bin{:03d}'.format(extra, n)

      hduA = fits.open(prefix + "ratio-5538-5518{}.fits".format(suffix))[1]
      hduB = fits.open(prefix + "ratio-6312-9069-deredden{}.fits".format(suffix))[1]

      Te = np.empty_like(hduA.data)
      Ne = np.empty_like(hduA.data)
      m = (np.isfinite(hduA.data) & np.isfinite(hduB.data)
           & (hduA.data > 0) & (hduB.data > 0))
      Te[m], Ne[m] = T_den_from_rcliii_rsiii(hduA.data[m], hduB.data[m])
      Te[~m], Ne[~m] = np.nan, np.nan
      fits.PrimaryHDU(header=hduA.header, data=Te).writeto(
          prefix + 'muse-derived-Te-iii{}.fits'.format(suffix), clobber=True)
      fits.PrimaryHDU(header=hduA.header, data=Ne).writeto(
          prefix + 'muse-derived-Ne-iii{}.fits'.format(suffix), clobber=True)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
time python muse-make-te-ne-maps-iii-rebin.py
#+END_SRC

#+RESULTS:


** Delta Te, Ne from the fuzzing
:PROPERTIES:
:ID:       8793FA29-D493-4859-A5E7-BD522D218497
:END:
+ [2015-11-02 Mon 17:45] No longer divide the \delta T by the mean - this makes more sense for comparing the histogram graphs
+ Calculate \(\delta t = T - T_{0}_{}\) where \(T\) is the temperature derived from the fuzzed datacube and \(T_{0}\) is the temperature derived from the observed datacube. 
#+BEGIN_SRC python :tangle delta-T-fuzz.py
  from __future__ import print_function
  import sys
  import glob
  import numpy as np
  from astropy.io import fits

  prefix = 'Linemaps/'

  try:
      quantity = sys.argv[1]
  except:
      sys.exit('Usage: {} (Te|Te-iii|Ne|Ne-iii)'.format(sys.argv[0]))

  obs_pattern = prefix + 'muse-derived-{}-bin???.fits'.format(quantity)
  obs_datafiles = glob.glob(obs_pattern)

  for obs_fn in obs_datafiles:
      obs_hdu = fits.open(obs_fn)['SCALED'].data
      fuzz_pattern = obs_fn.replace('-bin', '-fuzz???-bin')
      fuzz_datafiles = glob.glob(fuzz_pattern)
      for fuzz_fn in fuzz_datafiles:
          fuzz_hdu = fits.open(fuzz_fn)['SCALED']
          if 'Te' in fuzz_fn:
              # calculate (T - T0)/T0
              fuzz_hdu.data = (fuzz_hdu.data - obs_hdu.data)
          else:
              # calculate log10(N/N0)
              fuzz_hdu.data = np.log10(fuzz_hdu.data/obs_hdu.data)

          delta_fn = fuzz_fn.replace('derived-Te', 'delta-Te').replace('derived-Ne', 'log10-n')
          print('Writing', delta_fn)
          fuzz_hdu.writeto(delta_fn, clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results verbatim
python delta-T-fuzz.py Te
#+END_SRC

#+RESULTS:
#+begin_example
Writing Linemaps/muse-delta-Te-fuzz000-bin001.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin001.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin001.fits
Writing Linemaps/muse-delta-Te-fuzz000-bin002.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin002.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin002.fits
Writing Linemaps/muse-delta-Te-fuzz000-bin004.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin004.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin004.fits
Writing Linemaps/muse-delta-Te-fuzz000-bin008.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin008.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin008.fits
Writing Linemaps/muse-delta-Te-fuzz000-bin016.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin016.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin016.fits
Writing Linemaps/muse-delta-Te-fuzz000-bin032.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin032.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin032.fits
Writing Linemaps/muse-delta-Te-fuzz000-bin064.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin064.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin064.fits
Writing Linemaps/muse-delta-Te-fuzz000-bin128.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin128.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin128.fits
Writing Linemaps/muse-delta-Te-fuzz000-bin256.fits
Writing Linemaps/muse-delta-Te-fuzz001-bin256.fits
Writing Linemaps/muse-delta-Te-fuzz002-bin256.fits
#+end_example

#+BEGIN_SRC sh :results verbatim
python delta-T-fuzz.py Te-iii
#+END_SRC

#+RESULTS:
#+begin_example
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin001.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin001.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin001.fits
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin002.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin002.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin002.fits
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin004.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin004.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin004.fits
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin008.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin008.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin008.fits
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin016.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin016.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin016.fits
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin032.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin032.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin032.fits
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin064.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin064.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin064.fits
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin128.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin128.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin128.fits
Writing Linemaps/muse-delta-Te-iii-fuzz000-bin256.fits
Writing Linemaps/muse-delta-Te-iii-fuzz001-bin256.fits
Writing Linemaps/muse-delta-Te-iii-fuzz002-bin256.fits
#+end_example

#+BEGIN_SRC sh :results verbatim
python delta-T-fuzz.py Ne
#+END_SRC

#+RESULTS:
#+begin_example
Writing Linemaps/muse-log10-n-fuzz000-bin001.fits
Writing Linemaps/muse-log10-n-fuzz001-bin001.fits
Writing Linemaps/muse-log10-n-fuzz000-bin002.fits
Writing Linemaps/muse-log10-n-fuzz001-bin002.fits
Writing Linemaps/muse-log10-n-fuzz000-bin004.fits
Writing Linemaps/muse-log10-n-fuzz001-bin004.fits
Writing Linemaps/muse-log10-n-fuzz000-bin008.fits
Writing Linemaps/muse-log10-n-fuzz001-bin008.fits
Writing Linemaps/muse-log10-n-fuzz000-bin016.fits
Writing Linemaps/muse-log10-n-fuzz001-bin016.fits
Writing Linemaps/muse-log10-n-fuzz000-bin032.fits
Writing Linemaps/muse-log10-n-fuzz001-bin032.fits
Writing Linemaps/muse-log10-n-fuzz000-bin064.fits
Writing Linemaps/muse-log10-n-fuzz001-bin064.fits
Writing Linemaps/muse-log10-n-fuzz000-bin128.fits
Writing Linemaps/muse-log10-n-fuzz001-bin128.fits
Writing Linemaps/muse-log10-n-fuzz000-bin256.fits
Writing Linemaps/muse-log10-n-fuzz001-bin256.fits
#+end_example

#+BEGIN_SRC sh :results verbatim
python delta-T-fuzz.py Ne-iii
#+END_SRC

#+RESULTS:
#+begin_example
Writing Linemaps/muse-log10-n-iii-fuzz000-bin001.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin001.fits
Writing Linemaps/muse-log10-n-iii-fuzz000-bin002.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin002.fits
Writing Linemaps/muse-log10-n-iii-fuzz000-bin004.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin004.fits
Writing Linemaps/muse-log10-n-iii-fuzz000-bin008.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin008.fits
Writing Linemaps/muse-log10-n-iii-fuzz000-bin016.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin016.fits
Writing Linemaps/muse-log10-n-iii-fuzz000-bin032.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin032.fits
Writing Linemaps/muse-log10-n-iii-fuzz000-bin064.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin064.fits
Writing Linemaps/muse-log10-n-iii-fuzz000-bin128.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin128.fits
Writing Linemaps/muse-log10-n-iii-fuzz000-bin256.fits
Writing Linemaps/muse-log10-n-iii-fuzz001-bin256.fits
#+end_example



** TODO Fuzzy Deltas distribution histograms
:PROPERTIES:
:ID:       7DB9EEBF-F83B-4D93-8C0D-8665AC9881AD
:END:
Like the [[id:B85FB5E5-A541-4862-AEA4-796B64172022][following]] but for the quantities from the [[id:8793FA29-D493-4859-A5E7-BD522D218497][previous section]]

#+BEGIN_SRC python :tangle muse-Te-Ne-fuzz-histograms.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.table import Table, Column
  from matplotlib import pyplot as plt
  import seaborn as sns
  import pyregion
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from misc_utils import sanitize_string
  from stats_utils import stats_vs_x

  def prepare_string(label):
      newlabel = label.replace('log10 (N\' / N)', 'log10-n')
      return sanitize_string(newlabel)

  try:
      fuzz = sys.argv[1]
      binning = sys.argv[2]
      region = sys.argv[3]
  except IndexError:
      sys.exit('Usage: {} FUZZ BINNING REGION'.format(sys.argv[0]))

  file_patterns = {
      '[N II] Delta T'  : 'muse-delta-Te-fuzz{}-bin{}.fits',
      '[S II] log10 (N\' / N)'  : 'muse-log10-n-fuzz{}-bin{}.fits',
      '[S III] Delta T' : 'muse-delta-Te-iii-fuzz{}-bin{}.fits',
      '[Cl III] log10 (N\' / N)': 'muse-log10-n-iii-fuzz{}-bin{}.fits',
      'S(Pa 9)'    : 'linesum-H_I-9229-fuzz{}-bin{}.fits',
      'S(6716)'    : 'linesum-S_II-6716-fuzz{}-bin{}.fits',
      'S(6583)'    : 'linesum-N_II-6583-fuzz{}-bin{}.fits',
      'S(9069)'    : 'linesum-S_III-9069-fuzz{}-bin{}.fits',
      'S(5518)'    : 'linesum-Cl_III-5518-fuzz{}-bin{}.fits',
      'T([N II])'  : 'muse-derived-Te-fuzz{}-bin{}.fits',
      'N([S II])'  : 'muse-derived-Ne-fuzz{}-bin{}.fits',
      'T([S III])' : 'muse-derived-Te-iii-fuzz{}-bin{}.fits',
      'N([Cl III])': 'muse-derived-Ne-iii-fuzz{}-bin{}.fits',
  }
  minmax = {
      '[N II] Delta T'  : [-5000.0, 5000.0], 
      '[S II] log10 (N\' / N)'  : [-1.5, 1.5], 
      '[S III] Delta T' : [-5000.0, 5000.0], 
      '[Cl III] log10 (N\' / N)': [-1.5, 1.5], 
      'S(Pa 9)'    : [4.0e3, 4.0e5],
      'S(5755)'    : [600.0, 6.0e5],
      'S(6716)'    : [600.0, 6.0e5],
      'S(6312)'    : [600.0, 6.0e5],
      'S(5518)'    : [600.0, 6.0e5],
      'T([N II])'  : [5000.0, 15000.],
      'N([S II])'  : [100.0, 1e5],
      'T([S III])' : [5000.0, 15000.], 
      'N([Cl III])': [100.0, 1e5],
  }



  hdus = {k: fits.open('Linemaps/' + v.format(fuzz, binning))['SCALED']
          for k, v in file_patterns.items()}

  pairs = [
      ['S(Pa 9)', '[N II] Delta T'],
      ['S(Pa 9)', '[S II] log10 (N\' / N)'],
      ['S(Pa 9)', '[S III] Delta T'],
      ['S(Pa 9)', '[Cl III] log10 (N\' / N)'],
  ]

  # Pairs that need to know about each other because of co-dependent ratios
  complements = {
      '[S II] log10 (N\' / N)'   : 'T([N II])', 
      '[N II] Delta T'   : 'N([S II])', 
      '[Cl III] log10 (N\' / N)' : 'T([S III])', 
      '[S III] Delta T'  : 'N([Cl III])', 
  }

  weighting_maps = {
      '[N II] Delta T'  : 'S(6583)', 
      '[S II] log10 (N\' / N)'  : 'S(6716)', 
      '[S III] Delta T' : 'S(9069)', 
      '[Cl III] log10 (N\' / N)': 'S(5518)', 
  }

  mm = np.isfinite(hdus['S(Pa 9)'].data) & (hdus['S(Pa 9)'].data > 0.0) 
  if 'sweet' in region.lower():
      title = 'Orion S'
      include = pyregion.open(t2dir + '/will-nii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-nii-exclude-new.reg')
      mm = mm & include.get_mask(hdu=hdus['S(Pa 9)']) & (~exclude.get_mask(hdu=hdus['S(Pa 9)']))

      include = pyregion.open(t2dir + '/will-sii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-sii-exclude-new.reg')
      mm = mm & include.get_mask(hdu=hdus['S(Pa 9)']) & (~exclude.get_mask(hdu=hdus['S(Pa 9)']))
  else:
      title = 'Full nebula'

  for xlabel, ylabel in pairs:
      hduA = hdus[xlabel]
      hduB = hdus[ylabel]
      xmin, xmax = minmax[xlabel]
      ymin, ymax = minmax[ylabel]

      m = mm & np.isfinite(hduA.data) & np.isfinite(hduB.data)
      m = m & (hduA.data > xmin) & (hduB.data > ymin) 
      m = m & (hduA.data < xmax) & (hduB.data < ymax) 
      m = m & (hduA.data != 0.0) & (hduB.data != 0.0) 

      wlabels = []
      for label in xlabel, ylabel:
          # Make a list of quantities to use as weights for this map
          if label in weighting_maps:
              wlabels.append(weighting_maps[label])
          else:
              wlabels.append(label)
          # Also check complementary vars for being out-of-range
          if label in complements:
              zlabel = complements[label]
              zmin, zmax = minmax[zlabel]
              hduC = hdus[zlabel]
              m = m & (hduC.data > zmin) & (hduC.data < zmax)

      x = hduA.data[m]
      y = hduB.data[m]
      w = np.zeros_like(x)
      for wlabel in set(wlabels):
          w += hdus[wlabel].data[m]

      gamma = 1.5
      # Red tinted colormap for the error histograms
      cmap = sns.light_palette((30, 50, 30), input="husl", as_cmap=True)
      fig, ax = plt.subplots(1, 1)
      # Save a sorted, linear version of the weights
      ww = np.sort(w)
      # Use a log scale for surface brightnesses and densities
      if xlabel.startswith('S') or xlabel.startswith('N'):
          x = np.log10(x)
          xmin, xmax = np.log10(xmin), np.log10(xmax)
          xlabel = 'log10[ {} ]'.format(xlabel)
      if ylabel.startswith('S') or ylabel.startswith('N'):
          y = np.log10(y)
          ymin, ymax = np.log10(ymin), np.log10(ymax)
          ylabel = 'log10[ {} ]'.format(ylabel)
      H, xedges, yedges = np.histogram2d(x, y, 51,
                                         [[xmin, xmax], [ymin, ymax]],
                                         weights=w)
      stats_table = stats_vs_x(x, y, xedges)
      ax.imshow((H.T)**(1.0/gamma), extent=[xmin, xmax, ymin, ymax],
                interpolation='nearest', aspect='auto', origin='lower', 
                cmap=cmap, alpha=1.0)

      ax.set_xlim(xmin, xmax)
      ax.set_ylim(ymin, ymax)
      ax.set_xlabel(xlabel, fontsize='large')
      ax.set_ylabel(ylabel, fontsize='large')
      ax.grid(color='w', lw=0.5, alpha=0.5, zorder=100)

      fig.set_size_inches(3, 3)
      fig.tight_layout()
      pattern = 'muse-{}-{}-histogram-{}-fuzz{}-bin{}.pdf'
      pltfile = pattern.format(prepare_string(xlabel), prepare_string(ylabel),
                               region, fuzz, binning)

      fig.savefig(pltfile)
      statsfile = pltfile.replace('.pdf', '.tab').replace('-histogram-', '-stats-')
      stats_table.write(statsfile, format='ascii.tab')

      histfile = statsfile.replace('-stats-', '-hist-1d-')

      # Now save the full histogram for each tertile in the CDF of weights
      wcdf = np.cumsum(ww)/np.sum(ww)
      w1, w2 = [np.max(ww[100*wcdf < percentile]) for percentile in [33, 67]]
      print('Tertiles of CDF of weights:')
      print(w1, w2)
      m1 = (w <= w1)
      m2 = (w > w1) & (w <= w2)
      m3 = (w > w2) 
      HH1, yedges = np.histogram(y[m1], bins=51, range=[ymin, ymax], weights=w[m1])
      HH2, yedges = np.histogram(y[m2], bins=51, range=[ymin, ymax], weights=w[m2])
      HH3, yedges = np.histogram(y[m3], bins=51, range=[ymin, ymax], weights=w[m3])

      ycenters = 0.5*(yedges[:-1] + yedges[1:])

      hist_table = Table()
      hist_table.add_columns([
          Column(name=ylabel, data=ycenters),
          Column(name='T1', data=HH1),
          Column(name='T2', data=HH2),
          Column(name='T3', data=HH3),
      ])
      hist_table.write(histfile, format='ascii.tab')

      print(pltfile)

#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh :eval no :tangle muse-all-fuzz-histograms.sh
# for bin in 001 ; do
#     for fuzz in 009; do
for bin in 001 002 004 008 016 032 064 128 256; do
    for fuzz in 000 001 002 003 004 005 006 007 008 009; do
        python muse-Te-Ne-fuzz-histograms.py $fuzz $bin full
        python muse-Te-Ne-fuzz-histograms.py $fuzz $bin sweet
    done
done
#+END_SRC


#+BEGIN_SRC sh :results silent
open muse-log10_S_Pa_9_-S_II_log10-n-histogram-sweet-fuzz00?-bin001.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-log10_S_Pa_9_-Cl_III_log10-n-histogram-full-fuzz000-bin*.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-log10_S_Pa_9_-S_III_Delta_T-histogram-full-fuzz000-bin*.pdf
#+END_SRC

#+RESULTS:
#+begin_example
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz000-bin001.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz000-bin001.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz000-bin001.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz000-bin001.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz001-bin001.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz001-bin001.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz001-bin001.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz001-bin001.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz000-bin001.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz000-bin001.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz000-bin001.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz000-bin001.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz001-bin001.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz001-bin001.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz001-bin001.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz001-bin001.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz000-bin004.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz000-bin004.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz000-bin004.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz000-bin004.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz001-bin004.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz001-bin004.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz001-bin004.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz001-bin004.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz000-bin004.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz000-bin004.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz000-bin004.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz000-bin004.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz001-bin004.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz001-bin004.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz001-bin004.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz001-bin004.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz000-bin016.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz000-bin016.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz000-bin016.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz000-bin016.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz001-bin016.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz001-bin016.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz001-bin016.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz001-bin016.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz000-bin016.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz000-bin016.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz000-bin016.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz000-bin016.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz001-bin016.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz001-bin016.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz001-bin016.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz001-bin016.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz000-bin064.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz000-bin064.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz000-bin064.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz000-bin064.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz001-bin064.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz001-bin064.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz001-bin064.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz001-bin064.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz000-bin064.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz000-bin064.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz000-bin064.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz000-bin064.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz001-bin064.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz001-bin064.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz001-bin064.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz001-bin064.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz000-bin256.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz000-bin256.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz000-bin256.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz000-bin256.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-full-fuzz001-bin256.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-full-fuzz001-bin256.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-full-fuzz001-bin256.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-full-fuzz001-bin256.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz000-bin256.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz000-bin256.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz000-bin256.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz000-bin256.pdf
muse-log10_S_5755_-N_II_delta-t-histogram-sweet-fuzz001-bin256.pdf
muse-log10_S_6716_-S_II_log10-n-histogram-sweet-fuzz001-bin256.pdf
muse-log10_S_6312_-S_III_delta-t-histogram-sweet-fuzz001-bin256.pdf
muse-log10_S_5518_-Cl_III_log10-n-histogram-sweet-fuzz001-bin256.pdf
#+end_example

#+BEGIN_SRC sh :results silent
open muse-log10_S_5518_*log10-n*-full-fuzz000-bin*.pdf
open muse-log10_S_6312_*Delta_T*-full-fuzz000-bin*.pdf
open muse-log10_S_6716_*log10-n*-full-fuzz000-bin*.pdf
open muse-log10_S_5755_*Delta_T*-full-fuzz000-bin*.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-log10_S_5518_*log10-n*-sweet-fuzz000-bin*.pdf
open muse-log10_S_6312_*Delta_T*-sweet-fuzz000-bin*.pdf
open muse-log10_S_6716_*log10-n*-sweet-fuzz000-bin*.pdf
open muse-log10_S_5755_*Delta_T*-sweet-fuzz000-bin*.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-log10_S_5518_*log10-n*-full-fuzz001-bin*.pdf
open muse-log10_S_6312_*Delta_T*-full-fuzz001-bin*.pdf
open muse-log10_S_6716_*log10-n*-full-fuzz001-bin*.pdf
open muse-log10_S_5755_*Delta_T*-full-fuzz001-bin*.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-log10_S_5518_*log10-n*-sweet-fuzz001-bin*.pdf
open muse-log10_S_6312_*Delta_T*-sweet-fuzz001-bin*.pdf
open muse-log10_S_6716_*log10-n*-sweet-fuzz001-bin*.pdf
open muse-log10_S_5755_*Delta_T*-sweet-fuzz001-bin*.pdf
#+END_SRC




** Utility functions for calculating variance over histogram
:PROPERTIES:
:ID:       16E6C7CA-1806-4125-8148-F853B4D7FE78
:END:
#+BEGIN_SRC python :tangle stats_utils.py
  import numpy as np
  import scipy.stats as ss
  from astropy.table import Table
  from scipy.special import erfinv

  WAVS = {'N_II': '5755', 'S_III': '6312',}
  IQR_OVER_SIGMA = 2.0*np.sqrt(2.0)*erfinv(0.5)

  def stats_vs_x(x, y, xedges):
      '''Calculate statistics column by column to complement a histogram

      Returns an astropy.table object
      '''
      rslt = {'Y Mean': [], 'Y Median': [], 'Y Std': [],
              'Y Lower Quartile': [], 'Y Upper Quartile': [],
              'Count': [], 'X Mean': []}
      for x1, x2 in zip(xedges[:-1], xedges[1:]):
          thisbin = (x >= x1) & (x <= x2)
          rslt['Y Mean'].append(y[thisbin].mean())
          rslt['Y Median'].append(np.median(y[thisbin]))
          rslt['Y Std'].append(y[thisbin].std())
          rslt['Count'].append(thisbin.sum())
          rslt['X Mean'].append(x[thisbin].mean())
          if thisbin.sum() > 0:
              rslt['Y Lower Quartile'].append(
                  ss.scoreatpercentile(y[thisbin].ravel(), 25))
              rslt['Y Upper Quartile'].append(
                  ss.scoreatpercentile(y[thisbin].ravel(), 75))
          else:
              rslt['Y Lower Quartile'].append(np.nan)
              rslt['Y Upper Quartile'].append(np.nan)
      for s in rslt:
          rslt[s] = np.array(rslt[s])
      rslt['X Center'] = 0.5*(xedges[:-1] + xedges[1:])
      return Table(rslt)


  def get_stats_for_var(var='T', ion='N_II', region='full', nbin=1):
      xstring = 'log10_S_{}_'.format(WAVS[ion])
      ystring = '{}_{}'.format(var, ion)
      tabname = 'muse-{}-{}-stats-{}{:03d}.tab'.format(xstring, ystring, region, nbin)
      return Table.read(tabname, format='ascii.tab')

  def get_fuzzstats_for_var(var='Delta_T', ion='N_II', region='full', nbin=1, ifuzz=0):
      xstring = 'log10_S_{}_'.format(WAVS[ion])
      ystring = '{}_{}'.format(ion, var)
      tabname = 'muse-{}-{}-stats-{}-fuzz{:03d}-bin{:03d}.tab'.format(
          xstring, ystring, region, ifuzz, nbin)
      return Table.read(tabname, format='ascii.tab')


  def tsq_from_tables(tabvar, tabmean, robust=False):
      if robust:
          # Use Interquartile range as proxy for standard deviation
          sigma = (tabvar['Y Upper Quartile'].data
                   - tabvar['Y Lower Quartile'].data)/IQR_OVER_SIGMA
          # Use median as proxy for mean
          av = tabmean['Y Median'].data
      else:
          sigma = tabvar['Y Std'].data
          av = tabmean['Y Mean'].data

      return sigma**2/av**2

#+END_SRC
** DONE Te - Ne distribution histograms
CLOSED: [2016-03-14 Mon 20:08]
:PROPERTIES:
:ID:       B85FB5E5-A541-4862-AEA4-796B64172022
:END:
:LOGBOOK:
- Note taken on [2016-03-13 Sun 08:50] \\
  We need to adapt this in the same way as the [[id:52668E44-F2B6-4EFC-8703-A28B54D2D104][wfc3 version]] so that we can plot the 1d histograms of the tertiles
:END:
+ We want to get to the stuff in the ipynb file
+ Similar to other [[id:012A7F6B-BC6B-433E-A5A8-E1453B1E3FCA][histogram plot programs]]
+ But this does several different correlations
  + Te([N II]) vs Ne([S II])
  + Te([N II]) vs Te([S III])
  + Ne([S II]) vs Ne([Cl III])
  + Te([S III]) vs Ne([Cl III])


#+BEGIN_SRC python :tangle muse-Te-Ne-histograms.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.table import Table, Column
  from matplotlib import pyplot as plt
  import seaborn as sns
  import pyregion
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from misc_utils import sanitize_string
  from stats_utils import stats_vs_x


  try:
      region = sys.argv[1]
      suffix = sys.argv[2]
  except IndexError:
      sys.exit('Usage: {} REGION [SUFFIX]'.format(sys.argv[0]))

  file_patterns = {
      'T([N II])'  : 'muse-derived-Te-bin{}.fits',
      'N([S II])'  : 'muse-derived-Ne-bin{}.fits',
      'T([S III])' : 'muse-derived-Te-iii-bin{}.fits',
      'N([Cl III])': 'muse-derived-Ne-iii-bin{}.fits',
      'S(Pa 9)'    : 'linesum-H_I-9229-bin{}.fits',
      'S(5755)'    : 'linesum-N_II-5755-bin{}.fits',
      'S(6583)'    : 'linesum-N_II-6583-bin{}.fits',
      'S(6716)'    : 'linesum-S_II-6716-bin{}.fits',
      'S(6312)'    : 'linesum-S_III-6312-bin{}.fits',
      'S(5518)'    : 'linesum-Cl_III-5518-bin{}.fits',
  }

  minmax = {
      'T([N II])'  : [5000.0, 15000.],
      'N([S II])'  : [100.0, 1e5],
      'T([S III])' : [5000.0, 15000.], 
      'N([Cl III])': [100.0, 1e5],
      'S(Pa 9)'    : [4.0e3, 4.0e5],
      'S(5755)'    : [600.0, 6.0e5],
      'S(6716)'    : [600.0, 6.0e5],
      'S(6312)'    : [600.0, 6.0e5],
      'S(5518)'    : [600.0, 6.0e5],
  }



  hdus = {k: fits.open('Linemaps/' + v.format(suffix))['SCALED']
          for k, v in file_patterns.items()}

  true_shape = hdus['S(Pa 9)'].data.shape
  for lab, hdu in hdus.items():
      assert hdu.data.shape == true_shape, '{} has shape {}, should be {}'.format(hdu.fileinfo()['file'], hdu.data.shape, true_shape)

  pairs = [
      ['T([N II])', 'T([S III])'],
      ['N([S II])', 'N([Cl III])'],
      ['N([S II])', 'T([N II])'],
      ['N([Cl III])', 'T([S III])'],
      ['S(Pa 9)', 'N([S II])'],
      ['S(Pa 9)', 'N([Cl III])'],
      ['S(Pa 9)', 'T([N II])'],
      ['S(Pa 9)', 'T([S III])'],
      ['S(6716)', 'N([S II])'],
      ['S(5518)', 'N([Cl III])'],
      ['S(5755)', 'T([N II])'],
      ['S(6312)', 'T([S III])'],
  ]

  # Pairs that need to know about each other because of co-dependent ratios
  complements = {
      'N([S II])': 'T([N II])', 
      'T([N II])': 'N([S II])', 
      'N([Cl III])': 'T([S III])', 
      'T([S III])': 'N([Cl III])', 
  }

  weighting_maps = {
      'N([S II])': 'S(6716)', 
      'T([N II])': 'S(6583)', 
      'N([Cl III])': 'S(5518)', 
      'T([S III])': 'S(9069)', 
  }

  mm = np.isfinite(hdus['S(Pa 9)'].data) & (hdus['S(Pa 9)'].data > 0.0) 
  if 'sweet' in region.lower():
      title = 'Orion S'
      include = pyregion.open(t2dir + '/will-nii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-nii-exclude-new.reg')
      mm = mm & include.get_mask(hdu=hdus['S(Pa 9)']) & (~exclude.get_mask(hdu=hdus['S(Pa 9)']))

      include = pyregion.open(t2dir + '/will-sii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-sii-exclude-new.reg')
      mm = mm & include.get_mask(hdu=hdus['S(Pa 9)']) & (~exclude.get_mask(hdu=hdus['S(Pa 9)']))
  else:
      title = 'Full nebula'


  for xlabel, ylabel in pairs:
      hduA = hdus[xlabel]
      hduB = hdus[ylabel]
      xmin, xmax = minmax[xlabel]
      ymin, ymax = minmax[ylabel]

      m = mm & np.isfinite(hduA.data) & np.isfinite(hduB.data)
      m = m & (hduA.data > xmin) & (hduB.data > ymin) 
      m = m & (hduA.data < xmax) & (hduB.data < ymax) 

      wlabels = []
      for label in xlabel, ylabel:
          # Make a list of quantities to use as weights for this map
          if label in weighting_maps:
              wlabels.append(weighting_maps[label])
          else:
              wlabels.append(label)
          # Also check complementary vars for being out-of-range
          if label in complements:
              zlabel = complements[label]
              zmin, zmax = minmax[zlabel]
              hduC = hdus[zlabel]
              print('Labels:', xlabel, ylabel, zlabel)
              print('Shapes:', hduA.data.shape, hduB.data.shape, hduC.data.shape)
              m = m & (hduC.data > zmin) & (hduC.data < zmax)

      x = hduA.data[m]
      y = hduB.data[m]
      w = np.zeros_like(x)
      for wlabel in set(wlabels):
          w += hdus[wlabel].data[m]
      gamma = 1.5
      # Blue tinted colormap for the data histograms
      cmap = sns.light_palette((260, 50, 30), input="husl", as_cmap=True)
      fig, ax = plt.subplots(1, 1)
      # Save a sorted, linear version of the weights
      ww = np.sort(w)
      # Use a log scale for surface brightnesses and densities
      if xlabel.startswith('S') or xlabel.startswith('N'):
          x = np.log10(x)
          xmin, xmax = np.log10(xmin), np.log10(xmax)
          xlabel = 'log10[ {} ]'.format(xlabel)
      if ylabel.startswith('S') or ylabel.startswith('N'):
          y = np.log10(y)
          ymin, ymax = np.log10(ymin), np.log10(ymax)
          ylabel = 'log10[ {} ]'.format(ylabel)
      H, xedges, yedges = np.histogram2d(x, y, 51,
                                         [[xmin, xmax], [ymin, ymax]],
                                         weights=w)
      stats_table = stats_vs_x(x, y, xedges)
      ax.imshow((H.T)**(1.0/gamma), extent=[xmin, xmax, ymin, ymax],
                interpolation='nearest', aspect='auto', origin='lower', 
                cmap=cmap, alpha=1.0)

      ax.set_xlim(xmin, xmax)
      ax.set_ylim(ymin, ymax)
      ax.set_xlabel(xlabel, fontsize='large')
      ax.set_ylabel(ylabel, fontsize='large')
      ax.grid(color='w', lw=0.5, alpha=0.5, zorder=100)

      fig.set_size_inches(3, 3)
      fig.tight_layout()
      pltfile = 'muse-{}-{}-histogram-{}{}.pdf'.format(sanitize_string(xlabel),
                                                       sanitize_string(ylabel),
                                                       region, suffix)

      fig.savefig(pltfile)
      statsfile = pltfile.replace('.pdf', '.tab').replace('-histogram-', '-stats-')
      stats_table.write(statsfile, format='ascii.tab')

      histfile = statsfile.replace('-stats-', '-hist-1d-')

      # Now save the full histogram for each tertile in the CDF of weights
      wcdf = np.cumsum(ww)/np.sum(ww)
      w1, w2 = [np.max(ww[100*wcdf < percentile]) for percentile in [33, 67]]
      print('Tertiles of CDF of weights:')
      print(w1, w2)
      m1 = (w <= w1)
      m2 = (w > w1) & (w <= w2)
      m3 = (w > w2) 
      HH1, yedges = np.histogram(y[m1], bins=51, range=[ymin, ymax], weights=w[m1])
      HH2, yedges = np.histogram(y[m2], bins=51, range=[ymin, ymax], weights=w[m2])
      HH3, yedges = np.histogram(y[m3], bins=51, range=[ymin, ymax], weights=w[m3])

      ycenters = 0.5*(yedges[:-1] + yedges[1:])

      hist_table = Table()
      hist_table.add_columns([
          Column(name=ylabel, data=ycenters),
          Column(name='T1', data=HH1),
          Column(name='T2', data=HH2),
          Column(name='T3', data=HH3),
      ])
      hist_table.write(histfile, format='ascii.tab')


      print(pltfile)

#+END_SRC

#+RESULTS:


#+BEGIN_SRC sh :eval no :tangle muse-all-histograms.sh
  for bin in 001 002 004 008 016 032 064 128 256; do
  #for bin in 008 016 032 064 128 256; do
      time python muse-Te-Ne-histograms.py $1 $bin
  done
#+END_SRC

#+BEGIN_SRC sh :results verbatim 
sh muse-all-histograms.sh full
#+END_SRC

#+BEGIN_SRC sh :results verbatim 
sh muse-all-histograms.sh sweet
#+END_SRC




#+RESULTS:
#+begin_example
muse-T_N_II-T_S_III-histogram-full001.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full001.pdf
muse-log10_N_S_II_-T_N_II-histogram-full001.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-full001.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-full001.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-full001.pdf
muse-log10_S_5755_-T_N_II-histogram-full001.pdf
muse-log10_S_6312_-T_S_III-histogram-full001.pdf
muse-T_N_II-T_S_III-histogram-full004.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full004.pdf
muse-log10_N_S_II_-T_N_II-histogram-full004.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-full004.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-full004.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-full004.pdf
muse-log10_S_5755_-T_N_II-histogram-full004.pdf
muse-log10_S_6312_-T_S_III-histogram-full004.pdf
muse-T_N_II-T_S_III-histogram-full016.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full016.pdf
muse-log10_N_S_II_-T_N_II-histogram-full016.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-full016.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-full016.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-full016.pdf
muse-log10_S_5755_-T_N_II-histogram-full016.pdf
muse-log10_S_6312_-T_S_III-histogram-full016.pdf
muse-T_N_II-T_S_III-histogram-full064.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full064.pdf
muse-log10_N_S_II_-T_N_II-histogram-full064.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-full064.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-full064.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-full064.pdf
muse-log10_S_5755_-T_N_II-histogram-full064.pdf
muse-log10_S_6312_-T_S_III-histogram-full064.pdf
#+end_example



#+RESULTS:
#+BEGIN_SRC sh
open muse-log10_S_5518_-log10_N_Cl_III_-histogram-full???.pdf
open muse-log10_S_6312_-T_S_III-histogram-full???.pdf
open muse-log10_S_6716_-log10_N_S_II_-histogram-full???.pdf
open muse-log10_S_5755_-T_N_II-histogram-full???.pdf
#+END_SRC

#+BEGIN_SRC sh
open muse-log10_S_Pa_9_-log10_N_Cl_III_-histogram-full???.pdf
open muse-log10_S_Pa_9_-T_S_III-histogram-full???.pdf
open muse-log10_S_Pa_9_-log10_N_S_II_-histogram-full???.pdf
open muse-log10_S_Pa_9_-T_N_II-histogram-full???.pdf
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh
open muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full???.pdf
open muse-T_N_II-T_S_III-histogram-full???.pdf
open muse-log10_N_S_II_-T_N_II-histogram-full???.pdf
open muse-log10_N_Cl_III_-T_S_III-histogram-full???.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-log10_N_S_II_-T_N_II-histogram-sweet???.pdf
#+END_SRC

#+RESULTS:

#+RESULTS:

#+BEGIN_SRC sh :results verbatim
source activate py27
for bin in 001 002 004 008 016 032 064 128 256; do
    python muse-Te-Ne-histograms.py sweet $bin
done
#+END_SRC

#+RESULTS:
#+begin_example
muse-T_N_II-T_S_III-histogram-sweet001.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-sweet001.pdf
muse-log10_N_S_II_-T_N_II-histogram-sweet001.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-sweet001.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-sweet001.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet001.pdf
muse-log10_S_5755_-T_N_II-histogram-sweet001.pdf
muse-log10_S_6312_-T_S_III-histogram-sweet001.pdf
muse-T_N_II-T_S_III-histogram-sweet004.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-sweet004.pdf
muse-log10_N_S_II_-T_N_II-histogram-sweet004.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-sweet004.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-sweet004.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet004.pdf
muse-log10_S_5755_-T_N_II-histogram-sweet004.pdf
muse-log10_S_6312_-T_S_III-histogram-sweet004.pdf
muse-T_N_II-T_S_III-histogram-sweet016.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-sweet016.pdf
muse-log10_N_S_II_-T_N_II-histogram-sweet016.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-sweet016.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-sweet016.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet016.pdf
muse-log10_S_5755_-T_N_II-histogram-sweet016.pdf
muse-log10_S_6312_-T_S_III-histogram-sweet016.pdf
muse-T_N_II-T_S_III-histogram-sweet064.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-sweet064.pdf
muse-log10_N_S_II_-T_N_II-histogram-sweet064.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-sweet064.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-sweet064.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet064.pdf
muse-log10_S_5755_-T_N_II-histogram-sweet064.pdf
muse-log10_S_6312_-T_S_III-histogram-sweet064.pdf
#+end_example


#+BEGIN_SRC sh
open muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet???.pdf
open muse-log10_S_6312_-T_S_III-histogram-sweet???.pdf
open muse-log10_S_6716_-log10_N_S_II_-histogram-sweet???.pdf
open muse-log10_S_5755_-T_N_II-histogram-sweet???.pdf
#+END_SRC


#+BEGIN_SRC sh
open muse-log10_S_Pa_9_-log10_N_Cl_III_-histogram-sweet???.pdf
open muse-log10_S_Pa_9_-T_S_III-histogram-sweet???.pdf
open muse-log10_S_Pa_9_-log10_N_S_II_-histogram-sweet???.pdf
open muse-log10_S_Pa_9_-T_N_II-histogram-sweet???.pdf
#+END_SRC


#+RESULTS:

#+BEGIN_SRC sh
open muse-S_Pa_9-T_S_III-histogram-sweet???.pdf
#+END_SRC

#+RESULTS:
** Compare the observed and fuzzed variances in Te,Ne 
:PROPERTIES:
:ID:       6B630292-2F8F-4192-89C1-AF07F5462505
:END:
#+BEGIN_SRC python :tangle muse-tsq-vs-bright.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from matplotlib import pyplot as plt
  import seaborn as sns
  from astropy.table import Table
  from scipy.special import erfinv
  from stats_utils import (get_stats_for_var, get_fuzzstats_for_var, 
                           tsq_from_tables)

  IQR_OVER_SIGMA = 2.0*np.sqrt(2.0)*erfinv(0.5)
  print('IQR / sigma =', IQR_OVER_SIGMA)
  BINNINGS = [1, 2, 4, 8, 16, 32, 64, 128, 256]

  def plot_tsq_vs_bright(ax, ion, binnings, colors, robust=False):
      assert len(binnings) == len(colors)
      for nbin, color in zip(binnings, colors):
          stats = get_stats_for_var('T', ion, nbin=nbin)
          fuzzstats0 = get_fuzzstats_for_var('Delta_T', ion, nbin=nbin, ifuzz=0)
          fuzzstats1 = get_fuzzstats_for_var('Delta_T', ion, nbin=nbin, ifuzz=1)
          assert np.all(stats['X Center'] == fuzzstats0['X Center'])
          log_S = stats['X Center']
          npix = stats['Count']/(nbin**2)
          weight = stats['Count']*10**log_S
          weight /= weight.sum()
          m = (npix >= 5) & (weight > 0.5/len(stats))
          tsq = tsq_from_tables(stats, stats, robust)
          tsq_err0 = tsq_from_tables(fuzzstats0, stats, robust)
          tsq_err1 = tsq_from_tables(fuzzstats1, stats, robust)
          ax.plot(log_S[m], tsq[m], color=color, label='{0} x {0}'.format(nbin))
          ax.plot(log_S[m], tsq_err0[m], color=color, lw=0.5, label=None)
          ax.plot(log_S[m], tsq_err1[m], color=color, lw=0.5, label=None)

  def plot_corrected_tsq_vs_bright(ax, ion, binnings, colors, robust=False):
      assert len(binnings) == len(colors)
      for nbin, color in zip(binnings, colors):
          stats = get_stats_for_var('T', ion, nbin=nbin)
          fuzzstats0 = get_fuzzstats_for_var('Delta_T', ion, nbin=nbin, ifuzz=0)
          fuzzstats1 = get_fuzzstats_for_var('Delta_T', ion, nbin=nbin, ifuzz=1)
          assert np.all(stats['X Center'] == fuzzstats0['X Center'])
          log_S = stats['X Center']
          npix = stats['Count']/(nbin**2)
          weight = stats['Count']*10**log_S
          weight /= weight.sum()
          m = (npix >= 5) & (weight > 0.5/len(stats))
          tsq = tsq_from_tables(stats, stats, robust)
          tsq_err0 = tsq_from_tables(fuzzstats0, stats, robust)
          tsq_err1 = tsq_from_tables(fuzzstats1, stats, robust)
          tsq -= 0.5*(tsq_err0 + tsq_err1)
          ax.plot(log_S[m], tsq[m], color=color, label='{0} x {0}'.format(nbin))

  if __name__ == '__main__':
      binnings = BINNINGS[:8]
      #colors = sns.dark_palette('orange',  n_colors=len(binnings))
      #colors = sns.color_palette('Paired',  n_colors=len(binnings))
      colors = sns.color_palette('husl',  n_colors=len(binnings))
      #colors = sns.color_palette('Set2',  n_colors=len(binnings))
      #colors = ['k']*len(binnings)
      for ion in 'N_II', 'S_III':
          for variant in '', '-robust':
              fig, ax = plt.subplots(1, 1)
              plot_tsq_vs_bright(ax, ion, binnings, colors,
                                 robust=variant=='-robust')
              leg = ax.legend(ncol=2, fontsize='x-small',
                              title='Pixel Binning', frameon=True, fancybox=True)
              leg.get_title().set_fontsize('x-small')
              ax.set_yscale('log')
              ax.set_ylim(1e-6, 3.0)
              ax.set_xlabel(r'$\log_{{10}}$( {} )'.format(WAVS[ion]))
              ax.set_ylabel('Partial $t^{{\,2}}$([{}])'.format(ion.replace('_', ' ')))
              fig.set_size_inches(4, 4)
              figname = 'muse-tsq{}-vs-bright-{}.pdf'.format(variant, ion)
              fig.tight_layout()
              fig.savefig(figname)
              print(figname)

              fig, ax = plt.subplots(1, 1)
              plot_corrected_tsq_vs_bright(ax, ion, binnings, colors,
                                           robust=variant=='-robust')
              leg = ax.legend(ncol=2, fontsize='x-small',
                              title='Pixel Binning', frameon=True, fancybox=True)
              leg.get_title().set_fontsize('x-small')
              ax.set_yscale('log')
              ax.set_ylim(1e-6, 3.0)
              ax.set_xlabel(r'$\log_{{10}}$( {} )'.format(WAVS[ion]))
              ax.set_ylabel(r'Noise-Corrected Partial $t^{{\,2}}$([{}])'.format(ion.replace('_', ' ')))
              fig.set_size_inches(4, 4)
              figname = 'muse-corrected-tsq{}-vs-bright-{}.pdf'.format(variant, ion)
              fig.tight_layout()
              fig.savefig(figname)
              print(figname)

#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh :results verbatim
python muse-tsq-vs-bright.py
#+END_SRC

#+RESULTS:
: IQR / sigma = 1.34897950039
: muse-tsq-vs-bright-N_II.pdf
: muse-corrected-tsq-vs-bright-N_II.pdf
: muse-tsq-robust-vs-bright-N_II.pdf
: muse-corrected-tsq-robust-vs-bright-N_II.pdf
: muse-tsq-vs-bright-S_III.pdf
: muse-corrected-tsq-vs-bright-S_III.pdf
: muse-tsq-robust-vs-bright-S_III.pdf
: muse-corrected-tsq-robust-vs-bright-S_III.pdf

#+BEGIN_SRC sh :results silent
open muse-*tsq*-vs-bright-*.pdf
#+END_SRC
** Calculate the total noise-corrected t2 versus binning scale
:PROPERTIES:
:ID:       E7AFCF19-3976-4FD9-A91F-464A2EDD9C86
:END:
#+BEGIN_SRC python :eval no :tangle muse-total-tsq.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.table import Table, join
  from matplotlib import pyplot as plt
  import seaborn as sns
  from stats_utils import (get_stats_for_var,
                           get_fuzzstats_for_var,
                           tsq_from_tables)

  BINNINGS = [1, 2, 4, 8, 16, 32, 64, 128, 256]
 
  def nanaverage(a, w):
      '''Weighted average of `a` with weights `w`.  Just like np.average,
  but ignoring NaNs'''
      return np.nansum(a*w)/np.nansum(w)
      

  def total_combined_tsq(stats, robust=False, meanstats=None):
      '''Find weighted tsq over all brightnesses, including contribution
  from trend in mean T with brightness.  `stats` is a table of
  temperature statistics as a function of brightness bin.  If `robust` is
  `True` then median and IQR are used instead of mean and std.  If
  `stats` gives statistics for delta T instead of T (for instance, from
  fuzzing), then 'meanstats' must be supplied, giving the equivalent
  stats for T.

      '''
      if meanstats is None:
          tsq_vs_bright = tsq_from_tables(stats, stats, robust)
      else:
          checkbins = np.all(stats['X Center'] == meanstats['X Center'])
          assert checkbins, 'Error: brightness bins do not coincide'
          tsq_vs_bright = tsq_from_tables(stats, meanstats, robust)
      # Weight each brightness bin by the total flux from that bin
      weights = stats['Count']*(10**stats['X Mean'])
      average_tsq = nanaverage(tsq_vs_bright, weights)
      # Contribution from trend of mean (or median) T with brightness
      av_type = 'Y Median' if robust else 'Y Mean'
      T0_vs_bright = stats[av_type]
      average_T0 = nanaverage(T0_vs_bright, weights)
      average_T00 = average_T0
      if meanstats is not None:
          # Case where T0 is actually a Delta T, so we need to add on
          # the "real" mean T
          average_T00 += nanaverage(meanstats[av_type], weights)
      trend_tsq_vs_bright = ((T0_vs_bright - average_T0)/average_T00)**2
      
      trend_tsq = nanaverage(trend_tsq_vs_bright, weights)
      return {
          't^2': average_tsq + trend_tsq,
          'T': average_T0,
          'trend fraction': trend_tsq / (average_tsq + trend_tsq),
      }


  def find_tsq_vs_scale(ion, robust=False, ifuzz=0, region='full'):
      '''Calculate total t^2 versus binning. Returns an astropy.table'''
      results = {'nbin': BINNINGS, 't^2': [], 'T': [], 'trend fraction': []}
      fuzz_results = {'nbin': BINNINGS, 't^2': [], 'T': [], 'trend fraction': []}
      for nbin in BINNINGS:
          stats = get_stats_for_var('T', ion,
                                    region=region, nbin=nbin)
          fstats = get_fuzzstats_for_var('Delta_T', ion,
                                         region=region, nbin=nbin, ifuzz=ifuzz)
          for k, v in total_combined_tsq(stats, robust).items():
              results[k].append(v)
          for k, v in total_combined_tsq(fstats, robust, meanstats=stats).items():
              fuzz_results[k].append(v)
      tab = Table(results)
      ftab = Table(fuzz_results)
      for t in tab, ftab:
          t['T'].format = '{:.0f}'
          t['t^2'].format = '{:.5f}'
          t['trend fraction'].format = '{:.2f}'
      return join(tab, ftab, keys='nbin', table_names=['', 'd '],
                  uniq_col_name='{table_name}{col_name}')



  for ion in 'N_II', 'S_III':
      for variant in '', '-robust':
          for region in 'full', 'sweet':
              tab = find_tsq_vs_scale(ion, robust=(variant=='-robust'), region=region) 
              fn = 'muse-total-tsq-{}{}-{}.tab'.format(ion, variant, region)
              tab.write(fn, format='ascii.tab')
              print(fn)
  #            print('[[{}]]'.format(fn))
#+END_SRC

#+BEGIN_SRC sh :results verbatim
python muse-total-tsq.py
#+END_SRC

#+RESULTS:
: muse-total-tsq-N_II-full.tab
: muse-total-tsq-N_II-sweet.tab
: muse-total-tsq-N_II-robust-full.tab
: muse-total-tsq-N_II-robust-sweet.tab
: muse-total-tsq-S_III-full.tab
: muse-total-tsq-S_III-sweet.tab
: muse-total-tsq-S_III-robust-full.tab
: muse-total-tsq-S_III-robust-sweet.tab

** Plot of t2 versus scale
:PROPERTIES:
:ID:       BB997AAB-0452-497F-84A0-69713FB7228C
:END:
+ Uses the tables from the previous section
#+BEGIN_SRC python :eval no :tangle muse-total-tsq-plot.py
  from __future__ import print_function
  import sys
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns
  from astropy.table import Table

  PIXEL_SCALE = 0.2
  region_label = {'full': 'Full MUSE field', 'sweet': 'WFC3 field only'}


  def line_plus_symbol_plot(ax, x, y, label=None, symbol='o'):
      '''Like normal ax.plot, but use both a solid line and symbols, all
  with the same color

      '''
      ax.plot(x, y, symbol+'-', label=label)


  def plot_tsq_vs_scale(ion, region='full', variant='-robust', vscale=None):
      fn = 'muse-total-tsq-{}{}-{}.tab'.format(ion, variant, region)
      tab = Table.read(fn, format='ascii.tab')
      fig, ax = plt.subplots(1, 1)
      scale = tab['nbin']*PIXEL_SCALE
      line_plus_symbol_plot(ax, 2*scale, tab['t^2'], 'raw')
      line_plus_symbol_plot(ax, 2*scale, tab['d t^2'], 'noise')
      line_plus_symbol_plot(ax, 2*scale, tab['t^2'] - tab['d t^2'], 'corrected')
      if vscale is not None:
          ax.set_ylim(-0.02*vscale, 1.02*vscale)
      ax.set_xscale('log')
      ax.set_xlabel('Nyquist angular scale ($2 \\times$ bin width), arcsec')
      ax.set_ylabel('Total plane-of-sky $t^{{\,2}}$([{}])'
                    .format(ion.replace('_', ' ')))
      leg = ax.legend(fontsize='small', title=region_label[region],
                      frameon=True, fancybox=True)
      leg.get_title().set_fontsize('x-small')
      fig.set_size_inches(4, 4)
      figname = fn.replace('.tab', '.pdf')
      fig.tight_layout()
      fig.savefig(figname)
      print(figname)



  sns.set_palette('husl',  n_colors=3)
  for ion in 'N_II', 'S_III':
      for region in 'full', 'sweet':
          for variant in '-robust', '':
              vscale = 0.02 if ion == 'N_II' else 0.005
              plot_tsq_vs_scale(ion, region, variant, vscale)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
python muse-total-tsq-plot.py
#+END_SRC

#+RESULTS:
: muse-total-tsq-N_II-robust-full.pdf
: muse-total-tsq-N_II-full.pdf
: muse-total-tsq-N_II-robust-sweet.pdf
: muse-total-tsq-N_II-sweet.pdf
: muse-total-tsq-S_III-robust-full.pdf
: muse-total-tsq-S_III-full.pdf
: muse-total-tsq-S_III-robust-sweet.pdf
: muse-total-tsq-S_III-sweet.pdf

#+BEGIN_SRC sh
open muse-total-tsq-*.pdf
#+END_SRC

#+RESULTS:




** STARTED Plot the 1D histograms for MUSE data
:PROPERTIES:
:ID:       6BF38576-A09E-484C-8097-5A9DC834B72C
:END:
+ This is a port of [[id:D43C783F-0DD7-43ED-B642-337BD9BE7ECE][Plot the new 1D histograms]] which I did for the WFC3 data
+ [X] I have done it for the standard quantities
  + [X] Histogram tables written from [[id:B85FB5E5-A541-4862-AEA4-796B64172022][Te - Ne distribution histograms]]
  + [X] Plotting program below
    + Now works for any of the 4 quantities
+ [-] Now I have to do it for the fuzzed datasets to get the noise-broadening profile
  + [X] Copy from nil server
  + [X] Generate histogram tables
  + [ ] And another plotting program 


#+BEGIN_SRC python :eval no :tangle muse-plot-hist1d.py
  from __future__ import print_function
  import sys
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns
  from astropy.table import Table

  TERTILES = ['T1', 'T2', 'T3']
  BINNINGS = [1, 4, 16, 64]

  LINETYPES = ['-', '--', '-.', ':']
  LINEWIDTHS = [1, 1.5, 2.0, 2.5]
  # Sweet spot doesn't have enough pixels to tolerate 64x64 binning
  MAXBINNING = {'full': 64, 'sweet': 16}

  quant_label = {
      'T_N_II': 'T([N II])',
      'T_S_III': 'T([S III])',
      'log10_N_S_II_': 'log10[ N([S II]) ]',
      'log10_N_Cl_III_': 'log10[ N([Cl III]) ]',
  }

  quant_weight_text = {
      'T_N_II': '[N II] flux',
      'T_S_III': '[S III] flux',
      'log10_N_S_II_': '[S II] flux',
      'log10_N_Cl_III_': '[Cl III] flux',
  }

  def get_data(xlabel='log10_S_Pa_9_', ylabel='T_N_II', binning=1, region='full'):
      tabfile = 'muse-{xlabel}-{ylabel}-hist-1d-{region}{binning:03d}.tab'.format(
          xlabel=xlabel, ylabel=ylabel, binning=binning, region=region)
      return Table.read(tabfile, format='ascii.tab')


  if __name__ == '__main__':
      centiles = TERTILES
      try: 
          quant = sys.argv[1]
          region = sys.argv[2]
      
      except IndexError:
          print('Usage: {} QUANTITY ("full"|"sweet")'.format(sys.argv[0]))

      clabels = 'Brightest pixels', 'Mid-brightness pixels', 'Faintest pixels'
      sns.set_palette('dark')
      fig, axes = plt.subplots(len(centiles), 1, sharex=True, sharey=True)
      for binning, ls, lw in zip(BINNINGS, LINETYPES, LINEWIDTHS):
          if binning > MAXBINNING[region]:
              continue
          data = get_data(binning=binning, region=region, ylabel=quant)
          for ax, centile in zip(axes, centiles[::-1]):
              x = data[quant_label[quant]]
              y = data[centile]
              # x = 0.5*(x[:-1:2] + x[1::2])
              # y = 0.5*(y[:-1:2] + y[1::2])
              y /= y.sum()
              ax.plot(x, y, lw=lw, ls=ls,
                      label='{0} x {0}'.format(binning))
              ax.fill_between(x, y, alpha=0.2, color=(0.3, 0.3, 0.7))
      for ax, clabel in zip(axes, clabels):
          ax.set_yscale('log')
          ax.set_ylim(1e-3, 0.5)
          ax.text(0.02, 0.95, clabel, transform=ax.transAxes, fontsize='small')
      axes[-1].set_xlabel(quant_label[quant])
      axes[1].set_ylabel('Fraction of ' + quant_weight_text[quant])
      legend = axes[-1].legend(fontsize='small', title='Spatial binning')
      legend.get_title().set_fontsize('small')
      fn = 'muse-plot-{}-hist1d-{}.pdf'.format(quant, region)
      fig.set_size_inches(6, 9)
      fig.tight_layout()
      fig.savefig(fn)


#+END_SRC

#+BEGIN_SRC sh :results silent
python muse-plot-hist1d.py T_N_II full
#+END_SRC
#+BEGIN_SRC sh :results silent
python muse-plot-hist1d.py T_S_III full
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-plot-T_*-hist1d*.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
python muse-plot-hist1d.py log10_N_S_II_ full
#+END_SRC

#+BEGIN_SRC sh :results silent
python muse-plot-hist1d.py log10_N_Cl_III_ full
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-plot-log10_N_*-hist1d*.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
for Q in T_N_II T_S_III log10_N_S_II_ log10_N_Cl_III_; do
    python muse-plot-hist1d.py $Q sweet
    python muse-plot-hist1d.py $Q full
done
#+END_SRC


** Plot 1d histograms of the noise broadening
+ Similar to [[id:6BF38576-A09E-484C-8097-5A9DC834B72C][Plot the 1D histograms for MUSE data]], but for the fuzzed data
+ So draws on material from the WFC3 version:
  + [[id:F8C0DC6B-708D-4E7D-ACB8-FC95AA3258B8][And plot the 1D histograms for the noise too]]

#+BEGIN_SRC python :eval no :tangle muse-plot-noise-hist1d.py
  from __future__ import print_function
  import sys
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns
  from astropy.table import Table

  TERTILES = ['T1', 'T2', 'T3']
  BINNINGS = [1, 4, 16, 64]

  LINETYPES = ['-', '--', '-.', ':']
  LINEWIDTHS = [1, 1.5, 2.0, 2.5]
  # Sweet spot doesn't have enough pixels to tolerate 64x64 binning
  MAXBINNING = {'full': 64, 'sweet': 16}

  quant_label = {
      'N_II_Delta_T'  : '[N II] Delta T',
      'S_III_Delta_T' : '[S III] Delta T',
      'S_II_log10-n'  : '[S II] log10 (N\' / N)',
      'Cl_III_log10-n': '[Cl III] log10 (N\' / N)',
  }

  quant_weight_text = {
      'N_II_Delta_T': '[N II] flux',
      'S_III_Delta_T': '[S III] flux',
      'S_II_log10-n': '[S II] flux',
      'Cl_III_log10-n': '[Cl III] flux',
  }

  def get_data(xlabel='log10_S_Pa_9_', ylabel='T_N_II', binning=1, region='full', ifuzz=0):
      tabfile = 'muse-{xlabel}-{ylabel}-hist-1d-{region}-fuzz{ifuzz:03d}-bin{binning:03d}.tab'.format(
          xlabel=xlabel, ylabel=ylabel, binning=binning, region=region, ifuzz=ifuzz)
      return Table.read(tabfile, format='ascii.tab')


  if __name__ == '__main__':
      centiles = TERTILES
      try: 
          quant = sys.argv[1]
          region = sys.argv[2]
    
      except IndexError:
          print('Usage: {} QUANTITY ("full"|"sweet")'.format(sys.argv[0]))

      clabels = 'Brightest pixels', 'Mid-brightness pixels', 'Faintest pixels'
      sns.set_palette('dark')
      fig, axes = plt.subplots(len(centiles), 1, sharex=True, sharey=True)
      for binning, ls, lw in zip(BINNINGS, LINETYPES, LINEWIDTHS):
          if binning > MAXBINNING[region]:
              continue
          for ifuzz in range(10):
              data = get_data(binning=binning, region=region, ylabel=quant, ifuzz=ifuzz)
              if ifuzz == 0:
                  sumdata = data
              else:
                  for centile in centiles:
                      sumdata[centile] += data[centile]
          x = sumdata[quant_label[quant]]

          for ax, centile in zip(axes, centiles[::-1]):
              y = sumdata[centile]
              # x = 0.5*(x[:-1:2] + x[1::2])
              # y = 0.5*(y[:-1:2] + y[1::2])
              y /= y.sum()
              ax.plot(x, y, lw=lw, ls=ls,
                      label='{0} x {0}'.format(binning))
              ax.fill_between(x, y, alpha=0.2, color=(0.7, 0.3, 0.3))
      for ax, clabel in zip(axes, clabels):
          ax.set_yscale('log')
          ax.set_ylim(1e-3, 0.5)
          ax.text(0.02, 0.95, clabel, transform=ax.transAxes, fontsize='small')
      axes[-1].set_xlabel(quant_label[quant])
      axes[1].set_ylabel('Fraction of ' + quant_weight_text[quant])
      legend = axes[-1].legend(fontsize='small', title='Spatial binning')
      legend.get_title().set_fontsize('small')
      fn = 'muse-plot-{}-noise-hist1d-{}.pdf'.format(quant, region)
      fig.set_size_inches(6, 9)
      fig.tight_layout()
      fig.savefig(fn)


#+END_SRC

#+BEGIN_SRC sh :results silent
for Q in N_II_Delta_T S_III_Delta_T S_II_log10-n Cl_III_log10-n; do
    python muse-plot-noise-hist1d.py $Q full
    python muse-plot-noise-hist1d.py $Q sweet
done
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-plot-*noise-hist1d-full.pdf
#+END_SRC

#+BEGIN_SRC sh :results silent
open muse-plot-*noise-hist1d-sweet.pdf
#+END_SRC

** STARTED Calculate maps of the small-scale T fluctuations
+ [ ] We should do the IQR of the dt, to compare with the median of dt**2
#+BEGIN_SRC python :tangle muse-small-scale-t2-map.py
  from __future__ import print_function
  import sys
  import numpy as np
  from rebin_utils import oversample
  from astropy.io import fits

  nlist = [4, 8, 16, 32, 64, 128]
  for suffix in '', '-iii':
      fn = 'LineMaps/muse-derived-Te{}-bin001.fits'.format(suffix)
      hdu = fits.open(fn)['SCALED']
      ny, nx = hdu.data.shape
      print(ny, nx)
      for nbin in nlist:
          sbin = 'bin{:03d}'.format(nbin)
          mfn = fn.replace('bin001', sbin)
          T0 = fits.open(mfn)['SCALED'].data
          efn = fn.replace('bin', 'STD-bin')
          std = fits.open(efn)['SCALED'].data
          dt = (hdu.data - T0)/T0
          edt = std/T0
          dt4d = dt.reshape((nbin, ny//nbin, nbin, nx//nbin))
          t2 = np.nanmedian(dt4d**2, axis=(0, 2))
          t2 = oversample(t2, nbin)
          edt4d = edt.reshape((nbin, ny//nbin, nbin, nx//nbin))
          et2 = np.nanmedian(edt4d**2, axis=(0, 2))
          et2 = oversample(et2, nbin)
          t2 -= et2
          # sfn = mfn.replace('bin', 'SN-bin')
          # sn = fits.open(sfn)['SCALED'].data
          # t2 -= 1./sn**2
          out_fn = mfn.replace('derived-Te', 'finescale-t2')
          print('Writing', out_fn)
          fits.PrimaryHDU(header=hdu.header, data=t2).writeto(out_fn,
                                                              clobber=True)
          out_fn = mfn.replace('derived-Te', 'finescale-et2')
          print('Writing', out_fn)
          fits.PrimaryHDU(header=hdu.header, data=et2).writeto(out_fn,
                                                              clobber=True)
          out_fn = mfn.replace('derived-Te', 'finescale-dt')
          print('Writing', out_fn)
          fits.PrimaryHDU(header=hdu.header, data=dt).writeto(out_fn,
                                                              clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results verbatim
python muse-small-scale-t2-map.py
#+END_SRC

#+RESULTS:
#+begin_example
1536 1792
Writing LineMaps/muse-finescale-t2-bin004.fits
Writing LineMaps/muse-finescale-et2-bin004.fits
Writing LineMaps/muse-finescale-dt-bin004.fits
Writing LineMaps/muse-finescale-t2-bin008.fits
Writing LineMaps/muse-finescale-et2-bin008.fits
Writing LineMaps/muse-finescale-dt-bin008.fits
Writing LineMaps/muse-finescale-t2-bin016.fits
Writing LineMaps/muse-finescale-et2-bin016.fits
Writing LineMaps/muse-finescale-dt-bin016.fits
Writing LineMaps/muse-finescale-t2-bin032.fits
Writing LineMaps/muse-finescale-et2-bin032.fits
Writing LineMaps/muse-finescale-dt-bin032.fits
Writing LineMaps/muse-finescale-t2-bin064.fits
Writing LineMaps/muse-finescale-et2-bin064.fits
Writing LineMaps/muse-finescale-dt-bin064.fits
Writing LineMaps/muse-finescale-t2-bin128.fits
Writing LineMaps/muse-finescale-et2-bin128.fits
Writing LineMaps/muse-finescale-dt-bin128.fits
1536 1792
oversample: nan(s) found in input image
oversample: nan(s) found in output image
Writing LineMaps/muse-finescale-t2-iii-bin004.fits
Writing LineMaps/muse-finescale-et2-iii-bin004.fits
Writing LineMaps/muse-finescale-dt-iii-bin004.fits
Writing LineMaps/muse-finescale-t2-iii-bin008.fits
Writing LineMaps/muse-finescale-et2-iii-bin008.fits
Writing LineMaps/muse-finescale-dt-iii-bin008.fits
Writing LineMaps/muse-finescale-t2-iii-bin016.fits
Writing LineMaps/muse-finescale-et2-iii-bin016.fits
Writing LineMaps/muse-finescale-dt-iii-bin016.fits
Writing LineMaps/muse-finescale-t2-iii-bin032.fits
Writing LineMaps/muse-finescale-et2-iii-bin032.fits
Writing LineMaps/muse-finescale-dt-iii-bin032.fits
Writing LineMaps/muse-finescale-t2-iii-bin064.fits
Writing LineMaps/muse-finescale-et2-iii-bin064.fits
Writing LineMaps/muse-finescale-dt-iii-bin064.fits
Writing LineMaps/muse-finescale-t2-iii-bin128.fits
Writing LineMaps/muse-finescale-et2-iii-bin128.fits
Writing LineMaps/muse-finescale-dt-iii-bin128.fits
#+end_example

* Correlations between Te, Ne and other things

** Crazy things we could calculate

*** TODO Mean ionizing flux distribution
+ From the [O III]/[O II] ratio and assuming Ne([Cl III]) and Te([S III]) we can estimate what the flux in the O+ ionizing continuum is
+ This comes from the following:
  + O ionization balance: F \sigma n(O+) = \alpha n(e) n(O++)
  + [O III] Surface brightness: S([O III]) = \int n(e) n(O++) fIII(T) dz
  + [O II] Surface brightness: S([O II]) = \int n(e) n(O+) fII(T) dz
+ => "average" n(O++)/n(O+) = {S([O III]) / S([O II])} {fII(T) / fIII(T)}
+ => "average" F = (\alpha/\sigma) n(e) (fII/fIII) R(5007/7318)
+ But we have to correct 5007/7318 for extinction first
  + We should probably correct all the lines for extinction



* Thoughts on large scale features of the nebula

** The neutral filaments
+ These are best revealed in the O I 8446 / H I 8545 ratio
  + That is the closest Paschen line to the strongest O I permitted line that is not contaminated with something
+ The filaments show all the classic bars
  + Bright Bar
  + Trapezium Compact Bar
  + SW Compact Bar
+ What we called the Near E Bar in GDH07 turns out to be part of a knotty C-shaped shell that runs from N of Trap (intermediate between Trap Compact Bar and E-W Bright Bar) round to E, then turns S to form the Near E Bright Bar and then when it gets to SE of Trap it curves to the W again to run parallel to the Big Arc
  + It looks like it could possibly be related with the Big Arc
    + But in [O I] it does not have high velocity: +10 km/s at bluest, which is bluer than the Bright Bar (which is more like +20), but nothing like as blue as the Big Arc
    + So it is probably unrelated
  + So is it on the near side or the far side?
* Exploring the data cubes
** Original data locations
At CRyA in =/fs/nil/other0/will/orion-muse/DATA= 
+ LR :: 1.25 Angstrom sampling: DATACUBEFINALuser_20140216T010259_cf767044.fits
+ HR :: 0.85 Angstrom sampling: DATACUBEFINALuser_20140216T010259_78380e1d.fits
*** LR cube
+ Dimensions:
  + NV = 3818
  + NY = 1476
  + NX = 1766
+ Scales:
  + Spatial: 0.2 arcsec
  + Wavelength: 1.25 Ang
**** Reading in the cube
#+BEGIN_SRC python
from astropy.io import fits
from astropy import wcs
import numpy as np
hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_cf767044.fits')
cube = hdulist['DATA']
#+END_SRC
Note that this does not read the full data cube (40 GB) into memory unless we need to do something with it.
**** Extracting the Orion S region
+ To start with, we will look at a 300x300 box centered on (1050, 550)
+ This is more or less the quad filter region
#+BEGIN_SRC python
  subcube = cube.data[:, 400:700, 900:1200]
  spec = np.nansum(np.nansum(subcube, axis=-1), axis=-1)
  spechdu = fits.PrimaryHDU(header=cube.header, data=spec.reshape((3818, 1, 1)))
  spechdu.writeto('subcube-spec.fits')
#+END_SRC
+ So this gives the summed spectrum of the region
+ Note that I did a reshape on the array so that wavelength is still the 3rd FITS axis.  So that the header WCS keywords don't need changing 
#+BEGIN_SRC sh
rsync -avzP nil:/fs/nil/other0/will/orion-muse/subcube-spec.fits .
#+END_SRC
+ The spectrum shows up as a single pixel in ds9, but you can see a graph of it by using a region
*** HR cube
:PROPERTIES:
:TABLE_EXPORT_FILE: wavsec-startwavs.tab
:TABLE_EXPORT_FORMAT: orgtbl-to-tsv
:ID:       C2108CD1-EF28-4F63-9CA1-B7F9DA59C450
:END:
+ Exactly the same, except that NV = 5614
  + Wavelength scale: 0.85 angstroms
  + CRPIX3 = 1
  + CRVAL3 = 4595.
+ First try at dividing it up: do it by wavelength
  + Divide into 8 parts of length 702
    + Last one will be 700
  + Size will be 0.702 1.476 1.766 4 = 7.32 GB




#+name: wavsec-startwavs
| Section |  CRVAL3 |
|---------+---------|
|       0 | 4595.00 |
|       1 | 5191.70 |
|       2 | 5788.40 |
|       3 | 6385.10 |
|       4 | 6981.80 |
|       5 | 7578.50 |
|       6 | 8175.20 |
|       7 | 8771.90 |
#+TBLFM: $2=4595.0 + 0.85 702 $1 ;f2

#+BEGIN_SRC python :tangle muse_divide_cube_in_sections.py
  import sys
  from astropy.io import fits
  from astropy import wcs
  import numpy as np

  try:
      quantity = sys.argv[1]
      assert quantity in ['data', 'variance']
  except (IndexError, AssertionError) as e:
      sys.exit('Usage: {} (data|variance)'.format(sys.argv[0]))


  if quantity == 'variance':
      cubename = 'STAT'
  else:
      cubename = 'DATA'
    
  hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_78380e1d.fits')
  cube = hdulist[cubename]
  sections = np.arange(8, dtype=int)
  NV = 702
  k1_list = sections*NV
  k2_list = k1_list + NV
  wav0_list = cube.header['CRVAL3'] + cube.header['CD3_3']*NV*sections
  for section, k1, k2, wav0 in zip(sections, k1_list, k2_list, wav0_list):
      fn = 'muse-hr-{}-wavsec{}.fits'.format(quantity, section)
      hdr = cube.header.copy()
      hdr['CRVAL3'] = wav0
      hdr['NAXIS3'] = NV
      print('Writing', fn)
      fits.PrimaryHDU(header=hdr, data=cube.data[k1:k2]).writeto(fn, clobber=True)


#+END_SRC


+ That version is having problems with the later sections - memory usage is increasing, which is not good. 
+ So I will try a version that does only one section and then stops
+ Actually it looks like it is OK, so I won't need this version
  + Turns out that =watch ls -l PATTERN= only matches =PATTERN= once at the start, so any new files don't show up.  Better to use =watch -d ls -lth=
+ It takes 3 to 5 min per section to extract
+ File transfer to hypatia takes 8 min per section, so that is the limiting factor
#+BEGIN_SRC python :tangle muse_divide_and_conquer.py
  import sys
  from astropy.io import fits
  from astropy import wcs
  import numpy as np

  sections = np.arange(8, dtype=int)
  NV = 702
  k1_list = sections*NV
  k2_list = k1_list + NV

  try:
      quantity = sys.argv[1]
      section = int(sys.argv[2])
      assert quantity in ['data', 'variance']
      assert section in sections
  except (IndexError, AssertionError) as e:
      sys.exit('Usage: {} (data|variance) SECTION'.format(sys.argv[0]))


  if quantity == 'variance':
      cubename = 'STAT'
  else:
      cubename = 'DATA'
  
  hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_78380e1d.fits')
  cube = hdulist[cubename]

  wav0_list = cube.header['CRVAL3'] + cube.header['CD3_3']*NV*sections

  k1, k2, wav0 = k1_list[section], k2_list[section], wav0_list[section]
  fn = 'muse-hr-{}-wavsec{}.fits'.format(quantity, section)
  hdr = cube.header.copy()
  hdr['CRVAL3'] = wav0
  hdr['NAXIS3'] = NV
  print('Writing', fn)
  fits.PrimaryHDU(header=hdr, data=cube.data[k1:k2]).writeto(fn, clobber=True)


#+END_SRC

And finally, a version that solves the edge effect problem by extracting little cubes that straddle the dividing wavelengths

#+BEGIN_SRC python :tangle muse_edge_patch.py
  import sys
  from astropy.io import fits
  from astropy import wcs
  from astropy import units as u
  import numpy as np

  sections = np.arange(8, dtype=int)
  NV = 702
  # Extract cube that is +/- dwav around the wavsec boundary 
  dwav = 12.0

  try:
      quantity = sys.argv[1]
      section = int(sys.argv[2])
      assert quantity in ['data', 'variance']
      # makes no sense for 0th section
      assert section in sections and section > 0
  except (IndexError, AssertionError) as e:
      sys.exit('Usage: {} (data|variance) SECTION'.format(sys.argv[0]))


  if quantity == 'variance':
      cubename = 'STAT'
  else:
      cubename = 'DATA'
  
  hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_78380e1d.fits')
  cube = hdulist[cubename]
  w = wcs.WCS(cube.header)
  wav0 = cube.header['CRVAL3'] + cube.header['CD3_3']*NV*section
  wavs = (wav0 + dwav*np.array([-1.0, 1.0]))*u.Angstrom.to(u.m)
  print('Wavelength window', wavs)
  _, _, pixels = w.wcs_world2pix([0, 0], [0, 0], wavs, 0)
  k1, k2 = int(pixels[0]), int(pixels[1]) + 2
  window = slice(k1, k2), slice(None), slice(None)
  fn = 'muse-hr-{}-wavsec-edge{}{}.fits'.format(quantity, section - 1, section)
  hdr = cube.header.copy()
  hdr.update(w.slice(window).to_header())

  print('Writing', fn)
  fits.PrimaryHDU(header=hdr, data=cube.data[window]).writeto(fn, clobber=True)


#+END_SRC

These need to be run through clean_up_wav_wcs.py afterwards

*** Ship all relevant files to server
:PROPERTIES:
:ID:       E29DD76D-0B11-4F52-8B50-8967046D2F0C
:END:


**** Ship data tables to server
#+BEGIN_SRC sh :results verbatim
  date
  rsync -avzPL --info=progress0 [a-l,n-z]*.tab nil:/fs/nil/other0/will/orion-muse
#+END_SRC
  
**** Ship python programs and shell scripts to server
#+BEGIN_SRC sh :results verbatim
  date
  rsync -avzPL --info=progress0 *.{py,sh} nil:/fs/nil/other0/will/orion-muse
#+END_SRC

#+RESULTS:
: Mon Oct 30 12:10:54 CST 2017
: sending incremental file list
: extract-em-line-fuzz.py
: 
: sent 2,654 bytes  received 64 bytes  1,812.00 bytes/sec
: total size is 145,872  speedup is 53.67


**** Ship line class masks to server
+ /Note that this requires that external disk be connected/
#+BEGIN_SRC sh :results verbatim
  date
  rsync -avzPL --info=progress0 LineMaps/mask-line-class*.fits nil:/fs/nil/other0/will/orion-muse/LineMaps
#+END_SRC

#+RESULTS:
#+begin_example
Tue Oct 24 22:13:26 CDT 2017
sending incremental file list
basic-line-list.tab
line-classes.tab

sent 933 bytes  received 137 bytes  713.33 bytes/sec
total size is 785,704  speedup is 734.30
sending incremental file list

sent 2,165 bytes  received 11 bytes  1,450.67 bytes/sec
total size is 145,293  speedup is 66.77
#+end_example

*** Heliocentric correction
Again, these snippets need to be run on the CRyA server where the big data cubes are
**** Looking for keywords in the top-level header
#+BEGIN_SRC python
hdr = hdulist[0].header
hdr.tofile('HRcube.hdr', sep='\n', padding=False)
#+END_SRC

#+RESULTS:

#+BEGIN_EXAMPLE
SIMPLE  =                    T / file does conform to FITS standard             
BITPIX  =                    8 / number of bits per data pixel                  
NAXIS   =                    0 / number of data axes                            
EXTEND  =                    T / FITS dataset may contain extensions            
COMMENT   FITS (Flexible Image Transport System) format is defined in 'Astronomy
COMMENT   and Astrophysics', volume 376, page 359; bibcode: 2001A&A...376..359H 
DATE    = '2014-11-13T08:54:24' / file creation date (YYYY-MM-DDThh:mm:ss UT)   
ORIGIN  = 'TEST    '           / European Southern Observatory                  
TELESCOP= 'ESO-VLT-U4'         / ESO <TEL>                                      
INSTRUME= 'MUSE    '           / Instrument used.                               
RA      =            83.780509 / [deg] 05:35:07.3 RA (J2000) pointing           
DEC     =             -5.39556 / [deg] -05:23:44.0 DEC (J2000) pointing         
EQUINOX =                2000. / Standard FK5                                   
RADECSYS= 'FK5     '           / Coordinate system                              
EXPTIME =                   5. / Integration time                               
MJD-OBS =       56704.04374097 / Obs start                                      
DATE-OBS= '2014-02-16T01:02:59.219' / Observing date                            
UTC     =                3770. / [s] 01:02:49.000 UTC                           
LST     =             21901.85 / [s] 06:05:01.850 LST                           
PI-COI  = 'UNKNOWN '           / PI-COI name.                                   
OBSERVER= 'UNKNOWN '           / Name of observer.                              
PIPEFILE= 'DATACUBE_FINAL.fits' / Filename of data product                      
BUNIT   = '10**(-20)*erg/s/cm**2/Angstrom'                                      
DATAMD5 = '69173383d3718d3ddb46e187f4cc2954' / MD5 checksum                     
OBJECT  = 'M42-lr  '           / Original target.                               
CHECKSUM= 'NcfSOcZPNcdPNcZP'   / HDU checksum updated 2014-11-12T22:17:16       
DATASUM = '0       '           / data unit checksum updated 2014-11-12T22:17:16 
HIERARCH ESO OBS AIRM =     5. / Req. max. airmass                              
HIERARCH ESO OBS AMBI FWHM = 2. / Req. max. seeing 
... ETC ...        
#+END_EXAMPLE

So, this does have the info that we need: RA, DEC, MJD-OBS in particula


* Set matplotlib options for fonts
#+begin_src python :tangle matplotlibrc
text.usetex         : False
mathtext.fontset    : stixsans
#+end_src


